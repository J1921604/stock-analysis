
# 日本株 AI 解析システム 実装仕様書（他AI再現用）  

---

## 1. システム全体像

### 1.1 ゴール
- 日次で日本上場銘柄の情報（財務データ・株価など）を自動更新し、以下を提供する:  
  - ネットネットバリュー株ランキング  
  - ネットネットバリュー PBR 推移チャート  
  - 「オニールの成長株発掘法」に基づく成長株ランキング & 個別詳細ページ  
  - 「分配日」によるマーケット天井検出ツール  
- 解析ロジック・データはすべて SQLite ファイルに集約し、ブラウザ/ローカルの両方から利用可能にする。  
- 運用者は日々のバッチの成否をあまり気にせず、条件を満たした銘柄が見つかった時だけメール通知で把握できる。  

### 1.2 非機能要件・設計ポリシー
- 個人開発を前提に「運用コスト最小化」「フルマネージド」「要素削減による堅牢化」を最優先。  
- 24h 常時稼働サーバーは持たない（セキュリティ・アップデート・障害対応コスト回避）。  
- インフラ構成要素:  
  - AWS S3（+ Glacier Deep Archive）  
  - GitHub リポジトリ  
  - GitHub Actions（CI / スケジューラ）  
  - GitHub Pages（静的サイト配信）  
  - GitHub Issues（通知兼ログ）  

### 1.3 構成要約
- データストア: 単一の SQLite DB ファイル（＋過去の XBRL 等の「生ファイル」）  
- バッチ:  
  - GitHub Actions の cron が毎日実行  
  - S3 上の SQLite を取得 → 新規データDL&パース → SQLite 更新 → S3 にアップロード  
  - 解析実行・通知（GitHub Issue 作成）・HTMLリンク/DBダウンロードリンクの更新  
- フロント:  
  - GitHub Pages 上に配置された単一 HTML（CSS/JS 同梱）  
  - ページ起動時に presigned URL から最新 SQLite を取得（sqlite-wasm でブラウザ内クエリ）  
  - lightweight-charts でチャート描画  
  - パラメータはブラウザ内で動的変更可  
  - ローカル SQLite ファイルをユーザー手動指定して解析するモードも持つ  

---

## 2. データソースと保存戦略

### 2.1 データソース一覧
1. 有価証券報告書 XBRL  
   - 取得元: EDINET（金融庁）  
   - 範囲: 過去10年（API仕様に依存）  
   - ダウンロード制限: DoS 回避のため 1秒に1ファイル程度でレート制限  
2. 株価データ  
   - 日本株の終値・出来高など（日次）  
   - 具体的なAPIやデータ源は実装側で選択（証券会社API、公式配信、スクレイピング等）  

### 2.2 保存方針
- 生データ（XBRLなどの原ファイル）  
  - GitHub Actions にてダウンロード後、基本的にすべて S3 へアップロードし「永続保存」。  
  - 年ごとに tar.gz にまとめ、S3 Glacier Deep Archive クラスで格納し保管・転送料金を削減。  
  - ローカルでパーサー改善・再パースするときは `aws s3 sync` により S3 から取得。  
- SQLite ファイル  
  - S3 バケットに「バージョニング有効」で保存。  
  - 常に「最新版」を上書き保存、過去版はバージョンとして残る。  
  - 数百MB規模まで肥大化を想定し、非圧縮版と gzip 版の両方を用意。  
  - ダウンロード速度のため、GitHub Artifacts ではなく S3 を採用。  

---

## 3. SQLite スキーマ（概略）  
※厳密な列名は実装時に決めるが、他AIが再実装できるレベルで粒度を定義する。  

### 3.1 企業マスタ
- `companies` テーブル  
  - `security_code` (TEXT or INTEGER, primary key)  
  - `edinet_code` (TEXT)  
  - `company_name` (TEXT)  
  - `market` (TEXT)  
  - その他必要に応じた属性（業種など）  

### 3.2 財務データ（XBRL パース結果）
- `financials` テーブル（年次/四半期単位）  
  - `id` (INTEGER, PK)  
  - `security_code`  
  - `fiscal_year` / `fiscal_period`  
  - `report_type`（有報/四半期報 等）  
  - `total_assets`  
  - `total_liabilities`  
  - `cash_and_deposits`  
  - `marketable_securities`  
  - `inventory`  
  - その他、ネットネットバリュー計算・EPS計算等に必要な科目  

### 3.3 株価データ
- `prices` テーブル（日次）  
  - `security_code`  
  - `date`  
  - `open`  
  - `high`  
  - `low`  
  - `close`  
  - `volume`  
  - インデックス等、リラティブストレングスに必要な情報も別テーブルまたは列で保持  

### 3.4 指標/解析結果キャッシュ（任意）
- ネットネットバリューやオニール系評価値を事前計算してキャッシュするテーブルを用意しても良い。  
- ただしブラウザ側で動的計算も可能なため、どこまでサーバー側で前計算するかは要件次第。  

---

## 4. 解析ロジック仕様

### 4.1 ネットネットバリュー株ランキング

#### 4.1.1 指標の定義
- 「即時現金化可能な資産」から総負債を引いた会社の「解散時価値」を分子とし、時価総額を分母とした、PBRに類似する指標。  
- 基本式のイメージ：
\[
\text{NetNetValuePBR} = \frac{\text{即時現金化可能資産} - \text{総負債}}{\text{時価総額}}
\]
- 「即時現金化可能資産」は実装時に以下のような項目を対象候補とし、ユーザーが画面上でオン/オフや割引率を設定できる仕様にする:  
  - 現金及び預金  
  - 有価証券（短期保有）  
  - 受取手形・売掛金  
  - 棚卸資産（必要に応じて大きく割引）  
- 各項目の割引率（例：現金100%、有価証券80%、売掛金70%、棚卸資産50%など）を、UI上で変更可能なパラメータとして持つ。  

#### 4.1.2 ランキングロジック
- 毎日時点で時価総額が算出できる銘柄について、NetNetValuePBR を計算。  
- 1未満の銘柄を「割安」とみなし、値が小さい順にランキング。  
- 表示項目例:  
  - 証券コード・銘柄名  
  - NetNetValuePBR 値  
  - 時価総額  
  - 即時現金化可能資産総額・総負債  
  - 業種などの補足情報  

#### 4.1.3 PBR 推移チャート
- 過去の日次or決算ごとに NetNetValuePBR（および通常のPBR）を再現し、時系列チャートで描画。  
- 直近期に値が低くなっているかを一目で判定できるようにする。  
- 表示ライブラリは lightweight-charts を使用。  

---

### 4.2 オニールの成長株発掘ランキング

#### 4.2.1 元ネタ
- 書籍「オニールの成長株発掘法」で紹介されている CAN SLIM 系のスクリーニング手法をベースに実装。  

#### 4.2.2 スクリーニング指標例
- EPS 成長率（四半期・通期）  
- 売上高成長率  
- 株価リラティブストレングス（一定期間にわたる株価パフォーマンス vs 市場インデックス）  
- テクニカルなトレンド継続性（移動平均との位置など）  
※具体的な閾値は記事中では明示されていないため、「閾値を設定可能なパラメータ」として UI/コード上に用意すること。  

#### 4.2.3 一覧ページ仕様
- 一枚の HTML 内に、ランキング一覧と個別詳細を持つ SPA とする。  
- ランキング表示項目例:  
  - 証券コード・銘柄名  
  - EPS 成長率  
  - リラティブストレングス スコア  
  - 時価総額  
  - 直近決算期・次回決算予定日（わかる範囲で）  

#### 4.2.4 個別銘柄詳細ページ
- 上部: 価格チャート＋オニールシグナル期間の可視化  
  - 決算発表日をマーカーで表示。  
  - 条件を満たして「買いシグナル」となった期間を背景色（例：薄い緑など）でハイライト。  
- 下部: 指標一覧  
  - 四半期ごとの EPS・売上成長率一覧  
  - 過去のリラティブストレングス推移  
- すべて1枚HTML内でルーティング（SPA）する。  

---

### 4.3 オニールのマーケット天井検出ツール

#### 4.3.1 コンセプト
- オニールが定義する「分配日（distribution day）」をカウントし、上昇トレンドが天井を打つ可能性を検知する。  
- 市場インデックス（日経平均など）の日足データを使用。  

#### 4.3.2 分配日定義（一般的なイメージ）
- 価格下落かつ出来高増加の日を分配日としてカウントする（厳密な定義は書籍参照）。  
- 一定日数（例：過去 25 日など）の中で分配日が閾値を超えると警告ゾーンに入る。  

#### 4.3.3 表示仕様
- 市場指数チャート上に分配日をマーカー表示。  
- 「注意期間」を背景色で表示し、どのゾーンが危険域かを一目で分かるようにする。  
- 利用者がパラメータ（分配日判定条件、カウント対象期間、閾値）を UI から調整可能にする。  

#### 4.3.4 チューニング
- パラメータ最適化をベイズ最適化で試みたが「うまくいかなかった」という前提で、  
  - 実装上、「自動最適化アルゴリズム」はあってもなくてもよい。  
  - 少なくとも、手動でパラメータを変えながらチャートとシグナルを確認できるUIは必須。  

---

## 5. バッチ処理仕様（GitHub Actions）

### 5.1 スケジュール
- 実行時刻: 毎日 18:00 JST（= 9:00 UTC）  
- YAML例（概念）:

on:
schedule:
- cron: "0 9 * * *" # 9:00 UTC = 18:00 JST
workflow_dispatch:

### 5.2 日次ジョブの処理フロー
1. S3 から最新の SQLite ファイルをダウンロード。  
2. SQLite 内のテーブルから「最新日付」を取得し、それ以降のデータのみ更新対象とする。  
3. その日に更新された株価データをダウンロード。  
4. その日に公開・更新された XBRL ファイルを EDINET からダウンロード（レート制限付き）。  
5. ダウンロード済みの XBRL 等の生ファイルをパースし、正規化したデータを SQLite に追記。  
6. ダウンロードした生データファイル一式を `aws s3 sync` で S3 にアップロード。  
7. SQLite ファイルを更新し終えたあとで（ここが重要）最新版として S3 に上書きアップロード。  
8. SQLite に対して解析クエリを実行し、  
  - 新たに条件を満たした銘柄（ネットネットバリュー/オニール系など）を抽出。  
9. 条件を満たした新規銘柄があれば GitHub Issue を作成（＝メール通知）。  
10. 最新 SQLite ファイルの presigned URL を生成し、解析ページへのリンクと共に GitHub Actions Summary に表示。  
  - presigned URL の有効期限は7日程度を想定。  

### 5.3 欠損データ対策
- CI 失敗による一部日付の欠損を防ぐため、「SQLite 内の最新日付以降を再取得」する設計とし、  
  - バッチが1日飛んでも、次回実行時に欠損期間をまとめて取得できる。  
- SQLite のアップロードは「すべての更新が完了した最後」にのみ実施。  

---

## 6. フロントエンド（解析ページ）仕様

### 6.1 配信方法
- GitHub Pages に配置された静的 HTML ファイルとして配信。  
- ページ構成:  
  - HTML ファイル 1枚に  
    - レイアウト・スタイル（CSS）  
    - ロジック（JavaScript）  
    - ルーティング（SPA）  
  をすべて内包する。  
- レスポンシブ対応（スマホからの閲覧前提）。  

### 6.2 使用ライブラリ
- `sqlite-wasm`  
  - ブラウザ上で SQLite ファイルを読み、SQL クエリ実行ができるようにする。  
- `lightweight-charts`  
  - 多数データ点 & マーカー表示でも滑らかに動くチャートライブラリ。  
  - スクロール・拡大時のパフォーマンスを重視し、他のチャートライブラリより優先して採用。  

### 6.3 データ取得フロー
1. ページURLのクエリパラメータに `db_url=<presigned URL>` を付与して配信する設計にする。  
2. ブラウザ起動時に  
   - クエリパラメータから presigned URL を取得。  
   - `fetch` 等で SQLite ファイルをダウンロードし、ブラウザ内でキャッシュ。  
   - `sqlite-wasm` へロードし、以後の解析クエリに利用。  
3. パラメータ変更（ネットネットバリュー割引率・オニール閾値・分配日条件等）は JS 上で即時再計算して画面更新。  

### 6.4 ローカル DB 利用モード
- ファイル入力UIを用意し、ユーザーがローカル環境にある SQLite ファイルをアップロードして解析に用いるモードもサポート。  
- これにより、新しい解析ページを開発するときも、S3経由ではなくローカルだけで開発・検証が可能。  

---

## 7. 通知設計（GitHub Issues）

### 7.1 要件
- Slack やメール配信サービスを追加で使わずに「なるべく既存の GitHub 機能だけで通知を完結させる」。  

### 7.2 実装方針
- 日次バッチの解析フェーズで「新たに条件を満たした銘柄リスト」を生成。  
- リストが空でない場合、以下のフォーマットで GitHub Issue を作成:  
  - タイトル例: `【ネットネット or オニール】YYYY-MM-DD 新規検出銘柄`  
  - 本文:  
    - 検出条件（例: NetNetValuePBR < 1, EPS成長率 > X など）  
    - 検出銘柄一覧（証券コード、銘柄名、代表指標）  
- GitHub 側の設定により、リポジトリオーナー宛のメール通知が飛ぶ。  
- 運用者は  
  - 検出内容をメール/Issue上で確認  
  - 気に入らない銘柄については理由付きで Issue を close  
  - 後から「いつこう判断したか」のログとしても活用  

---

## 8. AI コーディングの使い方（再実装時のガイド）

※元記事では詳細は別記事予告だが、再現性のため方針だけまとめる。  

- 役割分担:  
  - 人間：アーキテクチャ設計、データフロー設計、必要機能の洗い出し、品質の最終判断  
  - AI：XBRL パーサー、バッチスクリプト、フロントエンドHTML/JS、チャート描画コードなどの実装 95% 以上  
- AI への指示例:  
  - 「EDINETのXBRLを○○APIから取得し、この勘定科目を抽出してSQLiteに格納するコードを書いて」  
  - 「sqlite-wasm と lightweight-charts を使って、このスキーマの DB からネットネットバリューランキングを表示する単一HTMLを作って」  
  - 「GitHub Actions で、このPythonスクリプトを毎日18時に実行するワークフローファイルを書いて」  

---

## 9. 成果と限界（参考情報）

- 開発期間: 休日・平日夜のみで約3ヶ月で上記レベルまで到達。  
- 利便性:  
  - 毎日の手動スクリプト実行が不要になり、条件を満たした銘柄が出たときだけ通知を見る運用に移行。  
- パフォーマンス:  
  - アーキテクチャ設計や効率的なコードは、現時点では人間エンジニアの工夫が依然として重要、という示唆。  
- 投資パフォーマンス:  
  - 当年の運用成績は日経平均 [finance:Nikkei 225] に負けており、「結局インデックス投資が強いかも」というオチを付す。  

---

## 10. 再実装チェックリスト

他AIでこの仕様書をもとにシステムを再現する際、以下を満たしていればほぼ同等とみなせる。  
- [ ] データはすべて SQLite 1ファイルに統合されている。  
- [ ] GitHub Actions の日次ジョブだけでデータ更新・解析・リンク生成まで完結する。  
- [ ] 生XBRLファイルはS3に年単位 tar.gz + Glacier で長期保管されている。  
- [ ] 解析ページは GitHub Pages 配信の単一HTML（CSS/JS埋め込み）であり、sqlite-wasm + lightweight-charts を使用している。  
- [ ] NetNetValuePBR ランキングとその推移チャートが閲覧できる。  
- [ ] オニール流の成長株ランキングと、決算マーカー＋シグナル区間を色分けした銘柄詳細ページがある。  
- [ ] 分配日にもとづくマーケット天井検出ツールがあり、注意ゾーンを背景色で表示できる。  
- [ ] 新規検出銘柄は GitHub Issue 経由で通知され、メールで受け取れる。  
- [ ] presigned URL をクエリパラメータとして解析ページに渡し、ブラウザ起動時に最新 SQLite を自動取得する。  
- [ ] ローカルの SQLite ファイルを指定して解析できるモードがある。  

この条件を満たす実装を行えば、元記事のシステムを他AIが「ほぼ完全に再現した」と言ってよい。  

---

もし次のステップで、  

- この仕様書をベースに「GitHub Actions のワークフローだけ先にAIに書かせるプロンプト」  
- あるいは「ネットネットバリュー用の SQLite スキーマとサンプルクエリ」  

などを切り出したい場合は、その部分だけ細かいテンプレートも用意できる。  

結論から述べると、この仕様書はAIによる株式分析システムを「他のAIでもほぼ完全に再現できる」レベルで構造化・網羅した実装ドキュメントになっています。記事全体を読み解いた内容が体系的にMarkdownフォーマットで整理されており、「他AIが完璧に再現できる仕様書.md」として、そのまま再実装や後続開発、引き継ぎ用途に使える内容です。[^2][^4]  

***  

# 日本株 AI 解析システム 実装仕様書（他AI再現用）  

本仕様書は、kawasin73氏の「AI に作らせる株式分析システム」記事をもとに、他AIでも同等レベルのシステム構築を目指すために作成されています。  

***  

## 1. システム全体像  

- 日次で日本上場銘柄のXBRL報告・株価データを自動収集・解析  
- 解析・ランキング機能（ネットネットバリュー、オニール法、天井検出）  
- すべてのデータ/ロジックは単一SQLiteファイルで一元管理  
- 静的HTML/SPA（GitHub Pages）でフロント配信、メール通知兼ログ（GitHub Issues）  

***  

## 2. 非機能要件・運用方針  

- 個人運用を主軸に保守・コスト最小、サーバーレス/フルマネージド設計  
- 24時間稼働サーバーや追加サービス不要、すべて既存クラウド基盤に集約  
- AWS S3（データ保存）、GitHub Actions（バッチ）、GitHub Pages（配信）、GitHub Issues（通知）  

***  

## 3. データ構造と保存戦略  

- XBRL財務データ/株価データは単回収集後S3に永続保存（年単位tar.gz、Glacier Deep Archive）  
- 解析対象は常に最新版SQLiteをS3＆バージョニング管理、必要時gzip圧縮で利用  
- 生データと解析DBのダウンロード・同期も自動化  

***  

## 4. データスキーマ例（SQLite）  

- 企業マスタ（証券コード、EDINETコード、銘柄名など）  
- 財務データ（決算ごと資産・負債・現金等XBRL抽出系）  
- 日次株価データ（始値/高値/安値/終値/出来高）  
- 指標キャッシュ（ネットネット/PBR/リラティブストレングス等）  

***  

## 5. 代表的な解析ロジック  

### ネットネットバリュー指標  

- 指標式：即時現金化可能資産−総負債÷時価総額（パラメータはUIで調整可）  
- 1未満を割安と判定、値が小さい順にランキング  
- 日次、決算単位で推移チャート化（lightweight-charts）  


### オニール成長株法  

- EPS成長率・リラティブストレングス等スクリーニング  
- 一覧と詳細（SPA内でルーティング、決算発表日・シグナル区間色分け）  


### マーケット天井検出  

- 分配日（distribution day）カウント\&閾値越えで注意ゾーン検出  
- パラメータはUI調整可能、背景色で危険ゾーン明示  

***  

## 6. 自動化バッチ処理（GitHub Actions）  

- S3からDB取得→差分データDL→パース＆DB更新→S3上書き→条件検出→GitHub Issueメール通知  
- 欠損対策として「DB最新日以降のみ再取得」、アップロードは最後のみ  
- presigned URL発行で解析ページ共有  

***  

## 7. フロントエンド構成  

- GitHub PagesにSPA形式で配信、HTML一枚にCSS/JS同梱  
- sqlite-wasm＆lightweight-chartsでブラウザ内処理/描画  
- DBはpresigned URLまたはローカル選択で利用可能  

***  

## 8. 通知・ログ  

- GitHub Issue自動作成によるイベント通知（メール転送含む）、運用者確認・ログにも二次活用  
- Slack/外部連携は行わず、GitHubのみで閉じる設計  

***  

## 9. AI/人の役割分担  

- 人間はアーキテクチャ・根幹設計と品質確認  
- AIはパーサ・バッチ・HTML/JS実装部分（95%程度を自動生成）  

***  

## 10. 再現チェックリスト  

- すべてSQLite単一DB管理  
- GitHub Actions日次更新で自動運用  
- 生データはS3長期保存、圧縮も対応  
- UI・通知も元記事同等ならOK  

***  
