
# AI株式分析システム 完全仕様書

## プロジェクト概要

日本の上場銘柄を自動解析するシステム。AI（主にClaude）に95%以上のコードを書かせて構築。個人運用を前提とし、メンテナンスコストをゼロに近づけることを最優先。

## 設計思想

### 1. 完全自動化
- 毎日のデータダウンロード・解析を自動実行
- 条件を満たす銘柄発見時は自動通知
- 人的介入は売買判断のみ

### 2. メンテナンスコスト最小化
- 24時間稼働サーバー不要
- フルマネージドサービスのみ使用
- 利用サービス数を最小限に
- 一度作ったら放置で動き続ける堅牢性

## システムアーキテクチャ

### 全体構成
```
[GitHub Actions] ← 日次バッチ実行
    ↓
[S3] ← SQLiteファイル + 生データ保存
    ↓
[GitHub Pages] ← 静的HTML解析ページ配信
    ↓
[ブラウザ] ← SQLite-wasmで動的解析
```

### 使用インフラ（2つのみ）
1. AWS S3
2. GitHubリポジトリ

## データ管理戦略

### SQLiteファイル中心設計
- **すべてのデータをSQLiteファイルで管理**
- ローカル解析、ブラウザ解析、バッチ処理すべてに対応
- S3で最新版を一元管理
- バージョニング有効化で履歴保持

### データフロー
1. GitHub ActionsがS3から最新SQLiteをダウンロード
2. 新規データを追記
3. S3に上書きアップロード

## 日次バッチ処理（GitHub Actions）

### 実行タイミング
```yaml
on:
  schedule:
    - cron: "0 9 * * *"  # 毎日18:00 JST (9:00 UTC)
  workflow_dispatch:  # 手動実行も可能
```

### 処理フロー
1. S3から最新SQLiteファイルをダウンロード
2. 当日更新された株価・XBRLファイルをダウンロード
3. ダウンロードしたファイルをパース・正規化してSQLiteに追記
4. 生データファイルを`aws s3 sync`でS3にアップロード
5. 最新SQLiteファイルをS3に上書き保存
6. データ解析・必要な通知実行
7. ダウンロードリンクをSummary UIに表示

### 欠損データ対策
- SQLiteファイル内の最新日付以降のデータのみ取得
- SQLiteアップロードは最後に実行（CI失敗時の保護）

## データストレージ（S3）

### 生データ管理
- XBRLファイル等をすべて永久保存
- 年毎にtar.gz圧縮
- Amazon S3 Glacier Deep Archiveで保管コスト削減
- EDINETから再ダウンロード回避（過去10年分のみ提供、1秒/1ファイル制限）

### SQLiteファイル管理
- バージョニング有効化
- 数百MBのためgzip版も配置
- Presigned URL生成（7日間有効期限）
- GitHub Actions SummaryのWebUIからダウンロード可能

**GitHub Artifacts不採用理由**: ダウンロード速度が1MB/sで遅すぎる

## 解析ページ実装

### 技術スタック
- **単一HTMLファイル構成**（CSS/JavaScript込み）
- ビルド不要で取り回し良好
- Gemini Canvasモードで生成
- レスポンシブ対応（スマホ可）

### 使用ライブラリ
- **sqlite-wasm**: ブラウザ上でSQLクエリ実行
- **lightweight-charts**: 大量データでもヌルヌル動作するチャート描画

### データ読み込み方式
1. URL内のクエリパラメータにS3 presigned URLを含む
2. ページ読み込み時にJavaScriptで自動ダウンロード
3. ブラウザキャッシュに保存
4. ローカルDBファイルの指定も可能

### 配信方法
- **GitHub Pages**で静的配信
- 認証不要で友人に共有可能
- 1つのURLでデータベース込みの完全な解析環境を提供

## 通知システム（GitHub Issues）

### 設計
- メール配信サービス不要
- Gmail認証設定不要
- **GitHub Issueを通知として活用**

### フロー
1. 日次解析で新規銘柄発見
2. GitHub Actions新しいIssueを作成
3. リポジトリオーナーにメール自動送信
4. メール本文にIssue内容表示
5. 不要な銘柄はIssue closeで理由記録

## 実装済み解析機能

### 1. ネットネットバリュー株ランキング

**指標定義**:
```
ネットネットバリューPBR = 時価総額 / (即時現金化可能資産 - 総負債)
```

**機能**:
- カスタマイズ可能な即時現金化資産項目
- 独自割引率設定
- PBR過去推移チャート表示
- 最近の割安化判別

**ページ構成**:
- ランキング一覧
- 個別銘柄詳細（PBRチャートタブ）

### 2. オニールの成長株発掘ランキング

**出典**: 「オニールの成長株発掘法」

**スクリーニング指標**:
- EPSの成長率
- リラティブストレングス（株価推移指標）

**可視化要素**:
- 決算発表日マーカー
- シグナル点灯区間の背景色変更

**ページ構成**:
- ランキング一覧
- 銘柄詳細ページ
- **完全SPA構成**（1枚のHTMLで実装）

### 3. オニールのマーケット天井検出

**出典**: 「オニールの成長株発掘法」

**機能**:
- 上昇トレンドから下落転換前の「分配日」カウント
- マーケット下落予測

**可視化要素**:
- シグナル発生日マーカー
- 注意期間の背景色変更

**課題**:
- パラメータチューニング困難
- ベイズ最適化試行も不成功

## データソース

### XBRL（有価証券報告書）
- **提供元**: 金融庁EDINET
- **フォーマット**: XBRL
- **取得範囲**: 過去10年分
- **ダウンロード制限**: 1秒/1ファイル（DoS回避）
- **パーサー**: 2年前に自作済み（今回システムで活用）

### 株価データ
- 日次更新
- SQLiteに正規化して格納

## 開発プロセス

### AI活用率
- **95%以上のコードをAIが生成**
- 使用AI: Claude Code Max プラン（2024年8月契約）
- Gemini Canvas: 解析ページUI生成

### 開発期間
- **3ヶ月**（休日・仕事終わりのみ）

### 人間の役割
- システムアーキテクチャ設計
- 効率的なプログラム構造の決定
- AI生成コードのレビュー・修正指示

## 技術的意思決定

### なぜGitHub Actions？
- ChatGPTの提案
- cronサポート
- サーバーレス実行環境
- 無料枠で十分

### なぜSQLite？
- 単一ファイルで管理容易
- ブラウザ上でも実行可能（sqlite-wasm）
- バージョン管理容易
- トランザクション対応
- ローカル分析も可能

### なぜlightweight-charts？
- 他ライブラリは大量データでカクつく
- ヌルヌル動作
- マーカー大量描画も高速

### なぜS3？
- フルマネージド
- 低コスト
- Presigned URL生成可能
- バージョニング対応

## セキュリティ・プライバシー

- 解析ページは認証なし（共有容易性優先）
- Presigned URLは7日間有効（流出被害限定）
- プライベートリポジトリ推奨
- Issue通知はリポジトリオーナーのみ

## コスト構造

- **GitHub**: 無料（Actions, Pages, リポジトリ）
- **AWS S3**: 
  - 標準ストレージ: 数百MB〜数GB
  - Glacier Deep Archive: 年次アーカイブ
  - 転送料: 月次で最小限
- **合計**: 月数百円程度と推定

## 今後の拡張性

### 実装予定（別記事で解説予定）
- AI使い方詳細
- XBRLパース手法解説
- パラメータ最適化改善

### 改善余地
- 効率的なプログラム構造（人間の役割）
- アーキテクチャ設計（人間の役割）
- パラメータチューニング自動化

## 運用結果

### システム安定性
- 一度構築後は放置で稼働
- 自動化により毎日確実に実行

### 投資成績
- **2024年は日経平均に負け**
- インデックス投資の優位性を実感
- システム自体は成功、投資手法は改善余地あり

## 再現手順

### 1. リポジトリ準備
```bash
git init stock-analysis
cd stock-analysis
```

### 2. GitHub Actions設定
- `.github/workflows/daily-update.yml`作成
- cron設定
- S3認証情報をSecrets登録

### 3. S3バケット作成
- バケット作成
- バージョニング有効化
- Glacier Deep Archiveライフサイクル設定

### 4. 初期データ取得スクリプト
- EDINET XBRLダウンロードスクリプト
- 株価取得スクリプト
- SQLite初期化スクリプト

### 5. パーサー実装
- XBRLパーサー（2年前実装済み）
- 株価データパーサー
- SQLite書き込みロジック

### 6. 解析ページ作成
- Gemini CanvasでUI生成
- sqlite-wasm統合
- lightweight-charts統合
- GitHub Pagesデプロイ

### 7. 通知システム
- GitHub Issue作成ロジック
- 条件判定ロジック

## まとめ

このシステムは以下を実現：

1. **完全自動化**: 人的介入最小限
2. **低コスト**: 月数百円程度
3. **メンテナンスフリー**: 一度構築すれば放置可能
4. **高い共有性**: 1URLで完結
5. **高速開発**: AIで3ヶ月で構築

**キーポイント**: SQLite中心設計により、ローカル・クラウド・ブラウザすべてで同じデータを扱える柔軟性を実現。

---
