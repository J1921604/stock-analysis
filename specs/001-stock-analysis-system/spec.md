# æ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ  å®Œå…¨ä»•æ§˜æ›¸

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0
**ä½œæˆæ—¥**: 2025å¹´11æœˆ22æ—¥
**æœ€çµ‚æ›´æ–°**: 2025å¹´11æœˆ22æ—¥
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ä»•æ§˜ç­–å®šå®Œäº†
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: stock-analysis

---

## ğŸ“‹ ç›®æ¬¡

1. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
2. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ)
3. [ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«](#ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«)
4. [æ©Ÿèƒ½ä»•æ§˜](#æ©Ÿèƒ½ä»•æ§˜)
5. [æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯](#æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯)
6. [ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æˆ¦ç•¥](#ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æˆ¦ç•¥)
7. [ãƒãƒƒãƒå‡¦ç†ä»•æ§˜](#ãƒãƒƒãƒå‡¦ç†ä»•æ§˜)
8. [è§£æãƒšãƒ¼ã‚¸ä»•æ§˜](#è§£æãƒšãƒ¼ã‚¸ä»•æ§˜)
9. [é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ](#é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ )
10. [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ](#ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ)
11. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)
12. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶)

---

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„

æ—¥æœ¬ã®ä¸Šå ´éŠ˜æŸ„ã‚’å¯¾è±¡ã¨ã—ãŸã€å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸæ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚AIï¼ˆä¸»ã«Claudeï¼‰ã‚’æ´»ç”¨ã—ã€95%ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚’AIãŒç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€å€‹äººé–‹ç™ºã§ã‚‚é‹ç”¨å¯èƒ½ãªå …ç‰¢ãªã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹ã€‚

### è¨­è¨ˆæ€æƒ³

```mermaid
flowchart TB
    subgraph philosophy["è¨­è¨ˆæ€æƒ³"]
        A[å®Œå…¨è‡ªå‹•åŒ–]
        B[ãƒ¡ãƒ³ãƒ†ã‚³ã‚¹ãƒˆæœ€å°åŒ–]
        C[ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰]
        D[è¦ç´ å‰Šæ¸›ã«ã‚ˆã‚‹å …ç‰¢æ€§]
    end
    
    subgraph implementation["å®Ÿè£…æ–¹é‡"]
        E[24hç¨¼åƒã‚µãƒ¼ãƒãƒ¼ä¸è¦]
        F[GitHubä¸­å¿ƒã®ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ]
        G[SQLiteå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«DB]
        H[é™çš„HTMLé…ä¿¡]
    end
    
    A --> E
    B --> E
    C --> F
    D --> G
    
    style philosophy fill:#e1bee7
    style implementation fill:#c8e6c9
```

### ä¸»è¦æ©Ÿèƒ½

1. **ãƒãƒƒãƒˆãƒãƒƒãƒˆãƒãƒªãƒ¥ãƒ¼æ ªãƒ©ãƒ³ã‚­ãƒ³ã‚°**
   - å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£ã‹ã‚‰ç·è² å‚µã‚’å¼•ã„ãŸç‹¬è‡ªPBRç®—å‡º
   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼ˆè³‡ç”£é …ç›®é¸æŠã€å‰²å¼•ç‡è¨­å®šï¼‰
   - éå»PBRæ¨ç§»ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º

2. **ã‚ªãƒ‹ãƒ¼ãƒ«æˆé•·æ ªç™ºæ˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°**
   - EPSæˆé•·ç‡ã«ã‚ˆã‚‹ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
   - ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹æŒ‡æ¨™
   - æ±ºç®—ç™ºè¡¨æ—¥ãƒãƒ¼ã‚«ãƒ¼è¡¨ç¤º
   - ã‚·ã‚°ãƒŠãƒ«åŒºé–“ã®èƒŒæ™¯è‰²å¯è¦–åŒ–

3. **ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡ºãƒ„ãƒ¼ãƒ«**
   - åˆ†é…æ—¥ã‚«ã‚¦ãƒ³ãƒˆã«ã‚ˆã‚‹å¤©äº•äºˆæ¸¬
   - æ³¨æ„æœŸé–“ã®èƒŒæ™¯è‰²è¡¨ç¤º
   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´æ©Ÿèƒ½

### ã‚·ã‚¹ãƒ†ãƒ ç‰¹æ€§

| ç‰¹æ€§ | èª¬æ˜ | å®Ÿç¾æ–¹æ³• |
|------|------|----------|
| å®Œå…¨è‡ªå‹•åŒ– | äººçš„ä»‹å…¥ã‚’å£²è²·åˆ¤æ–­ã®ã¿ã«é™å®š | GitHub Actionsæ—¥æ¬¡ãƒãƒƒãƒ |
| ã‚¼ãƒ­é‹ç”¨ã‚³ã‚¹ãƒˆ | ã‚µãƒ¼ãƒãƒ¼ç®¡ç†ãƒ»ä¿å®ˆä½œæ¥­ä¸è¦ | ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨ |
| ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ | éå»10å¹´è¶…ã®ãƒ‡ãƒ¼ã‚¿ä¿æŒ | GitHub Releases + LFS |
| é«˜é€Ÿé…ä¿¡ | ãƒ–ãƒ©ã‚¦ã‚¶å†…è§£æã§å³åº§ã«è¡¨ç¤º | sqlite-wasm + lightweight-charts |
| ã‚»ã‚­ãƒ¥ã‚¢ | èªè¨¼ãªã—ã§ã‚‚æ©Ÿå¯†æƒ…å ±ä¿è­· | presigned URLï¼ˆ7æ—¥æœ‰åŠ¹ï¼‰ |

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ§‹æˆ

```mermaid
flowchart TB
    subgraph github["GitHub ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ "]
        direction TB
        A[GitHub Actions<br/>æ—¥æ¬¡ãƒãƒƒãƒ]
        B[GitHub Releases<br/>XBRLã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]
        C[GitHub LFS<br/>SQLiteãƒ•ã‚¡ã‚¤ãƒ«]
        D[GitHub Pages<br/>é™çš„HTMLé…ä¿¡]
        E[GitHub Issues<br/>é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ]
    end
    
    subgraph data["ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼"]
        direction LR
        F[EDINET<br/>XBRLå–å¾—]
        G[æ ªä¾¡API<br/>æ—¥æ¬¡å–å¾—]
        H[ãƒ‘ãƒ¼ã‚¹ãƒ»æ­£è¦åŒ–]
        I[SQLiteæ›´æ–°]
    end
    
    subgraph user["ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“"]
        direction TB
        J[ãƒ–ãƒ©ã‚¦ã‚¶ã‚¢ã‚¯ã‚»ã‚¹]
        K[SQLiteè‡ªå‹•DL]
        L[ãƒ–ãƒ©ã‚¦ã‚¶å†…è§£æ]
        M[ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º]
    end
    
    F --> H
    G --> H
    H --> I
    A --> I
    I --> C
    C --> K
    D --> J
    J --> K
    K --> L
    L --> M
    A --> E
    I --> B
    
    style github fill:#fff9c4
    style data fill:#c8e6c9
    style user fill:#e3f2fd
```

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ

```mermaid
flowchart LR
    subgraph fetch["ãƒ‡ãƒ¼ã‚¿å–å¾—"]
        A1[EDINET Fetcher]
        A2[Stock Price Fetcher]
    end
    
    subgraph parse["ãƒ‡ãƒ¼ã‚¿å‡¦ç†"]
        B1[XBRL Parser]
        B2[Price Normalizer]
    end
    
    subgraph storage["ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"]
        C1[SQLite Manager]
        C2[GitHub LFS Handler]
        C3[Releases Manager]
    end
    
    subgraph analysis["è§£æã‚¨ãƒ³ã‚¸ãƒ³"]
        D1[NetNet Calculator]
        D2[ONeil Screener]
        D3[Market Top Detector]
    end
    
    subgraph ui["ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰"]
        E1[Static HTML/JS/CSS]
        E2[sqlite-wasm]
        E3[lightweight-charts]
    end
    
    A1 --> B1
    A2 --> B2
    B1 --> C1
    B2 --> C1
    C1 --> C2
    C1 --> D1
    C1 --> D2
    C1 --> D3
    C2 --> E2
    E1 --> E2
    E2 --> E3
    
    style fetch fill:#ffccbc
    style parse fill:#c5cae9
    style storage fill:#b2dfdb
    style analysis fill:#f0f4c3
    style ui fill:#e1bee7
```

---

## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

### SQLiteã‚¹ã‚­ãƒ¼ãƒ

**ãƒ‡ãƒ¼ã‚¿å‹ã®é¸æŠåŸºæº–**:
```yaml
data_types:
  TEXT:
    use_case: "ä¼æ¥­IDã€éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã€åå‰ã€URL"
    reason: "å¯å¤‰é•·æ–‡å­—åˆ—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹ç‡è‰¯å¥½"
    example: "company_id TEXT PRIMARY KEY"
  
  INTEGER:
    use_case: "IDã€å‡ºæ¥é«˜ã€æ ªæ•°"
    reason: "æ•´æ•°å€¤ã€æ¼”ç®—é«˜é€Ÿã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åŠ¹ç‡è‰¯å¥½"
    example: "volume INTEGER"
  
  REAL:
    use_case: "æ ªä¾¡ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€ã‚¹ã‚³ã‚¢"
    reason: "æµ®å‹•å°æ•°ç‚¹æ•°ã€ç²¾åº¦ååˆ†"
    example: "close REAL NOT NULL"
  
  DATE:
    use_case: "æ—¥ä»˜"
    reason: "ISO 8601å½¢å¼ï¼ˆYYYY-MM-DDï¼‰ã€ç¯„å›²æ¤œç´¢é«˜é€Ÿ"
    example: "date DATE NOT NULL"
  
  DATETIME:
    use_case: "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—"
    reason: "ISO 8601å½¢å¼ï¼ˆYYYY-MM-DD HH:MM:SSï¼‰"
    example: "created_at DATETIME DEFAULT CURRENT_TIMESTAMP"
  
  BOOLEAN:
    use_case: "ãƒ•ãƒ©ã‚°"
    reason: "0/1ã§ä¿å­˜ï¼ˆINTEGERï¼‰ã€å¯èª­æ€§å‘ä¸Š"
    example: "imported BOOLEAN DEFAULT 0"
  
  JSON:
    use_case: "å¯å¤‰æ§‹é€ ãƒ‡ãƒ¼ã‚¿"
    reason: "æŸ”è»Ÿæ€§ã€ã‚¯ã‚¨ãƒªå¯èƒ½ï¼ˆjson_extractï¼‰"
    example: "payload JSON"
```

#### 1. ä¼æ¥­ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«

```sql
CREATE TABLE IF NOT EXISTS companies (
  company_id TEXT PRIMARY KEY,      -- EDINETã‚³ãƒ¼ãƒ‰ã¾ãŸã¯è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰
  ticker TEXT UNIQUE NOT NULL,      -- è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ï¼ˆ4æ¡ï¼‰
  name TEXT NOT NULL,                -- ä¼æ¥­å
  sector TEXT,                       -- ã‚»ã‚¯ã‚¿ãƒ¼
  industry TEXT,                     -- æ¥­ç¨®
  market TEXT,                       -- å¸‚å ´ï¼ˆæ±è¨¼ãƒ—ãƒ©ã‚¤ãƒ ã€ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãªã©ï¼‰
  listing_date DATE,                 -- ä¸Šå ´æ—¥
  last_update DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_companies_ticker ON companies(ticker);
CREATE INDEX idx_companies_sector ON companies(sector);
```

#### 2. æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«

```sql
-- æ—¥æ¬¡æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ãƒ¼ãƒ–ãƒ«
-- èª¿æ•´å¾Œçµ‚å€¤ã‚’å«ã‚ã€æ ªå¼åˆ†å‰²ã‚„é…å½“ã®å½±éŸ¿ã‚’æ­£ç¢ºã«åæ˜ 
CREATE TABLE IF NOT EXISTS stock_prices (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  company_id TEXT NOT NULL,           -- ä¼æ¥­IDã¸ã®å¤–éƒ¨ã‚­ãƒ¼
  date DATE NOT NULL,                 -- æ ªä¾¡æ—¥ä»˜ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
  open REAL,                          -- å§‹å€¤ï¼ˆå††ï¼‰
  high REAL,                          -- é«˜å€¤ï¼ˆå††ï¼‰
  low REAL,                           -- å®‰å€¤ï¼ˆå††ï¼‰
  close REAL NOT NULL,                -- çµ‚å€¤ï¼ˆå††ã€å¿…é ˆï¼‰
  adj_close REAL,                     -- èª¿æ•´å¾Œçµ‚å€¤ï¼ˆæ ªå¼åˆ†å‰²ãƒ»é…å½“èª¿æ•´æ¸ˆã¿ï¼‰
  volume INTEGER,                     -- å‡ºæ¥é«˜ï¼ˆæ ªæ•°ï¼‰
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,  -- ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚
  FOREIGN KEY (company_id) REFERENCES companies(company_id),
  UNIQUE(company_id, date)            -- åŒä¸€ä¼æ¥­ãƒ»åŒä¸€æ—¥ä»˜ã®é‡è¤‡é˜²æ­¢
);

-- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
-- ä¼æ¥­IDã¨æ—¥ä»˜ã®è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé™é †ï¼‰ã§æœ€æ–°æ ªä¾¡ã®é«˜é€Ÿå–å¾—
CREATE INDEX idx_stock_prices_company_date ON stock_prices(company_id, date DESC);

-- å…¨ä¼æ¥­ã®ç‰¹å®šæ—¥ã®æ ªä¾¡ã‚’é«˜é€Ÿå–å¾—ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_stock_prices_date ON stock_prices(date DESC);
```

**è¨­è¨ˆæ„å›³**:
- `adj_close`ã‚’ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºæ™‚ã®æ ªä¾¡é€£ç¶šæ€§ã‚’ç¢ºä¿
- `UNIQUE(company_id, date)`åˆ¶ç´„ã«ã‚ˆã‚Šã€é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥ã‚’é˜²æ­¢
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚Šã€ã€Œç‰¹å®šä¼æ¥­ã®éå»1å¹´ã®æ ªä¾¡ã€ã®ã‚ˆã†ãªã‚¯ã‚¨ãƒªã‚’100msä»¥ä¸‹ã§å®Ÿè¡Œå¯èƒ½

#### 3. XBRLç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«

```sql
CREATE TABLE IF NOT EXISTS xbrl_files (
  file_id TEXT PRIMARY KEY,          -- EDINETãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID
  company_id TEXT NOT NULL,
  filing_date DATE NOT NULL,         -- æå‡ºæ—¥
  fiscal_year INTEGER,               -- æ±ºç®—å¹´åº¦
  fiscal_period TEXT,                -- æ±ºç®—æœŸï¼ˆQ1/Q2/Q3/Annualï¼‰
  report_type TEXT,                  -- å ±å‘Šæ›¸ç¨®åˆ¥ï¼ˆæœ‰å ±/å››åŠæœŸå ±å‘Šæ›¸ï¼‰
  storage_path TEXT,                 -- GitHub Releasesä¸Šã®ãƒ‘ã‚¹
  file_size INTEGER,                 -- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
  imported BOOLEAN DEFAULT 0,        -- ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ•ãƒ©ã‚°
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (company_id) REFERENCES companies(company_id)
);

CREATE INDEX idx_xbrl_files_company ON xbrl_files(company_id, filing_date DESC);
CREATE INDEX idx_xbrl_files_imported ON xbrl_files(imported);
```

#### 4. è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«

```sql
-- è²¡å‹™ãƒ‡ãƒ¼ã‚¿ï¼ˆè²¸å€Ÿå¯¾ç…§è¡¨ãƒ»æç›Šè¨ˆç®—æ›¸ï¼‰ä¿å­˜ãƒ†ãƒ¼ãƒ–ãƒ«
-- XBRLãƒ‘ãƒ¼ã‚¹çµæœã‚’æ­£è¦åŒ–ã—ã¦æ ¼ç´
CREATE TABLE IF NOT EXISTS financials (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  company_id TEXT NOT NULL,           -- ä¼æ¥­IDã¸ã®å¤–éƒ¨ã‚­ãƒ¼
  report_date DATE NOT NULL,          -- æ±ºç®—æ—¥ï¼ˆå ±å‘ŠåŸºæº–æ—¥ï¼‰
  fiscal_year INTEGER NOT NULL,       -- æ±ºç®—å¹´åº¦ï¼ˆä¾‹: 2024ï¼‰
  fiscal_period TEXT NOT NULL,        -- æ±ºç®—æœŸï¼ˆ'Q1'/'Q2'/'Q3'/'Annual'ï¼‰
  
  -- è³‡ç”£é …ç›®ï¼ˆå˜ä½: ç™¾ä¸‡å††ï¼‰
  total_assets REAL,                  -- ç·è³‡ç”£
  cash_and_deposits REAL,             -- ç¾é‡‘åŠã³é é‡‘ï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆè¨ˆç®—ã«ä½¿ç”¨ï¼‰
  marketable_securities REAL,         -- æœ‰ä¾¡è¨¼åˆ¸ï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆè¨ˆç®—ã«ä½¿ç”¨ï¼‰
  accounts_receivable REAL,           -- å£²æ›é‡‘ï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆè¨ˆç®—ã«ä½¿ç”¨ï¼‰
  inventory REAL,                     -- æ£šå¸è³‡ç”£ï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆè¨ˆç®—ã«ä½¿ç”¨ï¼‰
  tangible_assets REAL,               -- æœ‰å½¢å›ºå®šè³‡ç”£
  
  -- è² å‚µé …ç›®ï¼ˆå˜ä½: ç™¾ä¸‡å††ï¼‰
  total_liabilities REAL,             -- ç·è² å‚µï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆè¨ˆç®—ã«ä½¿ç”¨ï¼‰
  short_term_liabilities REAL,        -- æµå‹•è² å‚µ
  long_term_liabilities REAL,         -- å›ºå®šè² å‚µ
  
  -- ç´”è³‡ç”£ï¼ˆå˜ä½: ç™¾ä¸‡å††ï¼‰
  shareholders_equity REAL,           -- æ ªä¸»è³‡æœ¬
  
  -- æç›Šé …ç›®ï¼ˆå˜ä½: ç™¾ä¸‡å††ï¼‰
  revenue REAL,                       -- å£²ä¸Šé«˜
  operating_income REAL,              -- å–¶æ¥­åˆ©ç›Š
  ordinary_income REAL,               -- çµŒå¸¸åˆ©ç›Š
  net_income REAL,                    -- å½“æœŸç´”åˆ©ç›Šï¼ˆEPSè¨ˆç®—ã«ä½¿ç”¨ï¼‰
  
  -- 1æ ªã‚ãŸã‚ŠæŒ‡æ¨™ï¼ˆå˜ä½: å††ï¼‰
  eps REAL,                           -- EPSï¼ˆã‚ªãƒ‹ãƒ¼ãƒ«æˆé•·æ ªã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ï¼‰
  bps REAL,                           -- BPS
  
  -- æ ªæ•°ï¼ˆå˜ä½: æ ªï¼‰
  shares_outstanding BIGINT,          -- ç™ºè¡Œæ¸ˆæ ªå¼æ•°ï¼ˆæ™‚ä¾¡ç·é¡è¨ˆç®—ã«ä½¿ç”¨ï¼‰
  
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,  -- ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚
  FOREIGN KEY (company_id) REFERENCES companies(company_id),
  UNIQUE(company_id, report_date, fiscal_period)  -- åŒä¸€ä¼æ¥­ãƒ»åŒä¸€æ±ºç®—æ—¥ãƒ»åŒä¸€æœŸã®é‡è¤‡é˜²æ­¢
);

-- ä¼æ¥­IDãƒ»æ±ºç®—æ—¥ã®è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé™é †ï¼‰ã§æœ€æ–°è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®é«˜é€Ÿå–å¾—
CREATE INDEX idx_financials_company_date ON financials(company_id, report_date DESC);
```

**è¨­è¨ˆæ„å›³**:
- `fiscal_period`ã§å››åŠæœŸãƒ»å¹´æ¬¡ã‚’åŒºåˆ¥ã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãŒå¯èƒ½
- ãƒãƒƒãƒˆãƒãƒƒãƒˆè¨ˆç®—ã«å¿…è¦ãª4ã¤ã®è³‡ç”£é …ç›®ï¼ˆç¾é‡‘ã€æœ‰ä¾¡è¨¼åˆ¸ã€å£²æ›é‡‘ã€æ£šå¸è³‡ç”£ï¼‰ã‚’æ˜ç¤º
- `UNIQUE(company_id, report_date, fiscal_period)`åˆ¶ç´„ã«ã‚ˆã‚Šã€ä¿®æ­£å ±å‘Šæ›¸ã®é‡è¤‡æŒ¿å…¥ã‚’é˜²æ­¢
- å…¨ã¦ã®é‡‘é¡é …ç›®ã‚’ç™¾ä¸‡å††å˜ä½ã«çµ±ä¸€ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ãƒŸã‚¹ã‚’é˜²æ­¢

**ãƒ‡ãƒ¼ã‚¿ä¾‹**:
```sql
-- æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ã®2024å¹´3æœˆæœŸï¼ˆå¹´æ¬¡æ±ºç®—ï¼‰
INSERT INTO financials VALUES (
  1,                          -- id
  '9501',                     -- company_id
  '2024-03-31',               -- report_date
  2024,                       -- fiscal_year
  'Annual',                   -- fiscal_period
  71321000,                   -- total_assets (ç™¾ä¸‡å††)
  5432100,                    -- cash_and_deposits
  3210500,                    -- marketable_securities
  4567800,                    -- accounts_receivable
  2345600,                    -- inventory
  15678900,                   -- tangible_assets
  45678900,                   -- total_liabilities
  12345600,                   -- short_term_liabilities
  33333300,                   -- long_term_liabilities
  25642100,                   -- shareholders_equity
  37154300,                   -- revenue
  4567800,                    -- operating_income
  5123400,                    -- ordinary_income
  3678900,                    -- net_income
  1234.56,                    -- eps
  8765.43,                    -- bps
  2978234567,                 -- shares_outstanding
  '2024-06-20 10:30:00'       -- created_at
);
```

#### 5. è§£æçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«

```sql
CREATE TABLE IF NOT EXISTS analysis_cache (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  company_id TEXT NOT NULL,
  analysis_date DATE NOT NULL,
  analysis_type TEXT NOT NULL,       -- 'netnet', 'oneil', 'market_top'
  
  -- ãƒãƒƒãƒˆãƒãƒƒãƒˆãƒãƒªãƒ¥ãƒ¼æŒ‡æ¨™
  net_net_assets REAL,               -- ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£
  net_net_pbr REAL,                  -- ãƒãƒƒãƒˆãƒãƒƒãƒˆPBR
  
  -- ã‚ªãƒ‹ãƒ¼ãƒ«æŒ‡æ¨™
  eps_growth_3y REAL,                -- EPSæˆé•·ç‡ï¼ˆ3å¹´ï¼‰
  eps_growth_5y REAL,                -- EPSæˆé•·ç‡ï¼ˆ5å¹´ï¼‰
  relative_strength REAL,            -- ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹
  
  -- å¸‚å ´æŒ‡æ¨™
  market_cap REAL,                   -- æ™‚ä¾¡ç·é¡
  
  score REAL,                        -- ç·åˆã‚¹ã‚³ã‚¢
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (company_id) REFERENCES companies(company_id),
  UNIQUE(company_id, analysis_date, analysis_type)
);

CREATE INDEX idx_analysis_cache_type_score ON analysis_cache(analysis_type, score DESC);
CREATE INDEX idx_analysis_cache_date ON analysis_cache(analysis_date DESC);
```

#### 6. é€šçŸ¥å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«

```sql
CREATE TABLE IF NOT EXISTS notifications (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  company_id TEXT NOT NULL,
  notification_date DATE NOT NULL,
  notification_type TEXT NOT NULL,   -- 'netnet_new', 'oneil_new', 'market_alert'
  issue_number INTEGER,              -- GitHub Issueç•ªå·
  issue_url TEXT,                    -- GitHub Issue URL
  payload JSON,                      -- é€šçŸ¥è©³ç´°ãƒ‡ãƒ¼ã‚¿
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (company_id) REFERENCES companies(company_id)
);

CREATE INDEX idx_notifications_date ON notifications(notification_date DESC);
CREATE INDEX idx_notifications_type ON notifications(notification_type);
```

### ãƒ‡ãƒ¼ã‚¿é–¢é€£å›³

```mermaid
erDiagram
    companies ||--o{ stock_prices : has
    companies ||--o{ xbrl_files : has
    companies ||--o{ financials : has
    companies ||--o{ analysis_cache : has
    companies ||--o{ notifications : has
    
    companies {
        TEXT company_id PK
        TEXT ticker
        TEXT name
        TEXT sector
        TEXT industry
        TEXT market
    }
    
    stock_prices {
        INTEGER id PK
        TEXT company_id FK
        DATE date
        REAL close
        REAL adj_close
        INTEGER volume
    }
    
    xbrl_files {
        TEXT file_id PK
        TEXT company_id FK
        DATE filing_date
        INTEGER fiscal_year
        TEXT fiscal_period
        TEXT storage_path
    }
    
    financials {
        INTEGER id PK
        TEXT company_id FK
        DATE report_date
        REAL total_assets
        REAL total_liabilities
        REAL revenue
        REAL net_income
    }
    
    analysis_cache {
        INTEGER id PK
        TEXT company_id FK
        DATE analysis_date
        TEXT analysis_type
        REAL score
    }
```

---

## æ©Ÿèƒ½ä»•æ§˜

### 1. ãƒãƒƒãƒˆãƒãƒƒãƒˆãƒãƒªãƒ¥ãƒ¼æ ªãƒ©ãƒ³ã‚­ãƒ³ã‚°

#### 1.1 æŒ‡æ¨™å®šç¾©

**ãƒãƒƒãƒˆãƒãƒƒãƒˆãƒãƒªãƒ¥ãƒ¼PBR**:

$$
\text{NetNetPBR} = \frac{\text{æ™‚ä¾¡ç·é¡}}{\text{å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£} - \text{ç·è² å‚µ}}
$$

**å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£ã®è¨ˆç®—**:

$$
\begin{aligned}
\text{å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£} &= (\text{ç¾é‡‘åŠã³é é‡‘} \times 100\%) \\
&\quad + (\text{æœ‰ä¾¡è¨¼åˆ¸} \times \text{å‰²å¼•ç‡}_A) \\
&\quad + (\text{å£²æ›é‡‘} \times \text{å‰²å¼•ç‡}_B) \\
&\quad + (\text{æ£šå¸è³‡ç”£} \times \text{å‰²å¼•ç‡}_C)
\end{aligned}
$$

**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‰²å¼•ç‡**:
| è³‡ç”£é …ç›® | å‰²å¼•ç‡ | ç†ç”± |
|----------|--------|------|
| ç¾é‡‘åŠã³é é‡‘ | 100% | å³åº§ã«åˆ©ç”¨å¯èƒ½ |
| æœ‰ä¾¡è¨¼åˆ¸ | 80% | å¸‚å ´ã§å£²å´æ™‚ã«ä¾¡æ ¼å¤‰å‹•ãƒªã‚¹ã‚¯ |
| å£²æ›é‡‘ | 70% | å›åä¸èƒ½ãƒªã‚¹ã‚¯ã€æ™‚é–“ä¾¡å€¤ |
| æ£šå¸è³‡ç”£ | 50% | è²©å£²ä¸ç¢ºå®Ÿæ€§ã€åŠ£åŒ–ãƒªã‚¹ã‚¯ |

**ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£ã®è§£é‡ˆ**:
- **NetNetPBR < 1.0**: æ™‚ä¾¡ç·é¡ãŒæ¸…ç®—ä¾¡å€¤ã‚’ä¸‹å›ã‚‹ï¼ˆå‰²å®‰ï¼‰
- **NetNetPBR = 1.0**: æ™‚ä¾¡ç·é¡ãŒæ¸…ç®—ä¾¡å€¤ã¨ç­‰ã—ã„ï¼ˆå¦¥å½“ï¼‰
- **NetNetPBR > 1.0**: æ™‚ä¾¡ç·é¡ãŒæ¸…ç®—ä¾¡å€¤ã‚’ä¸Šå›ã‚‹ï¼ˆå‰²é«˜ã¾ãŸã¯æˆé•·æœŸå¾…ï¼‰

**è¨ˆç®—ä¾‹**:
```yaml
example_company:
  name: "æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹"
  ticker: "9501"
  
  balance_sheet:
    cash_and_deposits: 10000  # ç™¾ä¸‡å††
    marketable_securities: 5000
    accounts_receivable: 8000
    inventory: 3000
    total_liabilities: 15000
  
  market_data:
    shares_outstanding: 100000000  # æ ª
    stock_price: 500  # å††
    market_cap: 50000  # ç™¾ä¸‡å††
  
  calculation:
    liquid_assets: |
      10000 * 1.0 + 5000 * 0.8 + 8000 * 0.7 + 3000 * 0.5
      = 10000 + 4000 + 5600 + 1500
      = 21100 ç™¾ä¸‡å††
    
    net_net_assets: |
      21100 - 15000 = 6100 ç™¾ä¸‡å††
    
    net_net_pbr: |
      50000 / 6100 = 8.20
      â†’ å‰²é«˜ï¼ˆæ¸…ç®—ä¾¡å€¤ã®8å€ã§å–å¼•ã•ã‚Œã¦ã„ã‚‹ï¼‰
```

#### 1.2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯

```python
def calculate_net_net_pbr(company_id: str, params: dict) -> float:
    """
    ãƒãƒƒãƒˆãƒãƒƒãƒˆãƒãƒªãƒ¥ãƒ¼PBRã‚’è¨ˆç®—
    
    Args:
        company_id: ä¼æ¥­ID
        params: å‰²å¼•ç‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    Returns:
        NetNetPBRå€¤ï¼ˆ1æœªæº€ãŒå‰²å®‰ï¼‰
    
    Raises:
        ValueError: company_idãŒä¸æ­£ãªå ´åˆ
        DataNotFoundError: è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    try:
        # å…¥åŠ›æ¤œè¨¼
        if not company_id or not isinstance(company_id, str):
            raise ValueError(f"Invalid company_id: {company_id}")
        
        # æœ€æ–°è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—
        financials = get_latest_financials(company_id)
        
        if financials is None:
            raise DataNotFoundError(f"No financial data for {company_id}")
        
        # å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£è¨ˆç®—
        liquid_assets = (
            financials.cash_and_deposits * params.get('cash_rate', 1.0) +
            financials.marketable_securities * params.get('securities_rate', 0.8) +
            financials.accounts_receivable * params.get('receivables_rate', 0.7) +
            financials.inventory * params.get('inventory_rate', 0.5)
        )
        
        # ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£
        net_net_assets = liquid_assets - financials.total_liabilities
        
        # æ™‚ä¾¡ç·é¡å–å¾—
        market_cap = get_market_cap(company_id)
        
        if market_cap is None or market_cap <= 0:
            raise ValueError(f"Invalid market cap for {company_id}: {market_cap}")
        
        # NetNetPBRè¨ˆç®—
        if net_net_assets <= 0:
            return float('inf')  # è² å‚µè¶…éã®å ´åˆã¯ç„¡é™å¤§
        
        pbr = market_cap / net_net_assets
        
        # ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯
        if pbr < 0 or pbr > 1000:
            logger.warning(f"Abnormal NetNetPBR for {company_id}: {pbr:.2f}")
        
        return pbr
        
    except DataNotFoundError as e:
        logger.error(f"Data not found: {str(e)}")
        raise
    except ValueError as e:
        logger.error(f"Validation error: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in calculate_net_net_pbr: {type(e).__name__}")
        raise RuntimeError(f"Failed to calculate NetNetPBR for {company_id}") from e
```

#### 1.3 PBRæ¨ç§»ãƒãƒ£ãƒ¼ãƒˆ

- Xè»¸: æ±ºç®—æ—¥
- Yè»¸: NetNetPBRå€¤
- ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: éå»5å¹´åˆ†ï¼ˆå››åŠæœŸã”ã¨ï¼‰
- åŸºæº–ç·š: Y=1ï¼ˆå‰²å®‰ãƒ©ã‚¤ãƒ³ï¼‰

### 2. ã‚ªãƒ‹ãƒ¼ãƒ«æˆé•·æ ªç™ºæ˜ãƒ©ãƒ³ã‚­ãƒ³ã‚°

#### 2.1 ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶

```yaml
oneil_criteria:
  eps_growth:
    3_year: "> 20%"
    5_year: "> 15%"
  
  relative_strength:
    threshold: "> 70"
    period: 52é€±
  
  revenue_growth:
    quarterly: "> 10%"
  
  profit_margin:
    minimum: "> 5%"
```

#### 2.2 ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹è¨ˆç®—

**å®šç¾©**:
ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹ï¼ˆRSï¼‰ã¯ã€å€‹åˆ¥éŠ˜æŸ„ã®æ ªä¾¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¸‚å ´å…¨ä½“ã¨æ¯”è¼ƒã—ãŸæŒ‡æ¨™ã€‚

**è¨ˆç®—å¼**:

$$
\text{RS} = \text{Normalize}_{0-100}\left(\frac{P_{\text{stock}}}{P_{\text{index}}}\right)
$$

ã“ã“ã§ã€
- $P_{\text{stock}}$: éŠ˜æŸ„ã®æ ªä¾¡å¤‰åŒ–ç‡ï¼ˆ52é€±ï¼‰
- $P_{\text{index}}$: å¸‚å ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæ—¥çµŒå¹³å‡ï¼‰ã®å¤‰åŒ–ç‡ï¼ˆ52é€±ï¼‰

**è©³ç´°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:

```python
def calculate_relative_strength(company_id: str, period_weeks: int = 52) -> float:
    """
    ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹ã‚’è¨ˆç®—
    
    Args:
        company_id: ä¼æ¥­ID
        period_weeks: æœŸé–“ï¼ˆé€±æ•°ï¼‰
    
    Returns:
        RSå€¤ï¼ˆ0-100ï¼‰
    
    Raises:
        DataNotFoundError: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
    """
    try:
        # æ ªä¾¡å–å¾—ï¼ˆ52é€± = 260å–¶æ¥­æ—¥æƒ³å®šï¼‰
        prices = get_stock_prices(company_id, weeks=period_weeks)
        
        if len(prices) < period_weeks * 5:  # é€±5å–¶æ¥­æ—¥æƒ³å®š
            raise DataNotFoundError(f"Insufficient price data for {company_id}")
        
        # æ ªä¾¡å¤‰åŒ–ç‡è¨ˆç®—
        price_change = (prices[-1] - prices[0]) / prices[0]
        
        # å¸‚å ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
        index_prices = get_index_prices(weeks=period_weeks)
        index_change = (index_prices[-1] - index_prices[0]) / index_prices[0]
        
        # ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        if index_change == 0:
            relative_performance = 0
        else:
            relative_performance = price_change / index_change
        
        # 0-100ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–
        # å…¨éŠ˜æŸ„ã®ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å–å¾—ã—ã€ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ©ãƒ³ã‚¯ã‚’è¨ˆç®—
        all_performances = get_all_relative_performances(period_weeks)
        rs = percentile_rank(relative_performance, all_performances)
        
        return rs
        
    except DataNotFoundError as e:
        logger.error(f"Data not found: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in calculate_relative_strength: {type(e).__name__}")
        raise RuntimeError(f"Failed to calculate RS for {company_id}") from e


def percentile_rank(value: float, all_values: list) -> float:
    """
    ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ©ãƒ³ã‚¯ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰
    
    Args:
        value: å¯¾è±¡å€¤
        all_values: å…¨ä½“ã®å€¤ãƒªã‚¹ãƒˆ
    
    Returns:
        ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ©ãƒ³ã‚¯ï¼ˆ0-100ï¼‰
    """
    sorted_values = sorted(all_values)
    rank = sorted_values.index(value) if value in sorted_values else \
           sum(1 for v in sorted_values if v < value)
    
    percentile = (rank / len(sorted_values)) * 100
    return percentile
```

**è¨ˆç®—ä¾‹**:

```yaml
example_calculation:
  stock:
    ticker: "9501"  # æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
    price_52w_ago: 500å††
    price_current: 650å††
    change: (650 - 500) / 500 = 0.30 (30%ä¸Šæ˜‡)
  
  index:
    name: "æ—¥çµŒå¹³å‡"
    value_52w_ago: 28000å††
    value_current: 30800å††
    change: (30800 - 28000) / 28000 = 0.10 (10%ä¸Šæ˜‡)
  
  relative_performance:
    calculation: 0.30 / 0.10 = 3.0
    interpretation: "å¸‚å ´ã®3å€ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹"
  
  rs_score:
    all_stocks: 3800éŠ˜æŸ„
    better_than: 3420éŠ˜æŸ„
    percentile: (3420 / 3800) * 100 = 90
    interpretation: "RS = 90ï¼ˆä¸Šä½10%ï¼‰â†’ å¼·ã„éŠ˜æŸ„"
```

**RSã‚¹ã‚³ã‚¢ã®è§£é‡ˆ**:

| RSã‚¹ã‚³ã‚¢ | è©•ä¾¡ | æŠ•è³‡åˆ¤æ–­ |
|----------|------|----------|
| 90-100 | éå¸¸ã«å¼·ã„ | è²·ã„å€™è£œï¼ˆä¸Šä½10%ï¼‰ |
| 70-89 | å¼·ã„ | ç›£è¦–å¯¾è±¡ |
| 50-69 | å¹³å‡çš„ | ä¸­ç«‹ |
| 30-49 | å¼±ã„ | é¿ã‘ã‚‹ |
| 0-29 | éå¸¸ã«å¼±ã„ | å£²ã‚Šå€™è£œï¼ˆä¸‹ä½30%ï¼‰ |

#### 2.3 è©³ç´°ãƒšãƒ¼ã‚¸è¡¨ç¤ºè¦ç´ 

```mermaid
flowchart TD
    A[éŠ˜æŸ„è©³ç´°ãƒšãƒ¼ã‚¸] --> B[æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆ]
    A --> C[æ±ºç®—ç™ºè¡¨ãƒãƒ¼ã‚«ãƒ¼]
    A --> D[ã‚·ã‚°ãƒŠãƒ«åŒºé–“è¡¨ç¤º]
    A --> E[è²¡å‹™æŒ‡æ¨™ä¸€è¦§]
    
    B --> B1[52é€±é«˜å€¤ãƒ»å®‰å€¤]
    B --> B2[ç§»å‹•å¹³å‡ç·š]
    
    C --> C1[å››åŠæœŸæ±ºç®—]
    C --> C2[æœ¬æ±ºç®—]
    
    D --> D1[è²·ã„ã‚·ã‚°ãƒŠãƒ«æœŸé–“<br/>èƒŒæ™¯è‰²: ç·‘]
    D --> D2[æ³¨æ„æœŸé–“<br/>èƒŒæ™¯è‰²: é»„]
    
    E --> E1[EPSæˆé•·ç‡]
    E --> E2[å£²ä¸Šé«˜æ¨ç§»]
    E --> E3[åˆ©ç›Šç‡]
    
    style A fill:#e1bee7
    style B fill:#c8e6c9
    style C fill:#fff9c4
    style D fill:#ffccbc
    style E fill:#b2dfdb
```

### 3. ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡ºãƒ„ãƒ¼ãƒ«

#### 3.1 åˆ†é…æ—¥ã®å®šç¾©

```python
def is_distribution_day(index_data: dict, threshold: dict) -> bool:
    """
    åˆ†é…æ—¥åˆ¤å®š
    
    Args:
        index_data: å¸‚å ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿
        threshold: é–¾å€¤è¨­å®š
    
    Returns:
        åˆ†é…æ—¥ãƒ•ãƒ©ã‚°
    """
    # ä¾¡æ ¼ä¸‹è½ã‹ã¤å‡ºæ¥é«˜å¢—åŠ 
    price_drop = (index_data['close'] - index_data['prev_close']) / index_data['prev_close']
    volume_increase = index_data['volume'] / index_data['avg_volume']
    
    return (
        price_drop < threshold['price_drop_pct'] and
        volume_increase > threshold['volume_ratio']
    )
```

#### 3.2 å¤©äº•æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
def detect_market_top(lookback_days: int = 25, threshold: int = 5) -> dict:
    """
    ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡º
    
    Args:
        lookback_days: é¡åŠæ—¥æ•°
        threshold: åˆ†é…æ—¥é–¾å€¤
    
    Returns:
        æ¤œå‡ºçµæœ
    """
    distribution_count = 0
    alert_periods = []
    
    for day in get_market_days(lookback_days):
        if is_distribution_day(day, DEFAULT_THRESHOLD):
            distribution_count += 1
        
        # é–¾å€¤è¶…éã§è­¦å‘Š
        if distribution_count >= threshold:
            alert_periods.append({
                'start': day['date'],
                'count': distribution_count
            })
    
    return {
        'current_count': distribution_count,
        'alert': distribution_count >= threshold,
        'alert_periods': alert_periods
    }
```

---

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰

```yaml
core:
  html: HTML5
  css: CSS3
  javascript: ES2022+

libraries:
  sqlite_wasm: "^3.43.0"  # ãƒ–ãƒ©ã‚¦ã‚¶å†…SQLite
  lightweight_charts: "^4.0.0"  # é«˜é€Ÿãƒãƒ£ãƒ¼ãƒˆæç”»
  
design:
  responsive: true
  mobile_first: true
```

### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰

```yaml
language:
  python: "3.11"

core_libraries:
  pandas: "2.0.3"  # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
  lxml: "4.9.3"  # XBRLè§£æ
  sqlite3: "built-in"  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
  
data_fetching:
  requests: "2.31.0"  # HTTPé€šä¿¡
  beautifulsoup4: "4.12.2"  # HTMLè§£æ
  
analysis:
  numpy: "1.24.3"  # æ•°å€¤è¨ˆç®—
  scipy: "1.11.1"  # çµ±è¨ˆå‡¦ç†
  scikit-learn: "1.3.0"  # æ©Ÿæ¢°å­¦ç¿’ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```

### ã‚¤ãƒ³ãƒ•ãƒ©

```yaml
hosting:
  pages: "GitHub Pages"
  actions: "GitHub Actions"
  
storage:
  database: "GitHub LFS"
  archives: "GitHub Releases"
  artifacts: "GitHub Actions Artifacts"
  
ci_cd:
  workflow: "GitHub Actions"
  schedule: "cron: 0 9 * * *"  # æ¯æ—¥18:00 JST
```

---

## ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æˆ¦ç•¥

### GitHub Releasesæ´»ç”¨

```yaml
xbrl_archives:
  naming: "xbrl-archive-{YYYY}.tar.gz"
  structure:
    - "2023.tar.gz"  # 2023å¹´åˆ†å…¨XBRL
    - "2024.tar.gz"  # 2024å¹´åˆ†å…¨XBRL
    - "2025.tar.gz"  # 2025å¹´åˆ†å…¨XBRL
  
  compression:
    algorithm: gzip
    level: 9
  
  retention: æ°¸ä¹…
  
  auto_create:
    trigger: å¹´æ¬¡ãƒãƒƒãƒï¼ˆ1æœˆ1æ—¥ï¼‰
    script: scripts/archive_yearly_xbrl.py
```

### GitHub LFSæ´»ç”¨

```yaml
sqlite_database:
  file: "stock-analysis.db"
  compressed: "stock-analysis.db.gz"
  
  versioning:
    enabled: true
    track: "*.db"
  
  auto_commit:
    frequency: æ—¥æ¬¡
    script: scripts/commit_db.py
    message: "chore: Update database - {date}"
  
  size_limit: 2GB
  
  download:
    method: git-lfs pull
    url_generation: presigned URL (7æ—¥æœ‰åŠ¹)
```

### GitHub Actions Artifacts

```yaml
build_artifacts:
  retention: 90æ—¥
  
  types:
    - name: "daily-build"
      files:
        - "dist/"
        - "analysis-results.json"
    
    - name: "test-results"
      files:
        - "coverage/"
        - "test-report.html"
  
  auto_cleanup:
    enabled: true
    keep_latest: 30
```

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
stock-analysis/
â”œâ”€â”€ data/                      # Gitignoreï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼‰
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ xbrl/              # ç”ŸXBRLãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚   â””â”€â”€ prices/            # ç”Ÿæ ªä¾¡ãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ stock-analysis.db  # SQLiteï¼ˆLFSç®¡ç†ï¼‰
â”‚   â””â”€â”€ cache/                 # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ fetch_xbrl.py
â”‚   â”œâ”€â”€ fetch_prices.py
â”‚   â”œâ”€â”€ parse_xbrl.py
â”‚   â”œâ”€â”€ import_to_db.py
â”‚   â”œâ”€â”€ analyze.py
â”‚   â””â”€â”€ notify.py
â”œâ”€â”€ src/                       # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚½ãƒ¼ã‚¹
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â””â”€â”€ app.js
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ daily-update.yml
â”‚       â””â”€â”€ deploy.yml
â””â”€â”€ docs/
    â”œâ”€â”€ speckit.constitution
    â”œâ”€â”€ spec.md
    â””â”€â”€ requirements.md
```

---

## ãƒãƒƒãƒå‡¦ç†ä»•æ§˜

### æ—¥æ¬¡ãƒãƒƒãƒãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```mermaid
flowchart TD
    A[GitHub Actionsèµ·å‹•<br/>æ¯æ—¥18:00 JST] --> B[ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—<br/>Python 3.11]
    B --> C[LFSã‹ã‚‰DBå–å¾—<br/>git-lfs pull]
    C --> D{DBæœ€æ–°æ—¥ä»˜å–å¾—}
    D --> E[æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—<br/>æœ€æ–°æ—¥ä»¥é™]
    D --> F[XBRLå–å¾—<br/>æœ€æ–°æ—¥ä»¥é™]
    E --> G[æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚¹]
    F --> H[XBRLãƒ‘ãƒ¼ã‚¹<br/>1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«]
    G --> I[æ­£è¦åŒ–ãƒ»æ¤œè¨¼]
    H --> I
    I --> J[SQLiteæ›´æ–°<br/>ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³]
    J --> K[è§£æå®Ÿè¡Œ<br/>3ç¨®é¡ä¸¦åˆ—]
    K --> L{æ–°è¦éŠ˜æŸ„æ¤œå‡º?}
    L -->|Yes| M[GitHub Issueä½œæˆ]
    L -->|No| N[ã‚¹ã‚­ãƒƒãƒ—]
    M --> O[DBåœ§ç¸®<br/>gzip]
    N --> O
    O --> P[LFSã¸ã‚³ãƒŸãƒƒãƒˆ<br/>git-lfs push]
    P --> Q[presigned URLç”Ÿæˆ]
    Q --> R[Actions Summaryæ›´æ–°]
    R --> S[å®Œäº†]
    
    style A fill:#fff9c4
    style J fill:#c8e6c9
    style M fill:#ffccbc
    style P fill:#b2dfdb
    style S fill:#e1bee7
```

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼YAMLï¼ˆå®Œå…¨ç‰ˆï¼‰

```yaml
name: Daily Stock Analysis Update

on:
  schedule:
    - cron: '0 9 * * *'  # æ¯æ—¥ 9:00 UTC = 18:00 JST
  workflow_dispatch:

permissions:
  contents: write
  issues: write

jobs:
  update-analysis:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Pull LFS files
        run: |
          git lfs pull
      
      - name: Fetch stock prices
        run: |
          python scripts/fetch_prices.py --since-db data/db/stock-analysis.db
        env:
          STOCK_API_KEY: ${{ secrets.STOCK_API_KEY }}
        continue-on-error: true
        id: fetch_prices
      
      - name: Check fetch prices result
        if: steps.fetch_prices.outcome == 'failure'
        run: |
          echo "âš ï¸ Stock price fetch failed, continuing with existing data" >> $GITHUB_STEP_SUMMARY
          echo "ERROR_FETCH_PRICES=true" >> $GITHUB_ENV
      
      - name: Fetch XBRL files
        run: |
          python scripts/fetch_xbrl.py --since-db data/db/stock-analysis.db --rate-limit 1
        continue-on-error: true
        id: fetch_xbrl
      
      - name: Check fetch XBRL result
        if: steps.fetch_xbrl.outcome == 'failure'
        run: |
          echo "âš ï¸ XBRL fetch failed, continuing with existing data" >> $GITHUB_STEP_SUMMARY
          echo "ERROR_FETCH_XBRL=true" >> $GITHUB_ENV
      
      - name: Parse XBRL files
        run: |
          python scripts/parse_xbrl.py --input data/raw/xbrl --output data/normalized
      
      - name: Import to database
        run: |
          python scripts/import_to_db.py --db data/db/stock-analysis.db --input data/normalized
      
      - name: Run analysis
        run: |
          python scripts/analyze.py --db data/db/stock-analysis.db --output analysis-results.json
      
      - name: Create notifications
        id: notify
        run: |
          python scripts/notify.py --payload analysis-results.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Compress database
        run: |
          gzip -k -f data/db/stock-analysis.db
      
      - name: Commit and push changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/db/stock-analysis.db data/db/stock-analysis.db.gz
          git commit -m "chore: Update database - $(date +'%Y-%m-%d')" || echo "No changes"
          git push
      
      - name: Generate presigned URL
        id: presigned
        run: |
          echo "db_url=https://github.com/${{ github.repository }}/raw/main/data/db/stock-analysis.db.gz" >> $GITHUB_OUTPUT
      
      - name: Update Actions Summary
        run: |
          echo "## ğŸ“Š Daily Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date**: $(date +'%Y-%m-%d %H:%M:%S JST')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Database" >> $GITHUB_STEP_SUMMARY
          echo "- [Download DB](https://github.com/${{ github.repository }}/raw/main/data/db/stock-analysis.db.gz)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Analysis Pages" >> $GITHUB_STEP_SUMMARY
          echo "- [NetNet Ranking](https://github.com/${{ github.repository }}/pages/netnet.html?db=${{ steps.presigned.outputs.db_url }})" >> $GITHUB_STEP_SUMMARY
          echo "- [ONeil Ranking](https://github.com/${{ github.repository }}/pages/oneil.html?db=${{ steps.presigned.outputs.db_url }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Market Top Detector](https://github.com/${{ github.repository }}/pages/market-top.html?db=${{ steps.presigned.outputs.db_url }})" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: daily-build-${{ github.run_id }}
          path: |
            analysis-results.json
            data/db/stock-analysis.db.gz
          retention-days: 90
```

---

## è§£æãƒšãƒ¼ã‚¸ä»•æ§˜

### ãƒšãƒ¼ã‚¸æ§‹æˆ

```mermaid
flowchart TB
    subgraph pages["è§£æãƒšãƒ¼ã‚¸ç¾¤"]
        A[index.html<br/>ãƒ›ãƒ¼ãƒ ]
        B[netnet.html<br/>ãƒãƒƒãƒˆãƒãƒƒãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°]
        C[oneil.html<br/>ã‚ªãƒ‹ãƒ¼ãƒ«ãƒ©ãƒ³ã‚­ãƒ³ã‚°]
        D[market-top.html<br/>å¤©äº•æ¤œå‡º]
    end
    
    subgraph shared["å…±é€šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ"]
        E[app.js<br/>ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯]
        F[db-loader.js<br/>SQLiteèª­ã¿è¾¼ã¿]
        G[chart-renderer.js<br/>ãƒãƒ£ãƒ¼ãƒˆæç”»]
        H[styles.css<br/>ã‚¹ã‚¿ã‚¤ãƒ«]
    end
    
    A --> E
    B --> E
    C --> E
    D --> E
    E --> F
    E --> G
    E --> H
    
    style pages fill:#e1bee7
    style shared fill:#c8e6c9
```

### SQLite-wasmçµ±åˆ

```javascript
// db-loader.js
import initSqlJs from 'sql.js';

class DatabaseLoader {
  constructor() {
    this.db = null;
    this.SQL = null;
  }
  
  async initialize(dbUrl) {
    // SQLite-wasmåˆæœŸåŒ–
    this.SQL = await initSqlJs({
      locateFile: file => `https://sql.js.org/dist/${file}`
    });
    
    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    const response = await fetch(dbUrl);
    const buffer = await response.arrayBuffer();
    const uint8Array = new Uint8Array(buffer);
    
    // DBèª­ã¿è¾¼ã¿
    this.db = new this.SQL.Database(uint8Array);
    
    // IndexedDBã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    await this.cacheDatabase(dbUrl, uint8Array);
  }
  
  async cacheDatabase(url, data) {
    const db = await openDB('stock-analysis-cache', 1, {
      upgrade(db) {
        db.createObjectStore('databases');
      }
    });
    
    await db.put('databases', {
      url,
      data,
      timestamp: Date.now()
    }, 'latest');
  }
  
  query(sql, params = []) {
    const results = this.db.exec(sql, params);
    return this.formatResults(results);
  }
  
  formatResults(results) {
    if (!results.length) return [];
    
    const columns = results[0].columns;
    const values = results[0].values;
    
    return values.map(row => {
      const obj = {};
      columns.forEach((col, i) => {
        obj[col] = row[i];
      });
      return obj;
    });
  }
}

export default DatabaseLoader;
```

### lightweight-chartsçµ±åˆ

```javascript
// chart-renderer.js
import { createChart } from 'lightweight-charts';

class ChartRenderer {
  constructor(containerId) {
    this.container = document.getElementById(containerId);
    this.chart = createChart(this.container, {
      width: this.container.clientWidth,
      height: 600,
      layout: {
        background: { color: '#ffffff' },
        textColor: '#333333',
      },
      grid: {
        vertLines: { color: '#e1e1e1' },
        horzLines: { color: '#e1e1e1' },
      },
      rightPriceScale: {
        borderColor: '#cccccc',
      },
      timeScale: {
        borderColor: '#cccccc',
        timeVisible: true,
      },
    });
  }
  
  renderPBRHistory(data) {
    const lineSeries = this.chart.addLineSeries({
      color: '#2962FF',
      lineWidth: 2,
    });
    
    // ãƒ‡ãƒ¼ã‚¿å¤‰æ›
    const chartData = data.map(item => ({
      time: item.report_date,
      value: item.net_net_pbr
    }));
    
    lineSeries.setData(chartData);
    
    // åŸºæº–ç·šï¼ˆPBR=1ï¼‰
    const baselineSeries = this.chart.addLineSeries({
      color: '#FF6B6B',
      lineWidth: 1,
      lineStyle: 2,  // dashed
    });
    
    baselineSeries.setData(
      chartData.map(item => ({ ...item, value: 1.0 }))
    );
    
    // ãƒãƒ¼ã‚«ãƒ¼ï¼ˆæ±ºç®—ç™ºè¡¨æ—¥ï¼‰
    const markers = this.createEarningsMarkers(data);
    lineSeries.setMarkers(markers);
  }
  
  createEarningsMarkers(data) {
    return data
      .filter(item => item.is_earnings_date)
      .map(item => ({
        time: item.report_date,
        position: 'aboveBar',
        color: '#FFA500',
        shape: 'circle',
        text: 'æ±ºç®—'
      }));
  }
  
  destroy() {
    this.chart.remove();
  }
}

export default ChartRenderer;
```

---

## é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

### GitHub Issueè‡ªå‹•ä½œæˆ

```python
# scripts/notify.py
import os
import json
from typing import List, Dict
from github import Github

class NotificationManager:
    def __init__(self):
        self.github = Github(os.getenv('GITHUB_TOKEN'))
        self.repo = self.github.get_repo(os.getenv('GITHUB_REPOSITORY'))
    
    def create_notification(self, candidates: List[Dict]):
        """
        æ–°è¦æ¤œå‡ºéŠ˜æŸ„ã®é€šçŸ¥Issueä½œæˆ
        
        Args:
            candidates: æ¤œå‡ºéŠ˜æŸ„ãƒªã‚¹ãƒˆ
        """
        if not candidates:
            print("No new candidates detected.")
            return
        
        # æ—¢å­˜Issueç¢ºèªï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        today = datetime.date.today().isoformat()
        existing = self.check_existing_issue(today)
        
        if existing:
            print(f"Issue already exists: {existing.html_url}")
            return
        
        # Issueä½œæˆ
        title = f"ğŸ“Š æ–°è¦éŠ˜æŸ„æ¤œå‡º - {today}"
        body = self.generate_issue_body(candidates)
        
        issue = self.repo.create_issue(
            title=title,
            body=body,
            labels=['auto-detection', 'stock-alert']
        )
        
        print(f"Issue created: {issue.html_url}")
        
        # é€šçŸ¥å±¥æ­´DBä¿å­˜
        self.save_notification_history(candidates, issue.number, issue.html_url)
    
    def generate_issue_body(self, candidates: List[Dict]) -> str:
        """Issueæœ¬æ–‡ç”Ÿæˆ"""
        lines = [
            "## æ–°è¦éŠ˜æŸ„æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            f"**æ¤œå‡ºæ—¥æ™‚**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**æ¤œå‡ºä»¶æ•°**: {len(candidates)}ä»¶",
            "",
            "---",
            ""
        ]
        
        # éŠ˜æŸ„ã”ã¨ã«è©³ç´°
        for candidate in candidates:
            lines.extend([
                f"### {candidate['ticker']} - {candidate['name']}",
                "",
                f"**æ¤œå‡ºæ¡ä»¶**: {candidate['detection_type']}",
                "",
                "**ä¸»è¦æŒ‡æ¨™**:",
                f"- æ™‚ä¾¡ç·é¡: {candidate['market_cap']:,.0f}ç™¾ä¸‡å††",
                f"- NetNetPBR: {candidate.get('net_net_pbr', 'N/A')}",
                f"- EPSæˆé•·ç‡: {candidate.get('eps_growth', 'N/A')}%",
                f"- ã‚¹ã‚³ã‚¢: {candidate['score']:.2f}",
                "",
                f"[è©³ç´°ãƒšãƒ¼ã‚¸ã‚’è¦‹ã‚‹]({self.get_detail_page_url(candidate['ticker'])})",
                "",
                "---",
                ""
            ])
        
        return "\n".join(lines)
    
    def get_detail_page_url(self, ticker: str) -> str:
        """è©³ç´°ãƒšãƒ¼ã‚¸URLç”Ÿæˆ"""
        repo_url = f"https://{os.getenv('GITHUB_REPOSITORY_OWNER')}.github.io/{os.getenv('GITHUB_REPOSITORY').split('/')[-1]}"
        db_url = f"https://github.com/{os.getenv('GITHUB_REPOSITORY')}/raw/main/data/db/stock-analysis.db.gz"
        return f"{repo_url}/pages/detail.html?ticker={ticker}&db={db_url}"

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    manager = NotificationManager()
    
    # æ–°è¦æ¤œå‡ºéŠ˜æŸ„ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
    candidates = [
        {
            'ticker': '9501',
            'name': 'æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹',
            'detection_type': 'NetNetï¼ˆPBR < 1.0ï¼‰',
            'market_cap': 150000,
            'net_net_pbr': 0.75,
            'score': 92.3
        },
        {
            'ticker': '9502',
            'name': 'ä¸­éƒ¨é›»åŠ›',
            'detection_type': 'ã‚ªãƒ‹ãƒ¼ãƒ«æˆé•·æ ªï¼ˆEPSæˆé•·ç‡ > 20%ï¼‰',
            'market_cap': 120000,
            'eps_growth': 22.5,
            'score': 86.8
        }
    ]
    
    # é€šçŸ¥ä½œæˆ
    manager.create_notification(candidates)
```

**ç”Ÿæˆã•ã‚Œã‚‹Issueä¾‹**:

```markdown
## æ–°è¦éŠ˜æŸ„æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ

**æ¤œå‡ºæ—¥æ™‚**: 2025-11-22 18:30:45
**æ¤œå‡ºä»¶æ•°**: 2ä»¶

---

### 9501 - æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹

**æ¤œå‡ºæ¡ä»¶**: NetNetï¼ˆPBR < 1.0ï¼‰

**ä¸»è¦æŒ‡æ¨™**:
- æ™‚ä¾¡ç·é¡: 150,000ç™¾ä¸‡å††
- NetNetPBR: 0.75
- EPSæˆé•·ç‡: N/A
- ã‚¹ã‚³ã‚¢: 92.30

[è©³ç´°ãƒšãƒ¼ã‚¸ã‚’è¦‹ã‚‹](https://j1921604.github.io/stock-analysis/pages/detail.html?ticker=9501&db=https://github.com/j1921604/stock-analysis/raw/main/data/db/stock-analysis.db.gz)

---

### 9502 - ä¸­éƒ¨é›»åŠ›

**æ¤œå‡ºæ¡ä»¶**: ã‚ªãƒ‹ãƒ¼ãƒ«æˆé•·æ ªï¼ˆEPSæˆé•·ç‡ > 20%ï¼‰

**ä¸»è¦æŒ‡æ¨™**:
- æ™‚ä¾¡ç·é¡: 120,000ç™¾ä¸‡å††
- NetNetPBR: N/A
- EPSæˆé•·ç‡: 22.5%
- ã‚¹ã‚³ã‚¢: 86.80

[è©³ç´°ãƒšãƒ¼ã‚¸ã‚’è¦‹ã‚‹](https://j1921604.github.io/stock-analysis/pages/detail.html?ticker=9502&db=https://github.com/j1921604/stock-analysis/raw/main/data/db/stock-analysis.db.gz)

---
```

**é€šçŸ¥ãƒˆãƒªã‚¬ãƒ¼è¨­å®š**:

```yaml
notification_rules:
  netnet_detection:
    trigger: "NetNetPBR < 1.0 ã«æ–°ãŸã«ãªã£ãŸéŠ˜æŸ„"
    frequency: "æ—¥æ¬¡"
    priority: "é«˜"
    label: "netnet-alert"
  
  oneil_detection:
    trigger: "ã‚ªãƒ‹ãƒ¼ãƒ«æ¡ä»¶ã‚’æ–°ãŸã«æº€ãŸã—ãŸéŠ˜æŸ„"
    frequency: "æ—¥æ¬¡"
    priority: "ä¸­"
    label: "oneil-alert"
  
  market_top_alert:
    trigger: "åˆ†é…æ—¥ãŒ5å›ä»¥ä¸Šï¼ˆ25æ—¥ä»¥å†…ï¼‰"
    frequency: "å³æ™‚"
    priority: "æœ€é«˜"
    label: "market-top-warning"
  
  data_quality_alert:
    trigger: "XBRLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ç‡ > 5%"
    frequency: "å³æ™‚"
    priority: "ä¸­"
    label: "data-quality-issue"
```

---

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### GitHub Pagesè¨­å®š

```yaml
# .github/workflows/deploy.yml
name: Deploy to GitHub Pages

on:
  push:
    branches:
      - main
    paths:
      - 'src/**'
      - '.github/workflows/deploy.yml'

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './src'
  
  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ•ãƒ­ãƒ¼

```mermaid
flowchart LR
    A[ã‚³ãƒ¼ãƒ‰å¤‰æ›´<br/>src/é…ä¸‹] --> B[git push<br/>mainãƒ–ãƒ©ãƒ³ãƒ]
    B --> C[GitHub Actions<br/>ãƒˆãƒªã‚¬ãƒ¼]
    C --> D[ãƒ“ãƒ«ãƒ‰<br/>ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä½œæˆ]
    D --> E[GitHub Pages<br/>ãƒ‡ãƒ—ãƒ­ã‚¤]
    E --> F[CDNé…ä¿¡<br/>2-3åˆ†ã§åæ˜ ]
    F --> G[å…¬é–‹URL<br/>ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½]
    
    style A fill:#e3f2fd
    style C fill:#fff9c4
    style E fill:#c8e6c9
    style G fill:#e1bee7
```

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### å•é¡Œ1: GitHub PagesãŒæ›´æ–°ã•ã‚Œãªã„

**ç—‡çŠ¶**:
- ã‚³ãƒ¼ãƒ‰ã‚’pushã—ãŸãŒãƒšãƒ¼ã‚¸ãŒå¤ã„ã¾ã¾
- ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯æˆåŠŸã—ã¦ã„ã‚‹

**åŸå› ã¨å¯¾ç­–**:
```yaml
cause_1:
  description: "ãƒ–ãƒ©ã‚¦ã‚¶ã‚­ãƒ£ãƒƒã‚·ãƒ¥"
  solution:
    - "Ctrl+Shift+Rï¼ˆå¼·åˆ¶ãƒªãƒ­ãƒ¼ãƒ‰ï¼‰"
    - "ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã§ç¢ºèª"
    - "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"

cause_2:
  description: "CDNä¼æ’­é…å»¶"
  solution:
    - "5-10åˆ†å¾…ã¤"
    - "curl -I {URL} ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª"
    - "Cache-Control: max-age=600 æƒ³å®š"

cause_3:
  description: "GitHub Pagesè¨­å®šã‚¨ãƒ©ãƒ¼"
  solution:
    - "ãƒªãƒã‚¸ãƒˆãƒª Settings â†’ Pages ã§è¨­å®šç¢ºèª"
    - "Source: GitHub Actions ã‚’é¸æŠ"
    - "Custom domainè¨­å®šãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦å†è¨­å®š"
```

#### å•é¡Œ2: SQLite-wasmãŒèª­ã¿è¾¼ã‚ãªã„

**ç—‡çŠ¶**:
- ãƒšãƒ¼ã‚¸ã¯è¡¨ç¤ºã•ã‚Œã‚‹ãŒSQLiteã‚¨ãƒ©ãƒ¼
- Console: "Failed to load sqlite-wasm"

**åŸå› ã¨å¯¾ç­–**:
```yaml
cause_1:
  description: "CORSåˆ¶ç´„"
  solution: |
    # index.htmlã®scriptã‚¿ã‚°ç¢ºèª
    <script type="module">
      import initSqlJs from 'https://cdn.jsdelivr.net/npm/sql.js@1.8.0/dist/sql-wasm.js';
      // âœ… CDNçµŒç”±ã§èª­ã¿è¾¼ã¿
    </script>

cause_2:
  description: "WebAssemblyå¯¾å¿œãƒ–ãƒ©ã‚¦ã‚¶"
  solution:
    - "Chrome >= 90, Firefox >= 88 ç¢ºèª"
    - "Safari >= 14 ç¢ºèª"
    - "å¤ã„ãƒ–ãƒ©ã‚¦ã‚¶ã¯éå¯¾å¿œ"

cause_3:
  description: "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼"
  solution:
    - "DevTools Network ã‚¿ãƒ–ã§ç¢ºèª"
    - "sql-wasm.wasm ã® Status: 200 ç¢ºèª"
    - "ã‚µã‚¤ã‚º: ç´„800KB ç¢ºèª"
```

#### å•é¡Œ3: ãƒãƒ£ãƒ¼ãƒˆãŒè¡¨ç¤ºã•ã‚Œãªã„

**ç—‡çŠ¶**:
- ãƒ‡ãƒ¼ã‚¿ã¯èª­ã¿è¾¼ã¾ã‚Œã‚‹ãŒãƒãƒ£ãƒ¼ãƒˆãŒç©ºç™½
- Console: ã‚¨ãƒ©ãƒ¼ãªã—

**åŸå› ã¨å¯¾ç­–**:
```yaml
cause_1:
  description: "ã‚³ãƒ³ãƒ†ãƒŠã‚µã‚¤ã‚ºæœªæŒ‡å®š"
  solution: |
    /* styles.css */
    #chart-container {
      width: 100%;
      height: 600px;  /* âœ… é«˜ã•å¿…é ˆ */
    }

cause_2:
  description: "ãƒ‡ãƒ¼ã‚¿å½¢å¼ä¸æ­£"
  solution: |
    // ãƒ‡ãƒ¼ã‚¿å½¢å¼ç¢ºèª
    const chartData = data.map(item => ({
      time: item.report_date,  // âœ… YYYY-MM-DDå½¢å¼
      value: parseFloat(item.net_net_pbr)  // âœ… æ•°å€¤å¤‰æ›
    }));

cause_3:
  description: "lightweight-chartsèª­ã¿è¾¼ã¿å¤±æ•—"
  solution:
    - "DevTools Network ã§ lightweight-charts.js ç¢ºèª"
    - "CDN URLæ­£ã—ã„ã‹ç¢ºèª"
    - "https://unpkg.com/lightweight-charts@4.0.0/dist/lightweight-charts.standalone.production.js"
```

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ä¸€è¦§

```yaml
data_protection:
  encryption:
    - GitHub Secretsä½¿ç”¨ï¼ˆAPI ã‚­ãƒ¼ï¼‰
    - HTTPSé€šä¿¡å¿…é ˆ
    - presigned URLæœ‰åŠ¹æœŸé™: 7æ—¥
  
  access_control:
    - ãƒªãƒã‚¸ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™
    - LFSãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯
    - GitHub Pagesèªè¨¼ä¸è¦ï¼ˆå…¬é–‹æƒ…å ±ã®ã¿ï¼‰
  
  input_validation:
    - XBRLã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
    - æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
    - SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªï¼‰
  
  error_handling:
    - æ©Ÿå¯†æƒ…å ±ã‚’å«ã¾ãªã„ãƒ­ã‚°å‡ºåŠ›
    - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸€èˆ¬åŒ–
    - ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã®ç§˜åŒ¿
```

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] API ã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯GitHub Secretsã«ä¿å­˜
- [ ] `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã¯`.gitignore`ã«å«ã‚ã‚‹
- [ ] SQLã‚¯ã‚¨ãƒªã¯å…¨ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯å…¨ã¦ã‚µãƒ‹ã‚¿ã‚¤ã‚º
- [ ] HTTPSé€šä¿¡ã®ã¿è¨±å¯
- [ ] presigned URLã¯7æ—¥ã§è‡ªå‹•å¤±åŠ¹
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã«æ©Ÿå¯†æƒ…å ±ã‚’å«ã‚ãªã„
- [ ] ä¾å­˜é–¢ä¿‚ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆé€±æ¬¡ï¼‰

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤

```yaml
frontend:
  initial_load: < 2ç§’
  db_download: < 10ç§’ï¼ˆ100MBæƒ³å®šï¼‰
  query_execution: < 100ms
  chart_rendering_1000points: < 500ms
  filter_operation: < 200ms

backend:
  xbrl_parse: < 1ç§’/ãƒ•ã‚¡ã‚¤ãƒ«
  db_import: < 5åˆ†/1000ãƒ•ã‚¡ã‚¤ãƒ«
  analysis_execution: < 3åˆ†/å…¨éŠ˜æŸ„
  github_actions_total: < 30åˆ†

storage:
  db_size: < 500MBï¼ˆåœ§ç¸®å‰ï¼‰
  db_size_compressed: < 100MB
  lfs_quota: < 1GB
```

### æœ€é©åŒ–æˆ¦ç•¥

```mermaid
flowchart TD
    A[ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–] --> B[ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹]
    A --> C[ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰]
    A --> D[ãƒãƒƒãƒå‡¦ç†]
    
    B --> B1[ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–]
    B --> B2[ã‚¯ã‚¨ãƒªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°]
    B --> B3[åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ]
    
    C --> C1[SQLite-wasmã‚­ãƒ£ãƒƒã‚·ãƒ¥]
    C --> C2[ãƒãƒ£ãƒ¼ãƒˆä»®æƒ³åŒ–]
    C --> C3[é…å»¶èª­ã¿è¾¼ã¿]
    
    D --> D1[ä¸¦åˆ—å‡¦ç†]
    D --> D2[å¢—åˆ†æ›´æ–°]
    D --> D3[ãƒ¬ãƒ¼ãƒˆåˆ¶é™éµå®ˆ]
    
    style A fill:#e1bee7
    style B fill:#c8e6c9
    style C fill:#fff9c4
    style D fill:#ffccbc
```

### æœ€é©åŒ–å®Ÿè£…ä¾‹

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–

**ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ**:
```sql
-- æ‚ªã„ä¾‹: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—
SELECT * FROM stock_prices WHERE company_id = '9501' ORDER BY date DESC LIMIT 10;
-- å®Ÿè¡Œæ™‚é–“: 500msï¼ˆå…¨è¡Œã‚¹ã‚­ãƒ£ãƒ³ï¼‰

-- è‰¯ã„ä¾‹: è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_stock_prices_company_date ON stock_prices(company_id, date DESC);
SELECT * FROM stock_prices WHERE company_id = '9501' ORDER BY date DESC LIMIT 10;
-- å®Ÿè¡Œæ™‚é–“: 10msï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¹ã‚­ãƒ£ãƒ³ï¼‰
```

**ã‚¯ã‚¨ãƒªæœ€é©åŒ–**:
```sql
-- æ‚ªã„ä¾‹: ã‚µãƒ–ã‚¯ã‚¨ãƒªå¤šç”¨
SELECT 
  c.name,
  (SELECT MAX(date) FROM stock_prices WHERE company_id = c.company_id) as latest_date,
  (SELECT close FROM stock_prices WHERE company_id = c.company_id ORDER BY date DESC LIMIT 1) as latest_price
FROM companies c;
-- å®Ÿè¡Œæ™‚é–“: 5000ms

-- è‰¯ã„ä¾‹: JOINä½¿ç”¨
SELECT 
  c.name,
  sp.date as latest_date,
  sp.close as latest_price
FROM companies c
LEFT JOIN (
  SELECT company_id, date, close
  FROM stock_prices
  WHERE (company_id, date) IN (
    SELECT company_id, MAX(date) 
    FROM stock_prices 
    GROUP BY company_id
  )
) sp ON c.company_id = sp.company_id;
-- å®Ÿè¡Œæ™‚é–“: 200ms
```

**VACUUMå®Ÿè¡Œ**:
```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
def optimize_database(db_path: str):
    """VACUUMå®Ÿè¡Œã§DBã‚µã‚¤ã‚ºå‰Šæ¸›"""
    conn = sqlite3.connect(db_path)
    
    # VACUUMã§ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è§£æ¶ˆ
    conn.execute("VACUUM;")
    
    # ANALYZEã§çµ±è¨ˆæƒ…å ±æ›´æ–°
    conn.execute("ANALYZE;")
    
    conn.close()
    
    # æœŸå¾…åŠ¹æœ: DBã‚µã‚¤ã‚º 10-30%å‰Šæ¸›
```

#### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœ€é©åŒ–

**IndexedDBã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**:
```javascript
// SQLite DBã‚’IndexedDBã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
class DatabaseCache {
  async getCachedDB(url) {
    const db = await openDB('stock-analysis-cache', 1);
    const cached = await db.get('databases', url);
    
    if (cached && this.isFresh(cached.timestamp)) {
      console.log('Using cached database');
      return cached.data;
    }
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„ or å¤ã„å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    console.log('Downloading fresh database');
    const data = await this.downloadDB(url);
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    await db.put('databases', {
      url,
      data,
      timestamp: Date.now()
    });
    
    return data;
  }
  
  isFresh(timestamp) {
    const ONE_DAY = 24 * 60 * 60 * 1000;
    return (Date.now() - timestamp) < ONE_DAY;
  }
}
```

**ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿é–“å¼•ãï¼ˆLTTBï¼‰**:
```javascript
// Largest-Triangle-Three-Bucketsã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
function downsampleLTTB(data, threshold) {
  if (data.length <= threshold) return data;
  
  const sampled = [data[0]];  // æœ€åˆã®ãƒã‚¤ãƒ³ãƒˆ
  const bucketSize = (data.length - 2) / (threshold - 2);
  
  let a = 0;
  
  for (let i = 0; i < threshold - 2; i++) {
    const avgX = (i + 1) * bucketSize + 1;
    
    let maxArea = -1;
    let maxAreaPoint = null;
    
    const start = Math.floor(i * bucketSize) + 1;
    const end = Math.floor((i + 1) * bucketSize) + 1;
    
    for (let j = start; j < end; j++) {
      const area = Math.abs(
        (data[a].time - data[j].time) * (data[end].value - data[a].value) -
        (data[a].time - data[end].time) * (data[j].value - data[a].value)
      ) * 0.5;
      
      if (area > maxArea) {
        maxArea = area;
        maxAreaPoint = data[j];
      }
    }
    
    sampled.push(maxAreaPoint);
    a = data.indexOf(maxAreaPoint);
  }
  
  sampled.push(data[data.length - 1]);  // æœ€å¾Œã®ãƒã‚¤ãƒ³ãƒˆ
  
  return sampled;
}

// ä½¿ç”¨ä¾‹
const originalData = fetchPriceData();  // 10000ãƒã‚¤ãƒ³ãƒˆ
const downsampledData = downsampleLTTB(originalData, 1000);  // 1000ãƒã‚¤ãƒ³ãƒˆ
chart.setData(downsampledData);
// æç”»æ™‚é–“: 5000ms â†’ 500ms
```

#### ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–

**ä¸¦åˆ—å‡¦ç†ï¼ˆmultiprocessingï¼‰**:
```python
from multiprocessing import Pool
import os

def parse_xbrl_parallel(xbrl_files: list, num_workers: int = None):
    """XBRLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—ãƒ‘ãƒ¼ã‚¹"""
    if num_workers is None:
        num_workers = os.cpu_count()
    
    with Pool(num_workers) as pool:
        results = pool.map(parse_single_xbrl, xbrl_files)
    
    return results

# æœŸå¾…åŠ¹æœ: å‡¦ç†æ™‚é–“ 30åˆ† â†’ 10åˆ†ï¼ˆ3ã‚³ã‚¢CPUæƒ³å®šï¼‰
```

**å¢—åˆ†æ›´æ–°**:
```python
def incremental_update(db_path: str, since_date: str):
    """å·®åˆ†æ›´æ–°ã§å‡¦ç†é‡å‰Šæ¸›"""
    conn = sqlite3.connect(db_path)
    
    # å‰å›æ›´æ–°æ—¥å–å¾—
    last_update = conn.execute(
        "SELECT MAX(date) FROM stock_prices"
    ).fetchone()[0]
    
    # å·®åˆ†ã®ã¿å–å¾—
    new_data = fetch_prices(since=last_update)
    
    # å·®åˆ†ã®ã¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import_to_db(new_data)
    
    conn.close()

# æœŸå¾…åŠ¹æœ: å–å¾—ä»¶æ•° 100ä¸‡ä»¶ â†’ 5000ä»¶ï¼ˆæ—¥æ¬¡æ›´æ–°ã®å ´åˆï¼‰
```

---

**ã“ã®ä»•æ§˜æ›¸ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Œå…¨ãªæŠ€è¡“è¨­è¨ˆã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚**
**å®Ÿè£…æ™‚ã¯ã“ã®ä»•æ§˜æ›¸ã«å³å¯†ã«å¾“ã„ã€å¤‰æ›´ãŒã‚ã‚‹å ´åˆã¯ä»•æ§˜æ›¸ã‚’å…ˆã«æ›´æ–°ã—ã¦ãã ã•ã„ã€‚**

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0 | **ä½œæˆæ—¥**: 2025å¹´11æœˆ22æ—¥ | **æ‰¿èª**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ¼ãƒ‰
