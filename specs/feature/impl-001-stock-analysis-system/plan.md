# æ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ  å®Ÿè£…è¨ˆç”»æ›¸

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**ä½œæˆæ—¥**: 2025å¹´11æœˆ22æ—¥  
**æœ€çµ‚æ›´æ–°**: 2025å¹´11æœˆ22æ—¥  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: å®Ÿè£…è¨ˆç”»ç­–å®šå®Œäº†  
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: stock-analysis  
**å®Ÿè£…ãƒ–ãƒ©ãƒ³ãƒ**: feature/impl-001-stock-analysis-system

---

## ğŸ“‹ ç›®æ¬¡

1. [å®Ÿè£…è¨ˆç”»æ¦‚è¦](#å®Ÿè£…è¨ˆç”»æ¦‚è¦)
2. [é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚º](#é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚º)
3. [ã‚¿ã‚¹ã‚¯åˆ†è§£](#ã‚¿ã‚¹ã‚¯åˆ†è§£)
4. [å®Ÿè£…å„ªå…ˆé †ä½](#å®Ÿè£…å„ªå…ˆé †ä½)
5. [æŠ€è¡“é¸å®š](#æŠ€è¡“é¸å®š)
6. [é–‹ç™ºç’°å¢ƒæ§‹ç¯‰](#é–‹ç™ºç’°å¢ƒæ§‹ç¯‰)
7. [å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«](#å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«)
8. [å“è³ªä¿è¨¼è¨ˆç”»](#å“è³ªä¿è¨¼è¨ˆç”»)
9. [ãƒªã‚¹ã‚¯ç®¡ç†](#ãƒªã‚¹ã‚¯ç®¡ç†)
10. [ãƒ‡ãƒ—ãƒ­ã‚¤è¨ˆç”»](#ãƒ‡ãƒ—ãƒ­ã‚¤è¨ˆç”»)

---

## å®Ÿè£…è¨ˆç”»æ¦‚è¦

### è¨ˆç”»ã®ç›®çš„

ä»•æ§˜æ›¸ï¼ˆspec.mdï¼‰ã¨è¦ä»¶å®šç¾©æ›¸ï¼ˆrequirements.mdï¼‰ã«åŸºã¥ãã€æ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã‚’æ®µéšçš„ã«é€²ã‚ã‚‹ãŸã‚ã®è©³ç´°è¨ˆç”»ã‚’ç­–å®šã™ã‚‹ã€‚AIï¼ˆClaudeï¼‰ã«ã‚ˆã‚‹95%ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’æ´»ç”¨ã—ã€7é€±é–“ã§å®Ÿè£…å®Œäº†ã‚’ç›®æŒ‡ã™ã€‚

### é–‹ç™ºåŸå‰‡

```mermaid
flowchart TB
    subgraph principles["é–‹ç™ºåŸå‰‡"]
        A[AIæ´»ç”¨æœ€å¤§åŒ–<br/>95%ä»¥ä¸ŠAIç”Ÿæˆ]
        B[æ®µéšçš„å®Ÿè£…<br/>MVPâ†’æ‹¡å¼µ]
        C[ç¶™ç¶šçš„æ¤œè¨¼<br/>å‹•ä½œç¢ºèªå¾¹åº•]
        D[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé§†å‹•<br/>ä»•æ§˜â†’å®Ÿè£…]
    end
    
    subgraph practices["å®Ÿè·µæ–¹æ³•"]
        E[Claudeé€£æºé–‹ç™º]
        F[æ©Ÿèƒ½å˜ä½å®Ÿè£…]
        G[ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™º]
        H[ä»•æ§˜æº–æ‹ æ¤œè¨¼]
    end
    
    A --> E
    B --> F
    C --> G
    D --> H
    
    style principles fill:#e1bee7
    style practices fill:#c8e6c9
```

### å®Ÿè£…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

**ãƒ•ã‚§ãƒ¼ã‚ºåˆ†å‰²æˆ¦ç•¥**:
```yaml
approach:
  phase1_foundation:
    goal: "åŸºç›¤æ§‹ç¯‰"
    deliverables:
      - "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒä½œæˆ"
      - "åŸºæœ¬ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ "
      - "é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
    duration: "1é€±é–“"
    priority: "æœ€é«˜"
  
  phase2_data_pipeline:
    goal: "ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰"
    deliverables:
      - "EDINET XBRLå–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
      - "æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
      - "XBRLãƒ‘ãƒ¼ã‚µãƒ¼"
      - "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼"
    duration: "2é€±é–“"
    priority: "æœ€é«˜"
  
  phase3_analysis:
    goal: "è§£æã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…"
    deliverables:
      - "ãƒãƒƒãƒˆãƒãƒƒãƒˆPBRè¨ˆç®—"
      - "ã‚ªãƒ‹ãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼"
      - "ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡º"
    duration: "1.5é€±é–“"
    priority: "é«˜"
  
  phase4_frontend:
    goal: "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…"
    deliverables:
      - "è§£æãƒšãƒ¼ã‚¸HTML/CSS/JS"
      - "sqlite-wasmçµ±åˆ"
      - "lightweight-chartsçµ±åˆ"
    duration: "1.5é€±é–“"
    priority: "é«˜"
  
  phase5_automation:
    goal: "è‡ªå‹•åŒ–ãƒ»é€šçŸ¥"
    deliverables:
      - "GitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
      - "é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ "
      - "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"
    duration: "1é€±é–“"
    priority: "ä¸­"
```

---

## é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚º

### ãƒ•ã‚§ãƒ¼ã‚º1: åŸºç›¤æ§‹ç¯‰ï¼ˆWeek 1ï¼‰

```mermaid
flowchart LR
    A[ç’°å¢ƒæ§‹ç¯‰] --> B[DBè¨­è¨ˆ]
    B --> C[ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ]
    C --> D[ä¾å­˜é–¢ä¿‚ç®¡ç†]
    D --> E[åŸºç›¤å®Œæˆ]
    
    style A fill:#e3f2fd
    style E fill:#c8e6c9
```

**Week 1: Day 1-2ï¼ˆç’°å¢ƒæ§‹ç¯‰ï¼‰**
```yaml
tasks:
  - id: "IMPL-001"
    name: "Pythonç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
    details:
      - "Python 3.11ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª"
      - "venvä½œæˆ: python -m venv venv"
      - "requirements.txtä½œæˆ"
      - "åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpandas, lxml, requestsï¼‰"
    acceptance:
      - "python --version ãŒ 3.11ä»¥ä¸Š"
      - "pip list ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª"
    assigned: "AI (Claude)"
    
  - id: "IMPL-002"
    name: "Git/GitHubè¨­å®š"
    details:
      - "LFSæœ‰åŠ¹åŒ–: git lfs install"
      - ".gitignoreä½œæˆï¼ˆdata/, venv/, *.dbï¼‰"
      - "LFSãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨­å®š: git lfs track '*.db'"
    acceptance:
      - "git lfs ls-files ã§ç¢ºèª"
    assigned: "AI (Claude)"
```

**Week 1: Day 3-4ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆï¼‰**
```yaml
tasks:
  - id: "IMPL-003"
    name: "SQLiteã‚¹ã‚­ãƒ¼ãƒå®Ÿè£…"
    file: "schemas/create_tables.sql"
    details:
      - "companies ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"
      - "stock_prices ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"
      - "xbrl_files ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"
      - "financials ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"
      - "analysis_cache ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"
      - "notifications ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"
      - "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹17ç®‡æ‰€ä½œæˆ"
    sql_example: |
      CREATE TABLE IF NOT EXISTS companies (
        company_id TEXT PRIMARY KEY,
        ticker TEXT UNIQUE NOT NULL,
        name TEXT NOT NULL,
        sector TEXT,
        industry TEXT,
        market TEXT,
        listing_date DATE,
        last_update DATETIME DEFAULT CURRENT_TIMESTAMP
      );
    acceptance:
      - "sqlite3 data/db/stock-analysis.db '.schema' ã§å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèª"
      - "å…¨FOREIGN KEYåˆ¶ç´„ãŒæœ‰åŠ¹"
    assigned: "AI (Claude)"
  
  - id: "IMPL-004"
    name: "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
    file: "scripts/init_db.py"
    details:
      - "create_tables.sqlå®Ÿè¡Œ"
      - "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼ˆæ±äº¬é›»åŠ›ã€ä¸­éƒ¨é›»åŠ›ï¼‰"
      - "VACUUMå®Ÿè¡Œ"
    acceptance:
      - "python scripts/init_db.py ã§æ­£å¸¸å®Ÿè¡Œ"
      - "SELECT COUNT(*) FROM companies ãŒ 2"
    assigned: "AI (Claude)"
```

**Week 1: Day 5-7ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãƒ»ä¾å­˜é–¢ä¿‚ï¼‰**
```yaml
tasks:
  - id: "IMPL-005"
    name: "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ"
    structure: |
      stock-analysis/
      â”œâ”€â”€ data/
      â”‚   â”œâ”€â”€ raw/
      â”‚   â”‚   â”œâ”€â”€ xbrl/
      â”‚   â”‚   â””â”€â”€ prices/
      â”‚   â”œâ”€â”€ normalized/
      â”‚   â”œâ”€â”€ db/
      â”‚   â””â”€â”€ cache/
      â”œâ”€â”€ scripts/
      â”‚   â”œâ”€â”€ fetch_xbrl.py
      â”‚   â”œâ”€â”€ fetch_prices.py
      â”‚   â”œâ”€â”€ parse_xbrl.py
      â”‚   â”œâ”€â”€ import_to_db.py
      â”‚   â”œâ”€â”€ analyze.py
      â”‚   â””â”€â”€ notify.py
      â”œâ”€â”€ src/
      â”‚   â”œâ”€â”€ index.html
      â”‚   â”œâ”€â”€ styles.css
      â”‚   â””â”€â”€ app.js
      â”œâ”€â”€ schemas/
      â”‚   â””â”€â”€ create_tables.sql
      â”œâ”€â”€ tests/
      â”‚   â”œâ”€â”€ test_fetch.py
      â”‚   â”œâ”€â”€ test_parse.py
      â”‚   â””â”€â”€ test_analyze.py
      â””â”€â”€ utils/
          â”œâ”€â”€ performance.py
          â””â”€â”€ logger.py
    acceptance:
      - "å…¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨"
      - "README.mdã«æ§‹é€ å›³è¨˜è¼‰"
    assigned: "AI (Claude)"
  
  - id: "IMPL-006"
    name: "requirements.txtå®Œæˆ"
    file: "requirements.txt"
    packages:
      core:
        - "pandas==2.0.3"
        - "numpy==1.24.3"
        - "lxml==4.9.3"
        - "requests==2.31.0"
      
      testing:
        - "pytest==7.4.0"
        - "pytest-cov==4.1.0"
        - "pytest-mock==3.11.1"
        - "pytest-xdist==3.3.1"
        - "pytest-timeout==2.1.0"
        - "pytest-benchmark==4.0.0"
      
      quality:
        - "flake8==6.0.0"
        - "mypy==1.4.1"
        - "black==23.7.0"
        - "isort==5.12.0"
        - "pylint==2.17.5"
        - "radon==6.0.1"
      
      utilities:
        - "tqdm==4.65.0"          # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        - "python-dotenv==1.0.0"  # ç’°å¢ƒå¤‰æ•°ç®¡ç†
        - "pyyaml==6.0.1"         # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    
    full_requirements_txt: |
      # Core dependencies
      pandas==2.0.3
      numpy==1.24.3
      lxml==4.9.3
      requests==2.31.0
      
      # Testing
      pytest==7.4.0
      pytest-cov==4.1.0
      pytest-mock==3.11.1
      pytest-xdist==3.3.1
      pytest-timeout==2.1.0
      pytest-benchmark==4.0.0
      
      # Code quality
      flake8==6.0.0
      mypy==1.4.1
      black==23.7.0
      isort==5.12.0
      pylint==2.17.5
      radon==6.0.1
      
      # Utilities
      tqdm==4.65.0
      python-dotenv==1.0.0
      pyyaml==6.0.1
    
    acceptance:
      - "pip install -r requirements.txt ã§ã‚¨ãƒ©ãƒ¼ãªã—"
      - "pip list ã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª"
      - "python -c 'import pandas; print(pandas.__version__)' ãŒ 2.0.3"
    assigned: "AI (Claude)"
```

---

### ãƒ•ã‚§ãƒ¼ã‚º2: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ï¼ˆWeek 2-3ï¼‰

```mermaid
flowchart TB
    A[EDINET XBRLå–å¾—] --> B[æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—]
    B --> C[XBRLãƒ‘ãƒ¼ã‚¹]
    C --> D[æ­£è¦åŒ–]
    D --> E[DBã‚¤ãƒ³ãƒãƒ¼ãƒˆ]
    E --> F[ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œæˆ]
    
    style A fill:#fff9c4
    style C fill:#ffccbc
    style E fill:#c8e6c9
    style F fill:#e1bee7
```

**Week 2: Day 1-3ï¼ˆXBRLå–å¾—ï¼‰**
```yaml
tasks:
  - id: "IMPL-007"
    name: "EDINET APIé€£æº"
    file: "scripts/fetch_xbrl.py"
    details:
      - "EDINET API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©"
      - "ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œï¼ˆ1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
      - "å·®åˆ†æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ--since-dbï¼‰"
      - "ã‚¨ãƒ©ãƒ¼ãƒªãƒˆãƒ©ã‚¤ï¼ˆ3å›ã¾ã§ï¼‰"
    code_structure: |
      def fetch_xbrl_files(since_date: str, rate_limit: float = 1.0):
          """EDINET ã‹ã‚‰XBRLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
          # 1. æå‡ºæ›¸é¡ä¸€è¦§å–å¾—
          # 2. å·®åˆ†ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          # 3. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          # 4. data/raw/xbrl/ ã«ä¿å­˜
    acceptance:
      - "python scripts/fetch_xbrl.py --since-db data/db/stock-analysis.db"
      - "data/raw/xbrl/ ã«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç¢ºèª"
      - "1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™éµå®ˆç¢ºèª"
    assigned: "AI (Claude)"
  
  - id: "IMPL-008"
    name: "XBRLå–å¾—ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_fetch.py"
    details:
      - "ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ"
      - "ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ†ã‚¹ãƒˆ"
      - "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"
    acceptance:
      - "pytest tests/test_fetch.py -v ã§å…¨åˆæ ¼"
      - "ã‚«ãƒãƒ¬ãƒƒã‚¸ 100%"
    assigned: "AI (Claude)"
```

**Week 2: Day 4-7ï¼ˆæ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰**
```yaml
tasks:
  - id: "IMPL-009"
    name: "æ ªä¾¡APIé€£æº"
    file: "scripts/fetch_prices.py"
    details:
      - "ç„¡æ–™æ ªä¾¡APIé¸å®šï¼ˆYahoo Financeç­‰ï¼‰"
      - "æ—¥æ¬¡æ ªä¾¡å–å¾—ï¼ˆOHLCVï¼‰"
      - "å·®åˆ†æ›´æ–°å¯¾å¿œ"
      - "èª¿æ•´å¾Œçµ‚å€¤è¨ˆç®—"
    code_structure: |
      def fetch_stock_prices(tickers: List[str], since_date: str):
          """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
          # 1. ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆå–å¾—
          # 2. APIå‘¼ã³å‡ºã—
          # 3. ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
          # 4. data/raw/prices/ ã«ä¿å­˜
    acceptance:
      - "python scripts/fetch_prices.py --since-db data/db/stock-analysis.db"
      - "data/raw/prices/ ã«CSVä¿å­˜ç¢ºèª"
    assigned: "AI (Claude)"
  
  - id: "IMPL-010"
    name: "æ ªä¾¡å–å¾—ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_fetch_prices.py"
    details:
      - "ãƒ¢ãƒƒã‚¯APIä½œæˆ"
      - "ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆ"
    acceptance:
      - "pytest tests/test_fetch_prices.py -v ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

**Week 3: Day 1-4ï¼ˆXBRLãƒ‘ãƒ¼ã‚¹ï¼‰**
```yaml
tasks:
  - id: "IMPL-011"
    name: "XBRLãƒ‘ãƒ¼ã‚µãƒ¼å®Ÿè£…"
    file: "scripts/parse_xbrl.py"
    details:
      - "lxml ã§XMLè§£æ"
      - "è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆè³‡ç”£ãƒ»è² å‚µãƒ»æç›Šï¼‰"
      - "ã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰"
      - "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå‹ãƒ»ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼‰"
    code_structure: |
      def parse_xbrl_file(file_path: str) -> Dict:
          """XBRLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹"""
          # 1. XMLãƒ‘ãƒ¼ã‚¹
          # 2. åå‰ç©ºé–“è§£æ±º
          # 3. è²¡å‹™é …ç›®æŠ½å‡º
          # 4. å˜ä½çµ±ä¸€ï¼ˆç™¾ä¸‡å††ï¼‰
          # 5. ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    acceptance:
      - "python scripts/parse_xbrl.py --input data/raw/xbrl --output data/normalized"
      - "data/normalized/ ã«JSONä¿å­˜"
      - "ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ç‡ < 1%"
    assigned: "AI (Claude)"
  
  - id: "IMPL-012"
    name: "XBRLãƒ‘ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_parse.py"
    details:
      - "ã‚µãƒ³ãƒ—ãƒ«XBRLä½œæˆ"
      - "å…¨è²¡å‹™é …ç›®æŠ½å‡ºãƒ†ã‚¹ãƒˆ"
      - "ç•°å¸¸å€¤æ¤œå‡ºãƒ†ã‚¹ãƒˆ"
    acceptance:
      - "pytest tests/test_parse.py -v ã§å…¨åˆæ ¼"
      - "ã‚«ãƒãƒ¬ãƒƒã‚¸ 100%"
    assigned: "AI (Claude)"
```

**Week 3: Day 5-7ï¼ˆDBã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰**
```yaml
tasks:
  - id: "IMPL-013"
    name: "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼"
    file: "scripts/import_to_db.py"
    details:
      - "æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
      - "ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†"
      - "é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆUNIQUEåˆ¶ç´„ï¼‰"
      - "å¤–éƒ¨ã‚­ãƒ¼æ•´åˆæ€§ç¢ºèª"
    code_structure: |
      def import_to_database(db_path: str, input_dir: str):
          """æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
          # 1. ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹
          # 2. companies ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°
          # 3. financials ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°
          # 4. stock_prices ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°
          # 5. ã‚³ãƒŸãƒƒãƒˆ
    acceptance:
      - "python scripts/import_to_db.py --db data/db/stock-analysis.db --input data/normalized"
      - "SELECT COUNT(*) FROM financials > 0"
    assigned: "AI (Claude)"
  
  - id: "IMPL-014"
    name: "ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"
    file: "tests/test_import.py"
    details:
      - "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ"
      - "ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"
      - "é‡è¤‡æŒ¿å…¥ãƒ†ã‚¹ãƒˆ"
    acceptance:
      - "pytest tests/test_import.py -v ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

---

### ãƒ•ã‚§ãƒ¼ã‚º3: è§£æã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…ï¼ˆWeek 4-5å‰åŠï¼‰

```mermaid
flowchart LR
    A[NetNetè¨ˆç®—] --> B[ã‚ªãƒ‹ãƒ¼ãƒ«è¨ˆç®—]
    B --> C[å¤©äº•æ¤œå‡º]
    C --> D[è§£æå®Œæˆ]
    
    style A fill:#c8e6c9
    style B fill:#fff9c4
    style C fill:#ffccbc
    style D fill:#e1bee7
```

**Week 4: Day 1-3ï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆPBRï¼‰**
```yaml
tasks:
  - id: "IMPL-015"
    name: "NetNetPBRè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"
    file: "scripts/analyzers/netnet.py"
    details:
      - "å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£è¨ˆç®—"
      - "å‰²å¼•ç‡é©ç”¨ï¼ˆç¾é‡‘100%, æœ‰ä¾¡è¨¼åˆ¸80%, å£²æ›é‡‘70%, æ£šå¸50%ï¼‰"
      - "ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£è¨ˆç®—"
      - "NetNetPBRè¨ˆç®—"
      - "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆ"
    formula: |
      NetNetPBR = æ™‚ä¾¡ç·é¡ / (å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£ - ç·è² å‚µ)
    code_structure: |
      def calculate_net_net_pbr(company_id: str, params: dict) -> float:
          # 1. æœ€æ–°è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—
          # 2. å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£è¨ˆç®—
          # 3. ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£è¨ˆç®—
          # 4. æ™‚ä¾¡ç·é¡å–å¾—
          # 5. NetNetPBRè¨ˆç®—
          # 6. ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯
    acceptance:
      - "æ±äº¬é›»åŠ›ã®NetNetPBRè¨ˆç®—ãŒæ‰‹è¨ˆç®—ã¨èª¤å·®0.01%ä»¥å†…"
      - "NetNetPBR < 1.0 ã®éŠ˜æŸ„ã‚’æŠ½å‡º"
    assigned: "AI (Claude)"
  
  - id: "IMPL-016"
    name: "NetNetãƒ†ã‚¹ãƒˆ"
    file: "tests/test_netnet.py"
    details:
      - "è¨ˆç®—ç²¾åº¦ãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒ³ãƒ—ãƒ«10éŠ˜æŸ„ï¼‰"
      - "ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆè² å‚µè¶…éç­‰ï¼‰"
    acceptance:
      - "pytest tests/test_netnet.py -v ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

**Week 4: Day 4-7ï¼ˆã‚ªãƒ‹ãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ï¼‰**
```yaml
tasks:
  - id: "IMPL-017"
    name: "ã‚ªãƒ‹ãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼å®Ÿè£…"
    file: "scripts/analyzers/oneil.py"
    details:
      - "EPSæˆé•·ç‡è¨ˆç®—ï¼ˆ3å¹´ã€5å¹´ï¼‰"
      - "ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹è¨ˆç®—ï¼ˆ52é€±ï¼‰"
      - "å£²ä¸Šé«˜æˆé•·ç‡è¨ˆç®—"
      - "åˆ©ç›Šç‡è¨ˆç®—"
      - "ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ¡ä»¶: EPSæˆé•·ç‡>20%ç­‰ï¼‰"
    formula: |
      RS = Normalize_0-100(æ ªä¾¡å¤‰åŒ–ç‡ / å¸‚å ´å¤‰åŒ–ç‡)
    code_structure: |
      def calculate_relative_strength(company_id: str, period_weeks: int = 52) -> float:
          # 1. æ ªä¾¡å–å¾—ï¼ˆ52é€±ï¼‰
          # 2. å¸‚å ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
          # 3. ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®—
          # 4. ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ©ãƒ³ã‚¯è¨ˆç®—
    acceptance:
      - "æ±äº¬é›»åŠ›ã®RSè¨ˆç®—ãŒæ­£ç¢º"
      - "EPSæˆé•·ç‡>20%ã®éŠ˜æŸ„ã‚’æŠ½å‡º"
    assigned: "AI (Claude)"
  
  - id: "IMPL-018"
    name: "ã‚ªãƒ‹ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_oneil.py"
    details:
      - "RSè¨ˆç®—ç²¾åº¦ãƒ†ã‚¹ãƒˆ"
      - "EPSæˆé•·ç‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ"
    acceptance:
      - "pytest tests/test_oneil.py -v ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

**Week 5: Day 1-3ï¼ˆãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡ºï¼‰**
```yaml
tasks:
  - id: "IMPL-019"
    name: "ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡ºå®Ÿè£…"
    file: "scripts/analyzers/market_top.py"
    details:
      - "åˆ†é…æ—¥åˆ¤å®šï¼ˆä¾¡æ ¼ä¸‹è½ & å‡ºæ¥é«˜å¢—åŠ ï¼‰"
      - "25æ—¥é–“ã®åˆ†é…æ—¥ã‚«ã‚¦ãƒ³ãƒˆ"
      - "è­¦å‘Šãƒˆãƒªã‚¬ãƒ¼ï¼ˆ5å›ä»¥ä¸Šï¼‰"
    code_structure: |
      def detect_market_top(lookback_days: int = 25, threshold: int = 5) -> dict:
          # 1. å¸‚å ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
          # 2. åˆ†é…æ—¥åˆ¤å®š
          # 3. ã‚«ã‚¦ãƒ³ãƒˆ
          # 4. è­¦å‘Šåˆ¤å®š
    acceptance:
      - "éå»10å¹´ãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦80%ä»¥ä¸Š"
    assigned: "AI (Claude)"
  
  - id: "IMPL-020"
    name: "ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_market_top.py"
    details:
      - "åˆ†é…æ—¥åˆ¤å®šãƒ†ã‚¹ãƒˆ"
      - "éå»ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"
    acceptance:
      - "pytest tests/test_market_top.py -v ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

---

### ãƒ•ã‚§ãƒ¼ã‚º4: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…ï¼ˆWeek 5å¾ŒåŠ-6ï¼‰

```mermaid
flowchart TB
    A[HTMLæ§‹é€ ] --> B[CSS ãƒ‡ã‚¶ã‚¤ãƒ³]
    B --> C[sqlite-wasmçµ±åˆ]
    C --> D[lightweight-chartsçµ±åˆ]
    D --> E[ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Œæˆ]
    
    style A fill:#e3f2fd
    style C fill:#fff9c4
    style D fill:#ffccbc
    style E fill:#c8e6c9
```

**Week 5: Day 4-7ï¼ˆHTML/CSSï¼‰**
```yaml
tasks:
  - id: "IMPL-021"
    name: "HTMLãƒšãƒ¼ã‚¸ä½œæˆ"
    files:
      - "src/index.html"
      - "src/pages/netnet.html"
      - "src/pages/oneil.html"
      - "src/pages/market-top.html"
    details:
      - "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³"
      - "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³"
      - "ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ "
      - "ãƒãƒ£ãƒ¼ãƒˆã‚³ãƒ³ãƒ†ãƒŠ"
    acceptance:
      - "å…¨ãƒšãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹"
      - "ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œç¢ºèª"
    assigned: "AI (Claude)"
  
  - id: "IMPL-022"
    name: "CSSã‚¹ã‚¿ã‚¤ãƒ«ä½œæˆ"
    file: "src/styles.css"
    details:
      - "CSS Grid ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ"
      - "ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆå®šç¾©"
      - "ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«"
      - "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ–ãƒ¬ãƒ¼ã‚¯ãƒã‚¤ãƒ³ãƒˆ"
    acceptance:
      - "Lighthouse Performance >= 90"
    assigned: "AI (Claude)"
```

**Week 6: Day 1-4ï¼ˆsqlite-wasmçµ±åˆï¼‰**
```yaml
tasks:
  - id: "IMPL-023"
    name: "sqlite-wasmçµ±åˆ"
    file: "src/db-loader.js"
    details:
      - "sqlite-wasmåˆæœŸåŒ–"
      - "DBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
      - "IndexedDBã‚­ãƒ£ãƒƒã‚·ãƒ¥"
      - "ã‚¯ã‚¨ãƒªå®Ÿè¡Œé–¢æ•°"
    code_structure: |
      class DatabaseLoader {
        async initialize(dbUrl) {
          // 1. sqlite-wasmåˆæœŸåŒ–
          // 2. DBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          // 3. IndexedDBã‚­ãƒ£ãƒƒã‚·ãƒ¥
        }
        
        query(sql, params = []) {
          // SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        }
      }
    acceptance:
      - "ãƒ–ãƒ©ã‚¦ã‚¶ã§DBãƒ­ãƒ¼ãƒ‰æˆåŠŸ"
      - "SELECT ã‚¯ã‚¨ãƒªå®Ÿè¡Œç¢ºèª"
    assigned: "AI (Claude)"
  
  - id: "IMPL-024"
    name: "ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯"
    file: "src/app.js"
    details:
      - "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«æç”»"
      - "ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½"
      - "ã‚½ãƒ¼ãƒˆæ©Ÿèƒ½"
    acceptance:
      - "NetNetãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒè¡¨ç¤ºã•ã‚Œã‚‹"
      - "ã‚½ãƒ¼ãƒˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿å‹•ä½œç¢ºèª"
    assigned: "AI (Claude)"
```

**Week 6: Day 5-7ï¼ˆãƒãƒ£ãƒ¼ãƒˆçµ±åˆï¼‰**
```yaml
tasks:
  - id: "IMPL-025"
    name: "lightweight-chartsçµ±åˆ"
    file: "src/chart-renderer.js"
    details:
      - "ãƒãƒ£ãƒ¼ãƒˆåˆæœŸåŒ–"
      - "PBRæ¨ç§»ãƒãƒ£ãƒ¼ãƒˆ"
      - "æ±ºç®—ç™ºè¡¨ãƒãƒ¼ã‚«ãƒ¼"
      - "èƒŒæ™¯è‰²ã‚·ã‚°ãƒŠãƒ«"
    code_structure: |
      class ChartRenderer {
        renderPBRHistory(data) {
          // 1. ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
          # 2. ãƒ‡ãƒ¼ã‚¿è¨­å®š
          # 3. ãƒãƒ¼ã‚«ãƒ¼è¿½åŠ 
        }
      }
    acceptance:
      - "æ±äº¬é›»åŠ›ã®PBRæ¨ç§»ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º"
      - "1000ãƒã‚¤ãƒ³ãƒˆã§500msä»¥å†…æç”»"
    assigned: "AI (Claude)"
  
  - id: "IMPL-026"
    name: "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_frontend.js"
    details:
      - "ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆJestï¼‰"
      - "E2Eãƒ†ã‚¹ãƒˆï¼ˆPlaywrightï¼‰"
    acceptance:
      - "npm test ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

---

### ãƒ•ã‚§ãƒ¼ã‚º5: è‡ªå‹•åŒ–ãƒ»é€šçŸ¥ï¼ˆWeek 7ï¼‰

```mermaid
flowchart LR
    A[GitHub Actions<br/>ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼] --> B[é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ]
    B --> C[ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°]
    C --> D[è‡ªå‹•åŒ–å®Œæˆ]
    
    style A fill:#fff9c4
    style B fill:#ffccbc
    style D fill:#c8e6c9
```

**Week 7: Day 1-3ï¼ˆGitHub Actionsï¼‰**
```yaml
tasks:
  - id: "IMPL-027"
    name: "æ—¥æ¬¡ãƒãƒƒãƒãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
    file: ".github/workflows/daily-update.yml"
    details:
      - "cronè¨­å®šï¼ˆ0 9 * * *ï¼‰"
      - "ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
      - "ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ãƒ‘ãƒ¼ã‚¹ãƒ»è§£æ"
      - "DBæ›´æ–°ãƒ»LFSã‚³ãƒŸãƒƒãƒˆ"
    yaml_structure: |
      name: Daily Stock Analysis Update
      
      on:
        schedule:
          - cron: '0 9 * * *'  # æ—¥æœ¬æ™‚é–“18æ™‚ï¼ˆUTC+9ï¼‰
        workflow_dispatch:      # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
      
      jobs:
        update-analysis:
          runs-on: ubuntu-latest
          timeout-minutes: 60
          
          steps:
            - name: Checkout repository
              uses: actions/checkout@v4
              with:
                lfs: true
            
            - name: Setup Python
              uses: actions/setup-python@v5
              with:
                python-version: '3.11'
                cache: 'pip'
            
            - name: Install dependencies
              run: |
                pip install -r requirements.txt
            
            - name: Fetch XBRL files
              run: |
                python scripts/fetch_xbrl.py \
                  --db data/db/stock-analysis.db \
                  --output data/raw/xbrl \
                  --rate 1.0
            
            - name: Fetch stock prices
              run: |
                python scripts/fetch_prices.py \
                  --db data/db/stock-analysis.db \
                  --output data/raw/prices
            
            - name: Parse XBRL files
              run: |
                python scripts/parse_xbrl.py \
                  --input data/raw/xbrl \
                  --output data/normalized
            
            - name: Import to database
              run: |
                python scripts/import_to_db.py \
                  --db data/db/stock-analysis.db \
                  --input data/normalized
            
            - name: Run analysis
              run: |
                python scripts/analyzers/netnet.py --db data/db/stock-analysis.db
                python scripts/analyzers/oneil.py --db data/db/stock-analysis.db
                python scripts/analyzers/market_top.py --db data/db/stock-analysis.db
            
            - name: Send notifications
              env:
                GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
              run: |
                python scripts/notify.py --db data/db/stock-analysis.db
            
            - name: Compress database
              run: |
                gzip -9 -k data/db/stock-analysis.db
            
            - name: Update DB version
              run: |
                echo "$(date +%Y-%m-%d)" > src/db-version.txt
            
            - name: Commit and push
              run: |
                git config user.name "GitHub Actions Bot"
                git config user.email "actions@github.com"
                git add data/db/stock-analysis.db
                git add data/db/stock-analysis.db.gz
                git add src/db-version.txt
                git commit -m "Daily update: $(date +%Y-%m-%d)" || echo "No changes"
                git push
            
            - name: Upload artifact
              uses: actions/upload-artifact@v4
              with:
                name: stock-analysis-db-${{ github.run_number }}
                path: data/db/stock-analysis.db
                retention-days: 30
    acceptance:
      - "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ‰‹å‹•å®Ÿè¡ŒæˆåŠŸ"
      - "å®Ÿè¡Œæ™‚é–“ < 30åˆ†"
      - "DBæ›´æ–°ç¢ºèªï¼ˆgit logï¼‰"
    assigned: "AI (Claude)"
  
  - id: "IMPL-028"
    name: "ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
    file: ".github/workflows/deploy.yml"
    details:
      - "GitHub Pages ãƒ‡ãƒ—ãƒ­ã‚¤"
      - "ãƒ“ãƒ«ãƒ‰æˆæœç‰©ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
    yaml_structure: |
      name: Deploy to GitHub Pages
      
      on:
        push:
          branches:
            - main
          paths:
            - 'src/**'
            - 'data/db/stock-analysis.db'
      
      permissions:
        contents: read
        pages: write
        id-token: write
      
      jobs:
        build:
          runs-on: ubuntu-latest
          
          steps:
            - name: Checkout
              uses: actions/checkout@v4
              with:
                lfs: true
            
            - name: Setup Pages
              uses: actions/configure-pages@v4
            
            - name: Build
              run: |
                mkdir -p _site
                cp -r src/* _site/
                cp data/db/stock-analysis.db _site/data/
                cp data/db/stock-analysis.db.gz _site/data/
            
            - name: Upload artifact
              uses: actions/upload-pages-artifact@v3
        
        deploy:
          runs-on: ubuntu-latest
          needs: build
          environment:
            name: github-pages
            url: ${{ steps.deployment.outputs.page_url }}
          
          steps:
            - name: Deploy to GitHub Pages
              id: deployment
              uses: actions/deploy-pages@v4
    acceptance:
      - "src/ ã®å¤‰æ›´ã§è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤"
      - "https://j1921604.github.io/stock-analysis/ ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½"
    assigned: "AI (Claude)"
```

**Week 7: Day 4-5ï¼ˆé€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ï¼‰**
```yaml
tasks:
  - id: "IMPL-029"
    name: "GitHub Issueé€šçŸ¥å®Ÿè£…"
    file: "scripts/notify.py"
    details:
      - "æ–°è¦éŠ˜æŸ„æ¤œå‡º"
      - "Issueæœ¬æ–‡ç”Ÿæˆ"
      - "ãƒ©ãƒ™ãƒ«ä»˜ä¸"
      - "é€šçŸ¥å±¥æ­´DBä¿å­˜"
    code_structure: |
      class NotificationManager:
        def create_notification(self, candidates: List[Dict]):
          # 1. Issueä½œæˆ
          # 2. æœ¬æ–‡ç”Ÿæˆ
          # 3. DBä¿å­˜
    acceptance:
      - "æ–°è¦éŠ˜æŸ„ã§Issueè‡ªå‹•ä½œæˆ"
      - "é‡è¤‡Issueä½œæˆãªã—"
    assigned: "AI (Claude)"
  
  - id: "IMPL-030"
    name: "é€šçŸ¥ãƒ†ã‚¹ãƒˆ"
    file: "tests/test_notify.py"
    details:
      - "Issueä½œæˆãƒ†ã‚¹ãƒˆ"
      - "é‡è¤‡é˜²æ­¢ãƒ†ã‚¹ãƒˆ"
    acceptance:
      - "pytest tests/test_notify.py -v ã§å…¨åˆæ ¼"
    assigned: "AI (Claude)"
```

**Week 7: Day 6-7ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»æœ€çµ‚ç¢ºèªï¼‰**
```yaml
tasks:
  - id: "IMPL-031"
    name: "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–"
    files:
      - "scripts/*.py"
    details:
      - "å…¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«try-exceptè¿½åŠ "
      - "ãƒ­ã‚°å‡ºåŠ›å®Ÿè£…"
      - "ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯"
    acceptance:
      - "ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ç¶™ç¶šå®Ÿè¡Œ"
      - "ãƒ­ã‚°ãŒé©åˆ‡ã«å‡ºåŠ›"
    assigned: "AI (Claude)"
  
  - id: "IMPL-032"
    name: "çµ±åˆãƒ†ã‚¹ãƒˆ"
    file: "tests/test_integration.py"
    details:
      - "ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"
      - "å…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"
    acceptance:
      - "pytest tests/test_integration.py -v ã§å…¨åˆæ ¼"
      - "ã‚«ãƒãƒ¬ãƒƒã‚¸ 100%"
    assigned: "AI (Claude)"
```

---

## ã‚¿ã‚¹ã‚¯åˆ†è§£

### ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
flowchart TB
    subgraph external["å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ "]
        EDINET[EDINET API<br/>XBRLãƒ•ã‚¡ã‚¤ãƒ«]
        STOCK_API[æ ªä¾¡API<br/>æ—¥æ¬¡OHLCV]
    end
    
    subgraph data_ingestion["ãƒ‡ãƒ¼ã‚¿å–å¾—å±¤"]
        FETCH_XBRL[fetch_xbrl.py<br/>XBRLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰]
        FETCH_PRICES[fetch_prices.py<br/>æ ªä¾¡ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰]
        PARSE[parse_xbrl.py<br/>XBRLè§£æ]
    end
    
    subgraph storage["ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å±¤"]
        RAW_DATA[data/raw/<br/>ç”Ÿãƒ‡ãƒ¼ã‚¿]
        NORMALIZED[data/normalized/<br/>æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿]
        DB[(SQLite<br/>stock-analysis.db)]
    end
    
    subgraph analytics["è§£æå±¤"]
        NETNET[netnet.py<br/>NetNetPBRè¨ˆç®—]
        ONEIL[oneil.py<br/>ã‚ªãƒ‹ãƒ¼ãƒ«è¨ˆç®—]
        MARKET_TOP[market_top.py<br/>å¤©äº•æ¤œå‡º]
    end
    
    subgraph presentation["ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å±¤"]
        HTML[index.html<br/>ãƒšãƒ¼ã‚¸æ§‹é€ ]
        WASM[sqlite-wasm<br/>DBèª­è¾¼]
        CHARTS[lightweight-charts<br/>ãƒãƒ£ãƒ¼ãƒˆæç”»]
        BROWSER[ãƒ–ãƒ©ã‚¦ã‚¶<br/>ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼]
    end
    
    subgraph automation["è‡ªå‹•åŒ–å±¤"]
        ACTIONS[GitHub Actions<br/>æ—¥æ¬¡ãƒãƒƒãƒ]
        NOTIFY[notify.py<br/>Issueé€šçŸ¥]
    end
    
    EDINET --> FETCH_XBRL
    STOCK_API --> FETCH_PRICES
    FETCH_XBRL --> RAW_DATA
    FETCH_PRICES --> RAW_DATA
    RAW_DATA --> PARSE
    PARSE --> NORMALIZED
    NORMALIZED --> DB
    DB --> NETNET
    DB --> ONEIL
    DB --> MARKET_TOP
    NETNET --> NOTIFY
    ONEIL --> NOTIFY
    MARKET_TOP --> NOTIFY
    NOTIFY --> ACTIONS
    DB --> WASM
    WASM --> HTML
    HTML --> CHARTS
    CHARTS --> BROWSER
    ACTIONS --> FETCH_XBRL
    ACTIONS --> FETCH_PRICES
    
    style external fill:#ffe0b2
    style data_ingestion fill:#fff9c4
    style storage fill:#c8e6c9
    style analytics fill:#b3e5fc
    style presentation fill:#f8bbd0
    style automation fill:#e1bee7
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è©³ç´°

```mermaid
flowchart LR
    A[EDINET<br/>XBRLæå‡º] --> B{å·®åˆ†åˆ¤å®š}
    B -->|æ–°è¦| C[ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰<br/>1ç§’/ãƒ•ã‚¡ã‚¤ãƒ«]
    B -->|æ—¢å­˜| Z[ã‚¹ã‚­ãƒƒãƒ—]
    C --> D[lxmlè§£æ]
    D --> E[ã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°]
    E --> F{ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³}
    F -->|OK| G[æ­£è¦åŒ–JSON]
    F -->|NG| H[ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°]
    G --> I[DB INSERT]
    I --> J[NetNetè¨ˆç®—]
    J --> K[ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°]
    K --> L{æ–°è¦å€™è£œ?}
    L -->|Yes| M[Issueä½œæˆ]
    L -->|No| N[å¾…æ©Ÿ]
    
    style A fill:#ffe0b2
    style D fill:#fff9c4
    style G fill:#c8e6c9
    style J fill:#b3e5fc
    style M fill:#f8bbd0
```

### ã‚¿ã‚¹ã‚¯ä¸€è¦§ï¼ˆå…¨32ã‚¿ã‚¹ã‚¯ï¼‰

```mermaid
flowchart TB
    subgraph phase1["Phase 1: åŸºç›¤æ§‹ç¯‰"]
        T001[IMPL-001: Pythonç’°å¢ƒ]
        T002[IMPL-002: Git/GitHub]
        T003[IMPL-003: SQLiteã‚¹ã‚­ãƒ¼ãƒ]
        T004[IMPL-004: DBåˆæœŸåŒ–]
        T005[IMPL-005: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª]
        T006[IMPL-006: requirements.txt]
    end
    
    subgraph phase2["Phase 2: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"]
        T007[IMPL-007: XBRLå–å¾—]
        T008[IMPL-008: XBRLãƒ†ã‚¹ãƒˆ]
        T009[IMPL-009: æ ªä¾¡å–å¾—]
        T010[IMPL-010: æ ªä¾¡ãƒ†ã‚¹ãƒˆ]
        T011[IMPL-011: XBRLãƒ‘ãƒ¼ã‚¹]
        T012[IMPL-012: ãƒ‘ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ]
        T013[IMPL-013: DBã‚¤ãƒ³ãƒãƒ¼ãƒˆ]
        T014[IMPL-014: ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ]
    end
    
    subgraph phase3["Phase 3: è§£æã‚¨ãƒ³ã‚¸ãƒ³"]
        T015[IMPL-015: NetNetè¨ˆç®—]
        T016[IMPL-016: NetNetãƒ†ã‚¹ãƒˆ]
        T017[IMPL-017: ã‚ªãƒ‹ãƒ¼ãƒ«è¨ˆç®—]
        T018[IMPL-018: ã‚ªãƒ‹ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ]
        T019[IMPL-019: å¤©äº•æ¤œå‡º]
        T020[IMPL-020: å¤©äº•ãƒ†ã‚¹ãƒˆ]
    end
    
    subgraph phase4["Phase 4: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰"]
        T021[IMPL-021: HTMLä½œæˆ]
        T022[IMPL-022: CSSä½œæˆ]
        T023[IMPL-023: sqlite-wasm]
        T024[IMPL-024: ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º]
        T025[IMPL-025: ãƒãƒ£ãƒ¼ãƒˆ]
        T026[IMPL-026: FEãƒ†ã‚¹ãƒˆ]
    end
    
    subgraph phase5["Phase 5: è‡ªå‹•åŒ–"]
        T027[IMPL-027: Actionsæ—¥æ¬¡]
        T028[IMPL-028: Actionsãƒ‡ãƒ—ãƒ­ã‚¤]
        T029[IMPL-029: é€šçŸ¥]
        T030[IMPL-030: é€šçŸ¥ãƒ†ã‚¹ãƒˆ]
        T031[IMPL-031: ã‚¨ãƒ©ãƒ¼å¯¾å¿œ]
        T032[IMPL-032: çµ±åˆãƒ†ã‚¹ãƒˆ]
    end
    
    phase1 --> phase2
    phase2 --> phase3
    phase3 --> phase4
    phase4 --> phase5
    
    style phase1 fill:#e3f2fd
    style phase2 fill:#fff9c4
    style phase3 fill:#c8e6c9
    style phase4 fill:#ffccbc
    style phase5 fill:#e1bee7
```

### ã‚¿ã‚¹ã‚¯ä¾å­˜é–¢ä¿‚

```yaml
dependencies:
  IMPL-003:
    depends_on: []
    blocks: [IMPL-004, IMPL-013]
  
  IMPL-007:
    depends_on: [IMPL-004]
    blocks: [IMPL-011]
  
  IMPL-009:
    depends_on: [IMPL-004]
    blocks: [IMPL-013]
  
  IMPL-011:
    depends_on: [IMPL-007]
    blocks: [IMPL-013]
  
  IMPL-013:
    depends_on: [IMPL-003, IMPL-009, IMPL-011]
    blocks: [IMPL-015, IMPL-017, IMPL-019]
  
  IMPL-015:
    depends_on: [IMPL-013]
    blocks: [IMPL-029]
  
  IMPL-023:
    depends_on: [IMPL-013]
    blocks: [IMPL-024, IMPL-025]
  
  IMPL-027:
    depends_on: [IMPL-007, IMPL-009, IMPL-011, IMPL-013, IMPL-015, IMPL-017, IMPL-019]
    blocks: []
```

---

## å®Ÿè£…å„ªå…ˆé †ä½

### ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹

```mermaid
flowchart LR
    A[IMPL-003<br/>ã‚¹ã‚­ãƒ¼ãƒ] --> B[IMPL-007<br/>XBRLå–å¾—]
    B --> C[IMPL-011<br/>ãƒ‘ãƒ¼ã‚¹]
    C --> D[IMPL-013<br/>ã‚¤ãƒ³ãƒãƒ¼ãƒˆ]
    D --> E[IMPL-015<br/>NetNetè¨ˆç®—]
    E --> F[IMPL-027<br/>Actions]
    
    style A fill:#ff6b6b
    style B fill:#ff6b6b
    style C fill:#ff6b6b
    style D fill:#ff6b6b
    style E fill:#ff6b6b
    style F fill:#ff6b6b
```

**å„ªå…ˆåº¦å®šç¾©**:
```yaml
priority_levels:
  critical:
    description: "ã‚·ã‚¹ãƒ†ãƒ ã‚³ã‚¢æ©Ÿèƒ½ã€é…å»¶ä¸å¯"
    tasks:
      - IMPL-003  # ã‚¹ã‚­ãƒ¼ãƒ
      - IMPL-007  # XBRLå–å¾—
      - IMPL-011  # ãƒ‘ãƒ¼ã‚¹
      - IMPL-013  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
      - IMPL-015  # NetNetè¨ˆç®—
      - IMPL-027  # GitHub Actions
    color: "#ff6b6b"
  
  high:
    description: "ä¸»è¦æ©Ÿèƒ½ã€Week 7ã¾ã§ã«å¿…é ˆ"
    tasks:
      - IMPL-004  # DBåˆæœŸåŒ–
      - IMPL-009  # æ ªä¾¡å–å¾—
      - IMPL-017  # ã‚ªãƒ‹ãƒ¼ãƒ«
      - IMPL-023  # sqlite-wasm
      - IMPL-029  # é€šçŸ¥
    color: "#ffa500"
  
  medium:
    description: "è£œåŠ©æ©Ÿèƒ½ã€é…å»¶å¯èƒ½"
    tasks:
      - IMPL-019  # å¤©äº•æ¤œå‡º
      - IMPL-021  # HTML
      - IMPL-025  # ãƒãƒ£ãƒ¼ãƒˆ
    color: "#4ecdc4"
  
  low:
    description: "ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€å¾Œå›ã—å¯"
    tasks:
      - IMPL-026  # FEãƒ†ã‚¹ãƒˆ
      - IMPL-030  # é€šçŸ¥ãƒ†ã‚¹ãƒˆ
    color: "#95e1d3"
```

---

## æŠ€è¡“é¸å®š

### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯è©³ç´°

**ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆPythonï¼‰**:
```yaml
core:
  language: "Python 3.11"
  reason: "å‹ãƒ’ãƒ³ãƒˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€é•·æœŸã‚µãƒãƒ¼ãƒˆ"
  features:
    - "PEP 673: Selfå‹ï¼ˆã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰å‹å®‰å…¨æ€§ï¼‰"
    - "PEP 646: å¯å¤‰é•·ã‚¸ã‚§ãƒãƒªã‚¯ã‚¹ï¼ˆNumPyå‹æ³¨é‡ˆï¼‰"
    - "PEP 680: tomllibæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª"
    - "æœ€é©åŒ–: é–¢æ•°å‘¼ã³å‡ºã—10-25%é«˜é€ŸåŒ–"

data_processing:
  pandas: "2.0.3"
  numpy: "1.24.3"
  lxml: "4.9.3"
  reason: "XBRLè§£æã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª"
  usage_examples:
    pandas:
      - "è²¡å‹™ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ï¼ˆDataFrame.pivot_tableï¼‰"
      - "æ¬ æå€¤å‡¦ç†ï¼ˆDataFrame.fillnaï¼‰"
      - "æ™‚ç³»åˆ—ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆDataFrame.resampleï¼‰"
    numpy:
      - "NetNetPBRè¨ˆç®—ï¼ˆé…åˆ—æ¼”ç®—ï¼‰"
      - "ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹æ­£è¦åŒ–"
      - "çµ±è¨ˆé‡è¨ˆç®—ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ï¼‰"
    lxml:
      - "XBRLåå‰ç©ºé–“è§£æ±º"
      - "XPathè²¡å‹™é …ç›®æŠ½å‡º"
      - "å¤§å®¹é‡XMLé«˜é€Ÿãƒ‘ãƒ¼ã‚¹"

networking:
  requests: "2.31.0"
  reason: "HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€EDINETã‚¢ã‚¯ã‚»ã‚¹"
  features:
    - "ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥ï¼ˆurllib3.util.retryï¼‰"
    - "ã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨ï¼ˆæ¥ç¶šãƒ—ãƒ¼ãƒ«ï¼‰"
    - "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆconnect/readï¼‰"

testing:
  pytest: "7.4.0"
  pytest-cov: "4.1.0"
  pytest-mock: "3.11.1"
  reason: "ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸100%é”æˆ"
  plugins:
    - "pytest-xdist: ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"
    - "pytest-timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ¤œå‡º"
    - "pytest-benchmark: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"

quality:
  flake8: "6.0.0"
  mypy: "1.4.1"
  black: "23.7.0"
  reason: "ã‚³ãƒ¼ãƒ‰å“è³ªã€å‹ãƒã‚§ãƒƒã‚¯ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"
  additional:
    isort: "5.12.0"  # importæ–‡ã‚½ãƒ¼ãƒˆ
    pylint: "2.17.5"  # é«˜åº¦ãªé™çš„è§£æ
    radon: "6.0.1"    # è¤‡é›‘åº¦è¨ˆæ¸¬
```

**ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆJavaScriptï¼‰**:
```yaml
core:
  javascript: "ES2022+"
  reason: "ãƒ¢ãƒ€ãƒ³ãƒ–ãƒ©ã‚¦ã‚¶å¯¾å¿œã€async/awaitä½¿ç”¨"
  features:
    - "Top-level awaitï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«éåŒæœŸï¼‰"
    - "Array.at() ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè² ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰"
    - "Object.hasOwn()ï¼ˆãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒã‚§ãƒ¼ãƒ³å›é¿ï¼‰"
    - "Error.causeï¼ˆã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒ¼ãƒ³ï¼‰"
  browser_support:
    - "Chrome 90+"
    - "Firefox 89+"
    - "Safari 15.4+"
    - "Edge 90+"

database:
  sqlite_wasm: "3.43.0"
  url: "https://sql.js.org/dist/sql-wasm.js"
  reason: "ãƒ–ãƒ©ã‚¦ã‚¶å†…SQLiteã€ã‚µãƒ¼ãƒãƒ¼ä¸è¦"
  performance:
    - "WASM: Nativeé€Ÿåº¦ã®80-95%"
    - "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: DBå®¹é‡ã®2-3å€"
    - "åˆæœŸåŒ–: 100msä»¥ä¸‹"
  code_example: |
    import initSqlJs from 'sql-wasm.js';
    
    const SQL = await initSqlJs({
      locateFile: file => `/js/sql-wasm.wasm`
    });
    
    const response = await fetch('/data/stock-analysis.db');
    const buffer = await response.arrayBuffer();
    const db = new SQL.Database(new Uint8Array(buffer));

charts:
  lightweight_charts: "4.0.0"
  url: "https://unpkg.com/lightweight-charts@4.0.0"
  reason: "é«˜é€Ÿæç”»ï¼ˆ1000ãƒã‚¤ãƒ³ãƒˆ500msï¼‰"
  features:
    - "Canvasæç”»ï¼ˆé«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰"
    - "ãƒ”ãƒ³ãƒã‚ºãƒ¼ãƒ å¯¾å¿œ"
    - "ã‚¿ã‚¤ãƒ ã‚¹ã‚±ãƒ¼ãƒ«è‡ªå‹•èª¿æ•´"
    - "ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªãƒãƒ¼ã‚«ãƒ¼"
  code_example: |
    import { createChart } from 'lightweight-charts';
    
    const chart = createChart(container, {
      width: 800,
      height: 400,
      timeScale: { timeVisible: true, secondsVisible: false }
    });
    
    const lineSeries = chart.addLineSeries({
      color: '#2196F3',
      lineWidth: 2
    });
    
    lineSeries.setData([
      { time: '2024-01-01', value: 1.25 },
      { time: '2024-01-02', value: 1.28 }
    ]);

storage:
  indexeddb: "Native API"
  reason: "DBã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œ"
  capacity: "ãƒ–ãƒ©ã‚¦ã‚¶ç©ºãå®¹é‡ã®50%ã¾ã§"
  features:
    - "ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œ"
    - "éåŒæœŸAPIï¼ˆPromiseãƒ™ãƒ¼ã‚¹ï¼‰"
    - "è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"
  code_example: |
    // DBã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    const openRequest = indexedDB.open('StockAnalysisCache', 1);
    
    openRequest.onupgradeneeded = () => {
      const db = openRequest.result;
      db.createObjectStore('databases', { keyPath: 'version' });
    };
    
    openRequest.onsuccess = () => {
      const db = openRequest.result;
      const tx = db.transaction('databases', 'readwrite');
      tx.objectStore('databases').put({
        version: '2024-01-01',
        data: dbBuffer,
        timestamp: Date.now()
      });
    };

bundling:
  tool: "ãªã—ï¼ˆCDNåˆ©ç”¨ï¼‰"
  reason: "ãƒ“ãƒ«ãƒ‰ãƒ—ãƒ­ã‚»ã‚¹ä¸è¦ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ç°¡ç´ åŒ–"
  cdn:
    - "https://unpkg.com/ ï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰"
    - "https://cdn.jsdelivr.net/ ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"
  optimization:
    - "HTTP/2 ä¸¦åˆ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
    - "Brotliåœ§ç¸®ï¼ˆ70-80%å‰Šæ¸›ï¼‰"
    - "CDN ã‚¨ãƒƒã‚¸ã‚­ãƒ£ãƒƒã‚·ãƒ¥"
```

**ã‚¤ãƒ³ãƒ•ãƒ©ï¼ˆGitHubï¼‰**:
```yaml
hosting:
  github_pages:
    feature: "é™çš„ã‚µã‚¤ãƒˆãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°"
    cost: "ç„¡æ–™"
    bandwidth: "100GB/æœˆ"
    cdn: "ã‚°ãƒ­ãƒ¼ãƒãƒ«é…ä¿¡"
  
storage:
  github_lfs:
    feature: "å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†"
    cost: "ç„¡æ–™ï¼ˆ1GBï¼‰"
    file_size_limit: "2GB/ãƒ•ã‚¡ã‚¤ãƒ«"
  
  github_releases:
    feature: "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¿å­˜"
    cost: "ç„¡æ–™"
    size_limit: "åˆ¶é™ãªã—"
  
automation:
  github_actions:
    feature: "CI/CD"
    cost: "ç„¡æ–™ï¼ˆ2000åˆ†/æœˆï¼‰"
    concurrent_jobs: "20"
```

---

## é–‹ç™ºç’°å¢ƒæ§‹ç¯‰

### å®Ÿè£…ã‚³ãƒ¼ãƒ‰ä¾‹

**IMPL-007: EDINET XBRLå–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
```python
# scripts/fetch_xbrl.py
import requests
import sqlite3
import time
from datetime import datetime, timedelta
from typing import List, Dict
from pathlib import Path

class EDINETFetcher:
    """EDINET APIã‹ã‚‰XBRLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    
    BASE_URL = "https://disclosure.edinet-fsa.go.jp/api/v1"
    
    def __init__(self, db_path: str, output_dir: str, rate_limit: float = 1.0):
        self.db_path = Path(db_path)
        self.output_dir = Path(output_dir)
        self.rate_limiter = RateLimiter(rate_limit)
        self.session = requests.Session()
    
    def fetch_since_db(self) -> None:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€çµ‚æ›´æ–°æ—¥ä»¥é™ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        # 1. DBæœ€çµ‚æ›´æ–°æ—¥å–å¾—
        last_update = self._get_last_update_from_db()
        start_date = last_update + timedelta(days=1)
        end_date = datetime.now().date()
        
        print(f"å–å¾—æœŸé–“: {start_date} ~ {end_date}")
        
        # 2. æå‡ºæ›¸é¡ä¸€è¦§å–å¾—
        documents = self._get_document_list(start_date, end_date)
        print(f"å¯¾è±¡æ›¸é¡: {len(documents)}ä»¶")
        
        # 3. XBRLãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        for i, doc in enumerate(documents, 1):
            try:
                self.rate_limiter.acquire()
                self._download_xbrl(doc)
                print(f"[{i}/{len(documents)}] {doc['docID']} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼: {doc['docID']} - {e}")
    
    def _get_last_update_from_db(self) -> datetime.date:
        """DBã‹ã‚‰æœ€çµ‚æ›´æ–°æ—¥ã‚’å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT MAX(filing_date) FROM xbrl_files"
            )
            result = cursor.fetchone()[0]
            return datetime.fromisoformat(result).date() if result else datetime(2020, 1, 1).date()
    
    def _get_document_list(self, start_date: datetime.date, end_date: datetime.date) -> List[Dict]:
        """æå‡ºæ›¸é¡ä¸€è¦§å–å¾—"""
        documents = []
        current_date = start_date
        
        while current_date <= end_date:
            date_str = current_date.strftime("%Y-%m-%d")
            url = f"{self.BASE_URL}/documents.json"
            params = {
                "date": date_str,
                "type": 2  # XBRL
            }
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if data.get("results"):
                # æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã®ã¿ï¼ˆ120: æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ï¼‰
                docs = [
                    doc for doc in data["results"]
                    if doc.get("ordinanceCode") == "010" and doc.get("formCode") == "030000"
                ]
                documents.extend(docs)
            
            current_date += timedelta(days=1)
            time.sleep(0.1)  # APIè² è·è»½æ¸›
        
        return documents
    
    def _download_xbrl(self, doc: Dict) -> None:
        """XBRLãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        doc_id = doc["docID"]
        url = f"{self.BASE_URL}/documents/{doc_id}"
        params = {"type": 1}  # XBRLå½¢å¼
        
        # ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
        for attempt in range(3):
            try:
                response = self.session.get(url, params=params, timeout=60)
                response.raise_for_status()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                output_path = self.output_dir / f"{doc_id}.zip"
                output_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                
                break
            except requests.RequestException as e:
                if attempt == 2:
                    raise
                wait_time = 2 ** attempt
                print(f"ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/3 ({wait_time}ç§’å¾Œ)")
                time.sleep(wait_time)


class RateLimiter:
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…"""
    
    def __init__(self, rate: float):
        self.interval = 1.0 / rate
        self.last_call = 0.0
    
    def acquire(self) -> None:
        """ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¾…æ©Ÿï¼‰"""
        now = time.time()
        elapsed = now - self.last_call
        
        if elapsed < self.interval:
            time.sleep(self.interval - elapsed)
        
        self.last_call = time.time()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="EDINET XBRLãƒ•ã‚¡ã‚¤ãƒ«å–å¾—")
    parser.add_argument("--db", required=True, help="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹")
    parser.add_argument("--output", default="data/raw/xbrl", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--rate", type=float, default=1.0, help="ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆå›/ç§’ï¼‰")
    
    args = parser.parse_args()
    
    fetcher = EDINETFetcher(args.db, args.output, args.rate)
    fetcher.fetch_since_db()
```

**IMPL-015: NetNetPBRè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³**
```python
# scripts/analyzers/netnet.py
import sqlite3
from typing import Dict, List, Optional
from dataclasses import dataclass
import numpy as np

@dataclass
class NetNetPBRResult:
    """NetNetPBRè¨ˆç®—çµæœ"""
    company_id: str
    ticker: str
    name: str
    net_net_pbr: float
    net_net_assets: float
    market_cap: float
    filing_date: str
    rank: Optional[int] = None

class NetNetAnalyzer:
    """ãƒãƒƒãƒˆãƒãƒƒãƒˆPBRè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    # å‰²å¼•ç‡è¨­å®š
    DISCOUNT_RATES = {
        'cash': 1.00,              # ç¾é‡‘åŠã³é é‡‘: 100%
        'securities': 0.80,        # æœ‰ä¾¡è¨¼åˆ¸: 80%
        'receivables': 0.70,       # å£²æ›é‡‘: 70%
        'inventory': 0.50          # æ£šå¸è³‡ç”£: 50%
    }
    
    def __init__(self, db_path: str):
        self.db_path = db_path
    
    def calculate_all(self, params: Optional[Dict] = None) -> List[NetNetPBRResult]:
        """å…¨éŠ˜æŸ„ã®NetNetPBRè¨ˆç®—"""
        if params is None:
            params = self.DISCOUNT_RATES.copy()
        
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            # æœ€æ–°è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã¨æ ªä¾¡å–å¾—
            query = """
            WITH latest_financials AS (
                SELECT 
                    f.company_id,
                    f.cash,
                    f.securities,
                    f.accounts_receivable,
                    f.inventory,
                    f.total_liabilities,
                    f.filing_date,
                    ROW_NUMBER() OVER (
                        PARTITION BY f.company_id 
                        ORDER BY f.filing_date DESC
                    ) as rn
                FROM financials f
            ),
            latest_prices AS (
                SELECT 
                    p.company_id,
                    p.close_price,
                    p.shares_outstanding,
                    p.date,
                    ROW_NUMBER() OVER (
                        PARTITION BY p.company_id 
                        ORDER BY p.date DESC
                    ) as rn
                FROM stock_prices p
            )
            SELECT 
                c.company_id,
                c.ticker,
                c.name,
                lf.cash,
                lf.securities,
                lf.accounts_receivable,
                lf.inventory,
                lf.total_liabilities,
                lf.filing_date,
                lp.close_price,
                lp.shares_outstanding
            FROM companies c
            INNER JOIN latest_financials lf ON c.company_id = lf.company_id AND lf.rn = 1
            INNER JOIN latest_prices lp ON c.company_id = lp.company_id AND lp.rn = 1
            WHERE lf.cash IS NOT NULL
            """
            
            cursor = conn.execute(query)
            rows = cursor.fetchall()
        
        results = []
        for row in rows:
            try:
                result = self._calculate_single(row, params)
                if result and result.net_net_pbr > 0:  # æœ‰åŠ¹ãªå€¤ã®ã¿
                    results.append(result)
            except Exception as e:
                print(f"è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {row['ticker']} - {e}")
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ä¸
        results.sort(key=lambda x: x.net_net_pbr)
        for i, result in enumerate(results, 1):
            result.rank = i
        
        return results
    
    def _calculate_single(self, row: sqlite3.Row, params: Dict) -> NetNetPBRResult:
        """å˜ä¸€éŠ˜æŸ„ã®NetNetPBRè¨ˆç®—"""
        # 1. å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£è¨ˆç®—
        liquid_assets = (
            (row['cash'] or 0) * params['cash'] +
            (row['securities'] or 0) * params['securities'] +
            (row['accounts_receivable'] or 0) * params['receivables'] +
            (row['inventory'] or 0) * params['inventory']
        )
        
        # 2. ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£è¨ˆç®—
        total_liabilities = row['total_liabilities'] or 0
        net_net_assets = liquid_assets - total_liabilities
        
        # 3. æ™‚ä¾¡ç·é¡è¨ˆç®—
        market_cap = row['close_price'] * row['shares_outstanding']
        
        # 4. NetNetPBRè¨ˆç®—
        if net_net_assets <= 0:
            return None  # ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£ãŒè² ã®å ´åˆã¯é™¤å¤–
        
        net_net_pbr = market_cap / net_net_assets
        
        # 5. ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯
        if net_net_pbr < 0 or net_net_pbr > 10:
            return None
        
        return NetNetPBRResult(
            company_id=row['company_id'],
            ticker=row['ticker'],
            name=row['name'],
            net_net_pbr=net_net_pbr,
            net_net_assets=net_net_assets,
            market_cap=market_cap,
            filing_date=row['filing_date']
        )
    
    def screen(self, threshold: float = 1.0) -> List[NetNetPBRResult]:
        """NetNetPBR < threshold ã®éŠ˜æŸ„ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        all_results = self.calculate_all()
        return [r for r in all_results if r.net_net_pbr < threshold]


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="NetNetPBRè¨ˆç®—")
    parser.add_argument("--db", required=True, help="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹")
    parser.add_argument("--threshold", type=float, default=1.0, help="ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¾å€¤")
    
    args = parser.parse_args()
    
    analyzer = NetNetAnalyzer(args.db)
    results = analyzer.screen(args.threshold)
    
    print(f"\nNetNetPBR < {args.threshold} ã®éŠ˜æŸ„: {len(results)}ä»¶\n")
    print(f"{'Rank':<6}{'Ticker':<8}{'Name':<30}{'NetNetPBR':<12}{'NetNetè³‡ç”£':<15}{'æ™‚ä¾¡ç·é¡':<15}")
    print("-" * 90)
    
    for r in results[:50]:  # ä¸Šä½50éŠ˜æŸ„
        print(
            f"{r.rank:<6}"
            f"{r.ticker:<8}"
            f"{r.name:<30}"
            f"{r.net_net_pbr:>11.2f}"
            f"{r.net_net_assets:>14,.0f}"
            f"{r.market_cap:>14,.0f}"
        )
```

**IMPL-023: sqlite-wasmçµ±åˆï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼‰**
```javascript
// src/db-loader.js

class DatabaseLoader {
    constructor() {
        this.db = null;
        this.SQL = null;
        this.cacheDB = null;
        this.DB_VERSION = '2024-01-01'; // GitHub Actions ã§æ›´æ–°
    }

    async initialize(dbUrl) {
        try {
            // 1. IndexedDBåˆæœŸåŒ–
            await this.initIndexedDB();

            // 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            const cached = await this.getCachedDB();
            if (cached && cached.version === this.DB_VERSION) {
                console.log('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿');
                return await this.loadFromCache(cached.data);
            }

            // 3. æ–°è¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            console.log('æ–°è¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹');
            const dbData = await this.downloadDB(dbUrl);

            // 4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            await this.cacheDB(dbData);

            // 5. sqlite-wasmåˆæœŸåŒ–
            return await this.loadDatabase(dbData);
        } catch (error) {
            console.error('DBåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
            throw error;
        }
    }

    async initIndexedDB() {
        return new Promise((resolve, reject) => {
            const request = indexedDB.open('StockAnalysisCache', 1);

            request.onerror = () => reject(request.error);
            request.onsuccess = () => {
                this.cacheDB = request.result;
                resolve();
            };

            request.onupgradeneeded = (event) => {
                const db = event.target.result;
                if (!db.objectStoreNames.contains('databases')) {
                    db.createObjectStore('databases', { keyPath: 'version' });
                }
            };
        });
    }

    async getCachedDB() {
        return new Promise((resolve, reject) => {
            const tx = this.cacheDB.transaction('databases', 'readonly');
            const store = tx.objectStore('databases');
            const request = store.get(this.DB_VERSION);

            request.onsuccess = () => resolve(request.result);
            request.onerror = () => reject(request.error);
        });
    }

    async downloadDB(dbUrl) {
        const response = await fetch(dbUrl, {
            headers: {
                'Accept-Encoding': 'br, gzip, deflate'
            }
        });

        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        const contentLength = response.headers.get('Content-Length');
        console.log(`DB ã‚µã‚¤ã‚º: ${(contentLength / 1024 / 1024).toFixed(2)} MB`);

        // ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼å¯¾å¿œ
        const reader = response.body.getReader();
        const chunks = [];
        let receivedLength = 0;

        while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            chunks.push(value);
            receivedLength += value.length;

            const progress = (receivedLength / contentLength) * 100;
            this.updateProgress(progress);
        }

        // ArrayBufferã«çµåˆ
        const buffer = new Uint8Array(receivedLength);
        let position = 0;
        for (const chunk of chunks) {
            buffer.set(chunk, position);
            position += chunk.length;
        }

        return buffer;
    }

    async cacheDB(dbData) {
        return new Promise((resolve, reject) => {
            const tx = this.cacheDB.transaction('databases', 'readwrite');
            const store = tx.objectStore('databases');
            const request = store.put({
                version: this.DB_VERSION,
                data: dbData,
                timestamp: Date.now()
            });

            request.onsuccess = () => resolve();
            request.onerror = () => reject(request.error);
        });
    }

    async loadDatabase(dbData) {
        // sql-wasm.js èª­ã¿è¾¼ã¿
        const SQL = await initSqlJs({
            locateFile: file => `/js/${file}`
        });

        this.SQL = SQL;
        this.db = new SQL.Database(dbData);

        console.log('DBåˆæœŸåŒ–å®Œäº†');
        return this.db;
    }

    async loadFromCache(dbData) {
        return await this.loadDatabase(dbData);
    }

    query(sql, params = []) {
        if (!this.db) {
            throw new Error('DBæœªåˆæœŸåŒ–');
        }

        const stmt = this.db.prepare(sql);
        stmt.bind(params);

        const results = [];
        while (stmt.step()) {
            results.push(stmt.getAsObject());
        }
        stmt.free();

        return results;
    }

    queryRow(sql, params = []) {
        const results = this.query(sql, params);
        return results.length > 0 ? results[0] : null;
    }

    updateProgress(progress) {
        const progressBar = document.getElementById('db-progress');
        if (progressBar) {
            progressBar.style.width = `${progress}%`;
            progressBar.textContent = `${progress.toFixed(1)}%`;
        }
    }

    close() {
        if (this.db) {
            this.db.close();
        }
    }
}

// Export
export default DatabaseLoader;
```

### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```powershell
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/J1921604/stock-analysis.git
cd stock-analysis

# 2. å®Ÿè£…ãƒ–ãƒ©ãƒ³ãƒã«åˆ‡ã‚Šæ›¿ãˆ
git checkout feature/impl-001-stock-analysis-system

# 3. LFSåˆæœŸåŒ–
git lfs install
git lfs pull

# 4. Pythonä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv
.\venv\Scripts\Activate.ps1

# 5. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
python scripts/init_db.py

# 7. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
tree /F
```

### é–‹ç™ºãƒ„ãƒ¼ãƒ«

```yaml
ide:
  vscode:
    extensions:
      - "ms-python.python"
      - "ms-python.vscode-pylance"
      - "ms-toolsai.jupyter"
      - "esbenp.prettier-vscode"
      - "dbaeumer.vscode-eslint"
    settings:
      python.linting.enabled: true
      python.linting.flake8Enabled: true
      python.formatting.provider: "black"
      editor.formatOnSave: true

browser_dev:
  chrome_devtools:
    features:
      - "Network ã‚¿ãƒ–ï¼ˆDB DLç¢ºèªï¼‰"
      - "Performance ã‚¿ãƒ–ï¼ˆæ¸¬å®šï¼‰"
      - "Application ã‚¿ãƒ–ï¼ˆIndexedDBç¢ºèªï¼‰"
  
  lighthouse:
    metrics:
      - "Performance >= 90"
      - "Accessibility >= 95"
      - "Best Practices >= 90"

version_control:
  git:
    config:
      user.name: "J1921604"
      user.email: "{email}"
      core.autocrlf: "false"
      lfs.locksverify: "true"
```

---

## å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆ

```mermaid
gantt
    title æ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ7é€±é–“ï¼‰
    dateFormat YYYY-MM-DD
    section Phase 1: åŸºç›¤
    ç’°å¢ƒæ§‹ç¯‰           :p1-1, 2025-11-22, 2d
    DBè¨­è¨ˆ            :p1-2, after p1-1, 2d
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€     :p1-3, after p1-2, 3d
    
    section Phase 2: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    XBRLå–å¾—          :p2-1, after p1-3, 3d
    æ ªä¾¡å–å¾—          :p2-2, after p2-1, 4d
    XBRLãƒ‘ãƒ¼ã‚¹        :p2-3, after p2-2, 4d
    DBã‚¤ãƒ³ãƒãƒ¼ãƒˆ       :p2-4, after p2-3, 3d
    
    section Phase 3: è§£æã‚¨ãƒ³ã‚¸ãƒ³
    NetNetè¨ˆç®—        :p3-1, after p2-4, 3d
    ã‚ªãƒ‹ãƒ¼ãƒ«è¨ˆç®—       :p3-2, after p3-1, 4d
    å¤©äº•æ¤œå‡º          :p3-3, after p3-2, 3d
    
    section Phase 4: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
    HTML/CSS         :p4-1, after p3-3, 4d
    sqlite-wasm      :p4-2, after p4-1, 4d
    ãƒãƒ£ãƒ¼ãƒˆçµ±åˆ       :p4-3, after p4-2, 3d
    
    section Phase 5: è‡ªå‹•åŒ–
    GitHub Actions   :p5-1, after p4-3, 3d
    é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ        :p5-2, after p5-1, 2d
    çµ±åˆãƒ†ã‚¹ãƒˆ        :p5-3, after p5-2, 2d
```

### ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³

```yaml
milestones:
  M1_foundation_complete:
    date: "2025-11-29"
    deliverables:
      - "SQLiteã‚¹ã‚­ãƒ¼ãƒå®Œæˆ"
      - "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ å®Œæˆ"
      - "requirements.txtå®Œæˆ"
    acceptance:
      - "python scripts/init_db.py æˆåŠŸ"
      - "SELECT * FROM companies å®Ÿè¡Œå¯èƒ½"
  
  M2_pipeline_complete:
    date: "2025-12-13"
    deliverables:
      - "XBRLå–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Œæˆ"
      - "æ ªä¾¡å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Œæˆ"
      - "XBRLãƒ‘ãƒ¼ã‚µãƒ¼å®Œæˆ"
      - "DBã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼å®Œæˆ"
    acceptance:
      - "æ±äº¬é›»åŠ›ãƒ»ä¸­éƒ¨é›»åŠ›ã®ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ"
      - "data/db/stock-analysis.db ã«ãƒ‡ãƒ¼ã‚¿æ ¼ç´"
  
  M3_analysis_complete:
    date: "2025-12-20"
    deliverables:
      - "NetNetè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³å®Œæˆ"
      - "ã‚ªãƒ‹ãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼å®Œæˆ"
      - "å¤©äº•æ¤œå‡ºãƒ„ãƒ¼ãƒ«å®Œæˆ"
    acceptance:
      - "NetNetPBRè¨ˆç®—ãŒæ‰‹è¨ˆç®—ã¨ä¸€è‡´"
      - "EPSæˆé•·ç‡è¨ˆç®—ãŒæ­£ç¢º"
  
  M4_frontend_complete:
    date: "2025-12-27"
    deliverables:
      - "è§£æãƒšãƒ¼ã‚¸HTML/CSS/JSå®Œæˆ"
      - "sqlite-wasmçµ±åˆå®Œæˆ"
      - "ãƒãƒ£ãƒ¼ãƒˆæç”»å®Œæˆ"
    acceptance:
      - "ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º"
      - "Lighthouse Performance >= 90"
  
  M5_automation_complete:
    date: "2026-01-03"
    deliverables:
      - "GitHub Actionsæ—¥æ¬¡ãƒãƒƒãƒå®Œæˆ"
      - "é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ å®Œæˆ"
      - "çµ±åˆãƒ†ã‚¹ãƒˆå®Œæˆ"
    acceptance:
      - "æ—¥æ¬¡ãƒãƒƒãƒè‡ªå‹•å®Ÿè¡ŒæˆåŠŸ"
      - "ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ 100%"
```

---

## å“è³ªä¿è¨¼è¨ˆç”»

### ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

```mermaid
flowchart TB
    subgraph unit["ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆ100%ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰"]
        U1[é–¢æ•°å˜ä½ãƒ†ã‚¹ãƒˆ<br/>pytest]
        U2[ã‚¯ãƒ©ã‚¹å˜ä½ãƒ†ã‚¹ãƒˆ<br/>pytest-mock]
        U3[ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å˜ä½ãƒ†ã‚¹ãƒˆ<br/>pytest-cov]
    end
    
    subgraph integration["çµ±åˆãƒ†ã‚¹ãƒˆ"]
        I1[ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ãƒ†ã‚¹ãƒˆ<br/>DB â†” ã‚¹ã‚¯ãƒªãƒ—ãƒˆ]
        I2[ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ<br/>fetch â†’ parse â†’ import â†’ analyze]
    end
    
    subgraph acceptance["å—å…¥ãƒ†ã‚¹ãƒˆ"]
        A1[æ©Ÿèƒ½è¦ä»¶æ¤œè¨¼<br/>UAT-001~UAT-014]
        A2[éæ©Ÿèƒ½è¦ä»¶æ¤œè¨¼<br/>NFR-001~NFR-020]
        A3[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ<br/>å®Ÿãƒ‡ãƒ¼ã‚¿100éŠ˜æŸ„]
    end
    
    unit --> integration
    integration --> acceptance
    
    style unit fill:#c8e6c9
    style integration fill:#fff9c4
    style acceptance fill:#e1bee7
```

**ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è©³ç´°**:

```yaml
unit_tests:
  test_fetch_xbrl:
    file: "tests/test_fetch.py"
    coverage_target: "100%"
    test_cases:
      - name: "test_get_document_list"
        description: "æå‡ºæ›¸é¡ä¸€è¦§å–å¾—"
        setup: "ãƒ¢ãƒƒã‚¯APIï¼ˆresponsesï¼‰"
        assertions:
          - "len(documents) == 10"
          - "documents[0]['docID'] == 'S100XXXX'"
      
      - name: "test_download_xbrl_success"
        description: "XBRLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ"
        setup: "ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆ200 OKï¼‰"
        assertions:
          - "output_file.exists()"
          - "output_file.stat().st_size > 0"
      
      - name: "test_download_xbrl_retry"
        description: "ãƒªãƒˆãƒ©ã‚¤å‡¦ç†"
        setup: "ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆ[500, 500, 200]ï¼‰"
        assertions:
          - "retry_count == 2"
          - "output_file.exists()"
      
      - name: "test_rate_limiter"
        description: "ãƒ¬ãƒ¼ãƒˆåˆ¶é™"
        setup: "rate = 2.0å›/ç§’"
        assertions:
          - "10å›å‘¼ã³å‡ºã—æ™‚é–“ >= 5ç§’"
          - "10å›å‘¼ã³å‡ºã—æ™‚é–“ < 6ç§’"
    
    code_example: |
      import pytest
      import responses
      from scripts.fetch_xbrl import EDINETFetcher, RateLimiter
      import time
      
      @pytest.fixture
      def fetcher(tmp_path):
          db_path = tmp_path / "test.db"
          output_dir = tmp_path / "xbrl"
          return EDINETFetcher(str(db_path), str(output_dir))
      
      @responses.activate
      def test_get_document_list(fetcher):
          # ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¨­å®š
          responses.add(
              responses.GET,
              "https://disclosure.edinet-fsa.go.jp/api/v1/documents.json",
              json={
                  "results": [
                      {"docID": "S100XXXX", "ordinanceCode": "010", "formCode": "030000"}
                  ]
              },
              status=200
          )
          
          # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
          documents = fetcher._get_document_list(
              start_date="2024-01-01",
              end_date="2024-01-01"
          )
          
          # ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³
          assert len(documents) == 1
          assert documents[0]["docID"] == "S100XXXX"
      
      def test_rate_limiter():
          limiter = RateLimiter(rate=2.0)  # 2å›/ç§’
          
          start = time.time()
          for _ in range(10):
              limiter.acquire()
          elapsed = time.time() - start
          
          assert elapsed >= 5.0  # æœ€ä½5ç§’
          assert elapsed < 6.0   # ä¸Šé™6ç§’

  test_netnet:
    file: "tests/test_netnet.py"
    coverage_target: "100%"
    test_cases:
      - name: "test_calculate_single_normal"
        description: "é€šå¸¸éŠ˜æŸ„ã®NetNetPBRè¨ˆç®—"
        input:
          cash: 100000
          securities: 50000
          receivables: 30000
          inventory: 20000
          liabilities: 150000
          price: 1000
          shares: 10000
        expected:
          net_net_assets: 23000  # (100000*1.0 + 50000*0.8 + 30000*0.7 + 20000*0.5) - 150000
          market_cap: 10000000
          net_net_pbr: 434.78    # 10000000 / 23000
      
      - name: "test_calculate_single_negative_assets"
        description: "ãƒãƒƒãƒˆãƒãƒƒãƒˆè³‡ç”£ãŒè² ã®å ´åˆ"
        input:
          cash: 10000
          liabilities: 200000
        expected: None  # é™¤å¤–ã•ã‚Œã‚‹
      
      - name: "test_calculate_all"
        description: "å…¨éŠ˜æŸ„è¨ˆç®—"
        setup: "ã‚µãƒ³ãƒ—ãƒ«DBï¼ˆ10éŠ˜æŸ„ï¼‰"
        assertions:
          - "len(results) == 10"
          - "results[0].rank == 1"
          - "results[0].net_net_pbr < results[1].net_net_pbr"
    
    code_example: |
      import pytest
      import sqlite3
      from scripts.analyzers.netnet import NetNetAnalyzer
      
      @pytest.fixture
      def sample_db(tmp_path):
          db_path = tmp_path / "test.db"
          conn = sqlite3.connect(db_path)
          
          # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
          conn.execute("""
              CREATE TABLE companies (
                  company_id TEXT PRIMARY KEY,
                  ticker TEXT,
                  name TEXT
              )
          """)
          conn.execute("""
              CREATE TABLE financials (
                  company_id TEXT,
                  cash REAL,
                  securities REAL,
                  accounts_receivable REAL,
                  inventory REAL,
                  total_liabilities REAL,
                  filing_date TEXT
              )
          """)
          conn.execute("""
              CREATE TABLE stock_prices (
                  company_id TEXT,
                  close_price REAL,
                  shares_outstanding INTEGER,
                  date TEXT
              )
          """)
          
          # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼ˆæ±äº¬é›»åŠ›ï¼‰
          conn.execute(
              "INSERT INTO companies VALUES ('9501', '9501', 'æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹')"
          )
          conn.execute("""
              INSERT INTO financials VALUES (
                  '9501', 100000, 50000, 30000, 20000, 150000, '2024-03-31'
              )
          """)
          conn.execute("""
              INSERT INTO stock_prices VALUES (
                  '9501', 1000, 10000, '2024-06-01'
              )
          """)
          
          conn.commit()
          conn.close()
          
          return db_path
      
      def test_calculate_single_normal(sample_db):
          analyzer = NetNetAnalyzer(str(sample_db))
          results = analyzer.calculate_all()
          
          assert len(results) == 1
          assert results[0].ticker == '9501'
          assert abs(results[0].net_net_pbr - 434.78) < 0.01
          assert results[0].net_net_assets == 23000

integration_tests:
  test_full_pipeline:
    file: "tests/test_integration.py"
    description: "ãƒ‡ãƒ¼ã‚¿å–å¾—â†’è§£æâ†’é€šçŸ¥ã®å…¨ãƒ•ãƒ­ãƒ¼"
    steps:
      - name: "1. XBRLå–å¾—"
        action: "fetch_xbrl.py å®Ÿè¡Œ"
        verify: "data/raw/xbrl/ ã«ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨"
      
      - name: "2. XBRLãƒ‘ãƒ¼ã‚¹"
        action: "parse_xbrl.py å®Ÿè¡Œ"
        verify: "data/normalized/ ã«JSONå­˜åœ¨"
      
      - name: "3. DBã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
        action: "import_to_db.py å®Ÿè¡Œ"
        verify: "SELECT COUNT(*) FROM financials > 0"
      
      - name: "4. NetNetè¨ˆç®—"
        action: "netnet.py å®Ÿè¡Œ"
        verify: "analysis_cache ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°"
      
      - name: "5. é€šçŸ¥"
        action: "notify.py å®Ÿè¡Œ"
        verify: "notifications ãƒ†ãƒ¼ãƒ–ãƒ«æŒ¿å…¥"
    
    code_example: |
      import pytest
      import subprocess
      import sqlite3
      from pathlib import Path
      
      @pytest.fixture
      def test_env(tmp_path):
          # ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
          db_path = tmp_path / "test.db"
          raw_dir = tmp_path / "raw" / "xbrl"
          normalized_dir = tmp_path / "normalized"
          
          raw_dir.mkdir(parents=True)
          normalized_dir.mkdir(parents=True)
          
          # DBåˆæœŸåŒ–
          subprocess.run(
              ["python", "scripts/init_db.py", "--db", str(db_path)],
              check=True
          )
          
          return {
              "db_path": db_path,
              "raw_dir": raw_dir,
              "normalized_dir": normalized_dir
          }
      
      def test_full_pipeline(test_env):
          # 1. XBRLå–å¾—ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰
          # ï¼ˆå®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã§ã¯ãƒ¢ãƒƒã‚¯APIä½¿ç”¨ï¼‰
          
          # 2. XBRLãƒ‘ãƒ¼ã‚¹
          result = subprocess.run(
              [
                  "python", "scripts/parse_xbrl.py",
                  "--input", str(test_env["raw_dir"]),
                  "--output", str(test_env["normalized_dir"])
              ],
              capture_output=True,
              check=True
          )
          assert result.returncode == 0
          
          # 3. DBã‚¤ãƒ³ãƒãƒ¼ãƒˆ
          result = subprocess.run(
              [
                  "python", "scripts/import_to_db.py",
                  "--db", str(test_env["db_path"]),
                  "--input", str(test_env["normalized_dir"])
              ],
              check=True
          )
          
          # 4. ãƒ‡ãƒ¼ã‚¿ç¢ºèª
          conn = sqlite3.connect(test_env["db_path"])
          cursor = conn.execute("SELECT COUNT(*) FROM financials")
          count = cursor.fetchone()[0]
          assert count > 0
          
          # 5. NetNetè¨ˆç®—
          result = subprocess.run(
              [
                  "python", "scripts/analyzers/netnet.py",
                  "--db", str(test_env["db_path"])
              ],
              check=True
          )
          
          # 6. çµæœç¢ºèª
          cursor = conn.execute("SELECT COUNT(*) FROM analysis_cache")
          count = cursor.fetchone()[0]
          assert count > 0

acceptance_tests:
  uat_001:
    requirement: "UAT-001: NetNetPBRè¨ˆç®—ç²¾åº¦"
    test_procedure:
      - "æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ï¼ˆ9501ï¼‰ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—"
      - "æ‰‹è¨ˆç®—ã§NetNetPBRç®—å‡º"
      - "ã‚·ã‚¹ãƒ†ãƒ è¨ˆç®—å€¤ã¨æ¯”è¼ƒ"
    acceptance_criteria:
      - "èª¤å·® < 0.01%"
      - "è¨ˆç®—æ™‚é–“ < 1ç§’"
    sample_data:
      company: "æ±äº¬é›»åŠ›ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹"
      ticker: "9501"
      cash: 150000
      securities: 80000
      receivables: 50000
      inventory: 30000
      liabilities: 200000
      market_cap: 10000000
    expected:
      net_net_assets: 73000
      net_net_pbr: 136.99
  
  uat_002:
    requirement: "UAT-002: ã‚ªãƒ‹ãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç²¾åº¦"
    test_procedure:
      - "ä¸­éƒ¨é›»åŠ›ï¼ˆ9502ï¼‰ã®EPSæˆé•·ç‡è¨ˆç®—"
      - "ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹è¨ˆç®—"
      - "ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœç¢ºèª"
    acceptance_criteria:
      - "EPSæˆé•·ç‡è¨ˆç®—ç²¾åº¦ < 0.1%"
      - "RSè¨ˆç®—ç²¾åº¦ < 1ãƒã‚¤ãƒ³ãƒˆ"
    sample_data:
      company: "ä¸­éƒ¨é›»åŠ›"
      ticker: "9502"
      eps_history: [50, 55, 62, 70, 78]  # 5å¹´é–“
      price_change: 0.35  # 35%ä¸Šæ˜‡
      market_change: 0.20  # 20%ä¸Šæ˜‡
    expected:
      eps_growth_rate: 0.225  # 22.5%
      relative_strength: 75    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
```

**ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™**:
```yaml
coverage_targets:
  overall: "100%"
  
  by_module:
    scripts/fetch_xbrl.py: "100%"
    scripts/fetch_prices.py: "100%"
    scripts/parse_xbrl.py: "100%"
    scripts/import_to_db.py: "100%"
    scripts/analyzers/netnet.py: "100%"
    scripts/analyzers/oneil.py: "100%"
    scripts/analyzers/market_top.py: "100%"
    scripts/notify.py: "100%"
  
  exclusions:
    - "tests/*"
    - "scripts/__init__.py"
    - "venv/*"
```

**ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰**:
```powershell
# å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest

# ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ
pytest --cov=scripts --cov-report=term-missing --cov-report=html

# ç‰¹å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ
pytest tests/test_netnet.py -v

# ä¸¦åˆ—å®Ÿè¡Œï¼ˆé«˜é€ŸåŒ–ï¼‰
pytest -n auto

# ç¶™ç¶šçš„ãƒ†ã‚¹ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ï¼‰
pytest-watch
```

### ã‚³ãƒ¼ãƒ‰å“è³ªåŸºæº–

```yaml
quality_standards:
  linting:
    tool: "flake8"
    config:
      max-line-length: 100
      exclude: "venv,tests"
      ignore: "E203,W503"
    command: "flake8 scripts/"
  
  type_checking:
    tool: "mypy"
    config:
      python_version: "3.11"
      strict: true
      ignore_missing_imports: false
    command: "mypy scripts/"
  
  formatting:
    tool: "black"
    config:
      line-length: 100
      target-version: "py311"
    command: "black scripts/"
  
  complexity:
    tool: "radon"
    threshold: "B"  # å¾ªç’°çš„è¤‡é›‘åº¦ < 10
    command: "radon cc scripts/ -a -nb"
```

### ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```yaml
ci_pipeline:
  trigger:
    - "push to feature/impl-001-stock-analysis-system"
    - "pull request to main"
  
  jobs:
    test:
      runs-on: "ubuntu-latest"
      steps:
        - checkout
        - setup python 3.11
        - install dependencies
        - run pytest --cov=scripts
        - upload coverage to codecov
    
    lint:
      runs-on: "ubuntu-latest"
      steps:
        - checkout
        - setup python 3.11
        - run flake8
        - run mypy
        - run black --check
    
    security:
      runs-on: "ubuntu-latest"
      steps:
        - checkout
        - run safety check
        - run bandit -r scripts/
```

---

## ãƒªã‚¹ã‚¯ç®¡ç†

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æˆ¦ç•¥

**ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æœ€é©åŒ–**:
```yaml
xbrl_parsing:
  problem: "4000ç¤¾ Ã— 5ãƒ•ã‚¡ã‚¤ãƒ« = 20,000ãƒ•ã‚¡ã‚¤ãƒ«è§£æ"
  baseline: "0.5ç§’/ãƒ•ã‚¡ã‚¤ãƒ« = 2.8æ™‚é–“"
  optimizations:
    parallel_processing:
      method: "multiprocessing.Pool"
      workers: "CPUæ•° - 1"
      expected_speedup: "3-4å€"
      code_snippet: |
        from multiprocessing import Pool, cpu_count
        
        def parse_xbrl_parallel(file_paths: List[str]):
            with Pool(cpu_count() - 1) as pool:
                results = pool.map(parse_single_file, file_paths)
            return results
    
    incremental_updates:
      method: "å·®åˆ†æ›´æ–°ï¼ˆ--since-dbï¼‰"
      database_query: "SELECT MAX(filing_date) FROM xbrl_files"
      expected_reduction: "95%ä»¥ä¸Šï¼ˆæ—¥æ¬¡æ›´æ–°æ™‚ï¼‰"
    
    caching:
      method: "è§£ææ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"
      cache_key: "MD5(ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ + ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º + æ›´æ–°æ—¥æ™‚)"
      cache_location: "data/cache/parsed/"
      expiry: "30æ—¥é–“"
  
  target: "åˆå›: 45åˆ†ä»¥å†…ã€æ—¥æ¬¡: 3åˆ†ä»¥å†…"

database_operations:
  problem: "å¤§é‡INSERTæ™‚ã®ãƒ­ãƒƒã‚¯ç«¶åˆ"
  baseline: "1è¡Œãšã¤INSERT = 60ç§’/1000è¡Œ"
  optimizations:
    bulk_insert:
      method: "executemany() + ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³"
      batch_size: 1000
      expected_speedup: "50å€"
      code_snippet: |
        with sqlite3.connect(db_path) as conn:
            conn.execute('BEGIN')
            conn.executemany(
                'INSERT INTO financials VALUES (?,?,?,...)',
                batch_data
            )
            conn.execute('COMMIT')
    
    indexing:
      indexes:
        - "CREATE INDEX idx_companies_ticker ON companies(ticker)"
        - "CREATE INDEX idx_financials_date ON financials(filing_date)"
        - "CREATE INDEX idx_prices_date ON stock_prices(date)"
      expected_speedup: "SELECT: 10-100å€"
    
    pragma_settings:
      - "PRAGMA journal_mode = WAL"  # Write-Ahead Logging
      - "PRAGMA synchronous = NORMAL"
      - "PRAGMA cache_size = -64000"  # 64MB cache
      - "PRAGMA temp_store = MEMORY"
  
  target: "1000è¡ŒINSERT < 1ç§’"

network_efficiency:
  problem: "EDINET API ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
  baseline: "20,000ãƒ•ã‚¡ã‚¤ãƒ« = 5.6æ™‚é–“"
  optimizations:
    rate_limiter:
      method: "Token Bucket Algorithm"
      implementation: "time.sleep() + ã‚­ãƒ¥ãƒ¼ç®¡ç†"
      code_snippet: |
        import time
        from collections import deque
        
        class RateLimiter:
            def __init__(self, rate: float = 1.0):
                self.interval = 1.0 / rate
                self.timestamps = deque(maxlen=10)
            
            def acquire(self):
                now = time.time()
                if self.timestamps:
                    elapsed = now - self.timestamps[-1]
                    if elapsed < self.interval:
                        time.sleep(self.interval - elapsed)
                self.timestamps.append(time.time())
    
    connection_pooling:
      method: "requests.Session() å†åˆ©ç”¨"
      expected_speedup: "TCPæ¥ç¶šæ™‚é–“å‰Šæ¸›ï¼ˆ50-100ms/å›ï¼‰"
    
    retry_strategy:
      max_retries: 3
      backoff_factor: 2  # 1ç§’ã€2ç§’ã€4ç§’
      status_forcelist: [429, 500, 502, 503, 504]
  
  target: "ãƒ¬ãƒ¼ãƒˆåˆ¶é™éµå®ˆ + æ¥ç¶šã‚¨ãƒ©ãƒ¼è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤"
```

**ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœ€é©åŒ–**:
```yaml
database_loading:
  problem: "50MB DB ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ + WASMåˆæœŸåŒ–"
  baseline: "10ç§’ï¼ˆ50MB @ 5MB/sï¼‰"
  optimizations:
    compression:
      method: "Brotliåœ§ç¸®ï¼ˆGitHub Pagesè‡ªå‹•é©ç”¨ï¼‰"
      compression_ratio: "70-80%å‰Šæ¸›"
      expected_size: "10-15MB"
      expected_time: "2-3ç§’"
    
    indexeddb_cache:
      method: "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† + ã‚­ãƒ£ãƒƒã‚·ãƒ¥"
      cache_key: "DBæ›´æ–°æ—¥æ™‚ï¼ˆLast-Modifiedï¼‰"
      code_snippet: |
        async function loadDatabase(dbUrl) {
          const cache = await openIndexedDB();
          const cached = await cache.get('latest');
          
          const response = await fetch(dbUrl, {
            headers: {
              'If-Modified-Since': cached?.lastModified || ''
            }
          });
          
          if (response.status === 304) {
            // ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨
            return new SQL.Database(cached.data);
          }
          
          // æ–°è¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
          const buffer = await response.arrayBuffer();
          await cache.put('latest', {
            data: buffer,
            lastModified: response.headers.get('Last-Modified')
          });
          
          return new SQL.Database(buffer);
        }
    
    progressive_loading:
      method: "UIè¡¨ç¤º â†’ DBèª­è¾¼ï¼ˆéåŒæœŸï¼‰"
      ux: "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚¹ã‚¯ãƒªãƒ¼ãƒ³è¡¨ç¤º"
  
  target: "åˆå›: 3ç§’ä»¥å†…ã€2å›ç›®ä»¥é™: 100msä»¥å†…"

chart_rendering:
  problem: "1000ãƒã‚¤ãƒ³ãƒˆæç”»"
  baseline: "500msï¼ˆlightweight-chartsï¼‰"
  optimizations:
    data_decimation:
      method: "ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸé–“å¼•ã"
      full_data: "3000ãƒã‚¤ãƒ³ãƒˆ"
      zoomed_out: "300ãƒã‚¤ãƒ³ãƒˆï¼ˆ10å€é–“å¼•ãï¼‰"
      expected_speedup: "5å€"
    
    lazy_loading:
      method: "å¯è¦–ç¯„å›²ã®ã¿æç”»"
      viewport: "ç”»é¢è¡¨ç¤º Â± 20%"
    
    webworker:
      method: "è¨ˆç®—ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ"
      use_case: "RSè¨ˆç®—ã€çµ±è¨ˆé‡è¨ˆç®—"
  
  target: "1000ãƒã‚¤ãƒ³ãƒˆæç”» < 500msã€60fpsç¶­æŒ"

dom_manipulation:
  problem: "4000è¡Œãƒ†ãƒ¼ãƒ–ãƒ«æç”»"
  baseline: "2000msï¼ˆå…¨è¡Œä¸€æ‹¬æç”»ï¼‰"
  optimizations:
    virtual_scrolling:
      method: "å¯è¦–è¡Œã®ã¿æç”»"
      visible_rows: 20
      buffer_rows: 10
      expected_speedup: "50å€"
      code_snippet: |
        class VirtualTable {
          constructor(data, rowHeight = 40) {
            this.data = data;
            this.rowHeight = rowHeight;
            this.visibleRows = Math.ceil(window.innerHeight / rowHeight);
          }
          
          render(scrollTop) {
            const startIndex = Math.floor(scrollTop / this.rowHeight);
            const endIndex = startIndex + this.visibleRows + 10;
            const visibleData = this.data.slice(startIndex, endIndex);
            
            this.container.innerHTML = visibleData.map(
              (row, i) => this.renderRow(row, startIndex + i)
            ).join('');
          }
        }
    
    pagination:
      method: "ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆSQL LIMIT/OFFSETï¼‰"
      page_size: 100
      expected_speedup: "åˆæœŸæç”» 20å€"
  
  target: "4000è¡Œãƒ†ãƒ¼ãƒ–ãƒ« < 100ms"
```

### ãƒªã‚¹ã‚¯ä¸€è¦§ã¨å¯¾ç­–

```yaml
risks:
  RISK-001:
    category: "æŠ€è¡“"
    description: "EDINET APIä»•æ§˜å¤‰æ›´"
    probability: "ä½"
    impact: "é«˜"
    mitigation:
      - "ã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«åŒ–"
      - "è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œ"
      - "ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå……å®Ÿ"
    contingency:
      - "æ‰‹å‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æº–å‚™"
    owner: "é–‹ç™ºãƒãƒ¼ãƒ "
  
  RISK-002:
    category: "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹"
    description: "XBRLãƒ‘ãƒ¼ã‚¹æ™‚é–“è¶…é"
    probability: "ä¸­"
    impact: "ä¸­"
    mitigation:
      - "ä¸¦åˆ—å‡¦ç†å®Ÿè£…"
      - "ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ´»ç”¨"
      - "å¢—åˆ†æ›´æ–°å¾¹åº•"
    contingency:
      - "å¤–éƒ¨ãƒ‘ãƒ¼ã‚µãƒ¼æ¤œè¨"
    owner: "é–‹ç™ºãƒãƒ¼ãƒ "
  
  RISK-003:
    category: "ãƒªã‚½ãƒ¼ã‚¹"
    description: "GitHub LFSå®¹é‡è¶…é"
    probability: "ä¸­"
    impact: "ä¸­"
    mitigation:
      - "åœ§ç¸®ç‡å‘ä¸Šï¼ˆgzip level 9ï¼‰"
      - "å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³å‰Šé™¤"
      - "æœˆæ¬¡å®¹é‡ç›£è¦–"
    contingency:
      - "æœ‰æ–™ãƒ—ãƒ©ãƒ³æ¤œè¨ï¼ˆ$5/æœˆï¼‰"
    owner: "ã‚¤ãƒ³ãƒ•ãƒ©æ‹…å½“"
  
  RISK-004:
    category: "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"
    description: "å®Ÿè£…é…å»¶"
    probability: "ä¸­"
    impact: "ä½"
    mitigation:
      - "ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹å„ªå…ˆ"
      - "AIæ´»ç”¨æœ€å¤§åŒ–"
      - "é€±æ¬¡é€²æ—ç¢ºèª"
    contingency:
      - "ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½å¾Œå›ã—"
    owner: "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†"
  
  RISK-005:
    category: "å“è³ª"
    description: "è¨ˆç®—ç²¾åº¦ä¸è¶³"
    probability: "ä½"
    impact: "é«˜"
    mitigation:
      - "æ‰‹è¨ˆç®—ã¨ã®ç…§åˆ"
      - "ã‚µãƒ³ãƒ—ãƒ«100éŠ˜æŸ„æ¤œè¨¼"
      - "ç•°å¸¸å€¤æ¤œå‡ºå®Ÿè£…"
    contingency:
      - "å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã¨ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯"
    owner: "å“è³ªä¿è¨¼"
```

---

## ãƒ‡ãƒ—ãƒ­ã‚¤è¨ˆç”»

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ•ãƒ­ãƒ¼

```mermaid
flowchart TB
    A[feature/impl-001<br/>å®Ÿè£…å®Œäº†] --> B{å…¨ãƒ†ã‚¹ãƒˆåˆæ ¼?}
    B -->|Yes| C[Pull Requestä½œæˆ]
    B -->|No| A
    C --> D{ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿èª?}
    D -->|Yes| E[spec/001ã¸ãƒãƒ¼ã‚¸]
    D -->|No| A
    E --> F{å—å…¥ãƒ†ã‚¹ãƒˆåˆæ ¼?}
    F -->|Yes| G[mainã¸ãƒãƒ¼ã‚¸]
    F -->|No| A
    G --> H[GitHub Actionsèµ·å‹•]
    H --> I[GitHub Pagesè‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤]
    I --> J[æœ¬ç•ªç’°å¢ƒå…¬é–‹]
    
    style A fill:#e3f2fd
    style C fill:#fff9c4
    style E fill:#ffccbc
    style G fill:#c8e6c9
    style J fill:#e1bee7
```

### ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒ

```yaml
environments:
  development:
    branch: "feature/impl-001-stock-analysis-system"
    purpose: "é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ"
    url: "http://localhost:5000"
    database: "data/db/stock-analysis.dbï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰"
    auto_deploy: false
  
  staging:
    branch: "spec/001-stock-analysis-system"
    purpose: "å—å…¥ãƒ†ã‚¹ãƒˆ"
    url: "https://j1921604.github.io/stock-analysis-staging/"
    database: "GitHub LFSï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰"
    auto_deploy: true
  
  production:
    branch: "main"
    purpose: "æœ¬ç•ªé‹ç”¨"
    url: "https://j1921604.github.io/stock-analysis/"
    database: "GitHub LFSï¼ˆæœ¬ç•ªï¼‰"
    auto_deploy: true
    monitoring: "GitHub Actions Summary"
```

### ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç”»

```yaml
rollback_procedure:
  trigger:
    - "é‡å¤§ãªãƒã‚°ç™ºè¦‹"
    - "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–"
    - "ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ"
  
  steps:
    1_immediate:
      action: "mainãƒ–ãƒ©ãƒ³ãƒã‚’å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãƒªã‚»ãƒƒãƒˆ"
      command: "git revert {commit-hash}"
      time: "< 5åˆ†"
    
    2_notification:
      action: "GitHub Issueä½œæˆ"
      template: "ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯é€šçŸ¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"
      assignee: "é–‹ç™ºãƒãƒ¼ãƒ "
    
    3_investigation:
      action: "æ ¹æœ¬åŸå› åˆ†æ"
      deliverable: "ãƒã‚°ãƒ¬ãƒãƒ¼ãƒˆ"
      time: "1æ—¥ä»¥å†…"
    
    4_fix:
      action: "ä¿®æ­£ç‰ˆå®Ÿè£…"
      branch: "hotfix/{issue-number}"
      test: "çµ±åˆãƒ†ã‚¹ãƒˆå†å®Ÿè¡Œ"
    
    5_redeploy:
      action: "ä¿®æ­£ç‰ˆãƒ‡ãƒ—ãƒ­ã‚¤"
      approval: "ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…é ˆ"
```

### ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»é‹ç”¨

**ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–**:
```yaml
github_actions_monitoring:
  metrics:
    - name: "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æˆåŠŸç‡"
      target: ">= 95%"
      alert: "3å›é€£ç¶šå¤±æ•—æ™‚"
      action: "GitHub Issueè‡ªå‹•ä½œæˆ"
    
    - name: "å®Ÿè¡Œæ™‚é–“"
      target: "< 30åˆ†"
      alert: ">= 45åˆ†æ™‚"
      action: "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æŸ»"
    
    - name: "DB ã‚µã‚¤ã‚º"
      target: "< 1GB"
      alert: ">= 900MBæ™‚"
      action: "ãƒ‡ãƒ¼ã‚¿åœ§ç¸®ãƒ»ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"
  
  dashboard:
    url: "https://github.com/J1921604/stock-analysis/actions"
    metrics:
      - "æˆåŠŸ/å¤±æ•—ã‚°ãƒ©ãƒ•"
      - "å®Ÿè¡Œæ™‚é–“æ¨ç§»"
      - "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡"

database_health:
  checks:
    - name: "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹ç‡"
      query: "PRAGMA index_list(companies)"
      frequency: "é€±æ¬¡"
      action: "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰"
    
    - name: "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§"
      query: "SELECT COUNT(*) FROM financials WHERE company_id NOT IN (SELECT company_id FROM companies)"
      expected: 0
      frequency: "æ—¥æ¬¡"
    
    - name: "VACUUMã‚µã‚¤ã‚º"
      query: "PRAGMA page_count * PRAGMA page_size"
      action: "VACUUM ANALYZE"
      frequency: "æœˆæ¬¡"

frontend_monitoring:
  tools:
    - name: "Google Analytics"
      metrics:
        - "ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼æ•°"
        - "å¹³å‡ãƒšãƒ¼ã‚¸èª­è¾¼æ™‚é–“"
        - "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ"
    
    - name: "Web Vitals"
      metrics:
        - "LCP (Largest Contentful Paint) < 2.5ç§’"
        - "FID (First Input Delay) < 100ms"
        - "CLS (Cumulative Layout Shift) < 0.1"
      reporting: "Chrome User Experience Report"

error_tracking:
  backend:
    method: "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« + GitHub Actions Summary"
    log_location: "logs/fetch_xbrl.log"
    rotation: "æ—¥æ¬¡"
    retention: "30æ—¥é–“"
    format: |
      [2024-01-01 18:00:00] ERROR fetch_xbrl.py:123 - ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: S100XXXX (HTTP 500)
  
  frontend:
    method: "window.onerror + console.error"
    reporting: "GitHub Issuesï¼ˆæ‰‹å‹•ï¼‰"
    example: |
      window.onerror = function(message, source, lineno, colno, error) {
        console.error('ã‚¨ãƒ©ãƒ¼:', {
          message, source, lineno, colno,
          stack: error?.stack
        });
        // é‡å¤§ãªã‚¨ãƒ©ãƒ¼æ™‚ã®ã¿å ±å‘Š
        if (isCriticalError(error)) {
          reportToGitHub(error);
        }
      };

backup_strategy:
  database:
    frequency: "æ—¥æ¬¡ï¼ˆGitHub Actionsï¼‰"
    method: "Git LFS ã‚³ãƒŸãƒƒãƒˆ"
    retention: "ç„¡æœŸé™ï¼ˆGitãƒªãƒã‚¸ãƒˆãƒªï¼‰"
    restore_procedure:
      - "git log --all -- data/db/stock-analysis.db"
      - "git checkout {commit-hash} -- data/db/stock-analysis.db"
  
  artifacts:
    frequency: "æ—¥æ¬¡ï¼ˆGitHub Actionsï¼‰"
    method: "GitHub Artifacts"
    retention: "30æ—¥é–“"
    size_limit: "10GB"
```

**é‹ç”¨æ‰‹é †æ›¸**:
```yaml
daily_operations:
  morning_check:
    time: "9:00ï¼ˆGitHub Actionså®Ÿè¡Œå¾Œï¼‰"
    checklist:
      - "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æˆåŠŸç¢ºèª"
      - "DBæ›´æ–°ç¢ºèªï¼ˆgit logï¼‰"
      - "æ–°è¦Issueç¢ºèª"
      - "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª"
  
  weekly_maintenance:
    day: "æ—¥æ›œæ—¥"
    tasks:
      - "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹ç‡ãƒã‚§ãƒƒã‚¯"
      - "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡ç¢ºèª"
      - "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"
  
  monthly_review:
    tasks:
      - "VACUUM ANALYZEå®Ÿè¡Œ"
      - "å¤ã„ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‰Šé™¤"
      - "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆç¢ºèª"

incident_response:
  severity_levels:
    critical:
      definition: "ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åœæ­¢ã€ãƒ‡ãƒ¼ã‚¿æå¤±"
      response_time: "15åˆ†ä»¥å†…"
      escalation: "å³åº§ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"
      examples:
        - "DBç ´æ"
        - "GitHub Actions å…¨å¤±æ•—"
        - "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºä¸å¯"
    
    high:
      definition: "ä¸»è¦æ©Ÿèƒ½åœæ­¢ã€ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ"
      response_time: "1æ™‚é–“ä»¥å†…"
      escalation: "Issueä½œæˆã€èª¿æŸ»é–‹å§‹"
      examples:
        - "NetNetè¨ˆç®—ã‚¨ãƒ©ãƒ¼"
        - "XBRLå–å¾—å¤±æ•—"
        - "ãƒãƒ£ãƒ¼ãƒˆæç”»å¤±æ•—"
    
    medium:
      definition: "ä¸€éƒ¨æ©Ÿèƒ½ä½ä¸‹ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–"
      response_time: "4æ™‚é–“ä»¥å†…"
      escalation: "é€šå¸¸ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã§å¯¾å¿œ"
      examples:
        - "ä¸€éƒ¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿æ¬ æ"
        - "ãƒšãƒ¼ã‚¸èª­è¾¼æ™‚é–“å¢—åŠ "
    
    low:
      definition: "è»½å¾®ãªãƒã‚°ã€æ”¹å–„è¦æœ›"
      response_time: "1é€±é–“ä»¥å†…"
      escalation: "ãƒãƒƒã‚¯ãƒ­ã‚°è¿½åŠ "
      examples:
        - "UIæ”¹å–„è¦æœ›"
        - "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª¤å­—"

  incident_template: |
    ## ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå ±å‘Š
    
    **ç™ºç”Ÿæ—¥æ™‚**: YYYY-MM-DD HH:MM
    **é‡è¦åº¦**: Critical / High / Medium / Low
    **å½±éŸ¿ç¯„å›²**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ / ç‰¹å®šæ©Ÿèƒ½ / ä¸€éƒ¨ãƒ¦ãƒ¼ã‚¶ãƒ¼
    
    ### ç—‡çŠ¶
    - å…·ä½“çš„ãªç—‡çŠ¶ã‚’è¨˜è¼‰
    
    ### å½±éŸ¿
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å½±éŸ¿
    - ãƒ‡ãƒ¼ã‚¿ã¸ã®å½±éŸ¿
    
    ### å¯¾å¿œå±¥æ­´
    - HH:MM: æ¤œçŸ¥
    - HH:MM: èª¿æŸ»é–‹å§‹
    - HH:MM: åŸå› ç‰¹å®š
    - HH:MM: å¯¾å¿œå®Œäº†
    
    ### æ ¹æœ¬åŸå› 
    - åŸå› ã®è©³ç´°
    
    ### æ’ä¹…å¯¾ç­–
    - å†ç™ºé˜²æ­¢ç­–
```

---

## ä»˜éŒ²

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

**å®Ÿè£…å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
```yaml
phase1_foundation:
  - [ ] Python 3.11ç’°å¢ƒæ§‹ç¯‰
  - [ ] Git LFSæœ‰åŠ¹åŒ–
  - [ ] SQLiteã‚¹ã‚­ãƒ¼ãƒä½œæˆï¼ˆ6ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
  - [ ] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹17ç®‡æ‰€ä½œæˆ
  - [ ] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ å®Œæˆ
  - [ ] requirements.txtå®Œæˆ

phase2_pipeline:
  - [ ] EDINET XBRLå–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
  - [ ] æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
  - [ ] XBRLãƒ‘ãƒ¼ã‚µãƒ¼å®Ÿè£…
  - [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼å®Ÿè£…
  - [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ 100%

phase3_analysis:
  - [ ] NetNetPBRè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
  - [ ] ã‚ªãƒ‹ãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼
  - [ ] ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©äº•æ¤œå‡º
  - [ ] è¨ˆç®—ç²¾åº¦æ¤œè¨¼ï¼ˆèª¤å·®<0.01%ï¼‰

phase4_frontend:
  - [ ] HTML/CSSä½œæˆ
  - [ ] sqlite-wasmçµ±åˆ
  - [ ] lightweight-chartsçµ±åˆ
  - [ ] Lighthouse Performance >= 90

phase5_automation:
  - [ ] GitHub Actionsæ—¥æ¬¡ãƒãƒƒãƒ
  - [ ] GitHub Actions ãƒ‡ãƒ—ãƒ­ã‚¤
  - [ ] é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
  - [ ] çµ±åˆãƒ†ã‚¹ãƒˆåˆæ ¼

quality:
  - [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ 100%
  - [ ] flake8åˆæ ¼
  - [ ] mypyåˆæ ¼
  - [ ] black ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨
  - [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ï¼ˆREADME.mdï¼‰

deployment:
  - [ ] GitHub Pages ãƒ‡ãƒ—ãƒ­ã‚¤æˆåŠŸ
  - [ ] æ—¥æ¬¡ãƒãƒƒãƒè‡ªå‹•å®Ÿè¡Œç¢ºèª
  - [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å‹•ä½œç¢ºèª
  - [ ] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †ç¢ºèª
```

### FAQï¼ˆã‚ˆãã‚ã‚‹è³ªå•ï¼‰

**Q1: ãªãœPython 3.11ã‚’é¸æŠã—ãŸã®ã‹?**
```yaml
answer:
  reasons:
    - "å‹ãƒ’ãƒ³ãƒˆæ©Ÿèƒ½ã®å……å®Ÿï¼ˆPEP 673, 646ï¼‰"
    - "é–¢æ•°å‘¼ã³å‡ºã—10-25%é«˜é€ŸåŒ–"
    - "2027å¹´10æœˆã¾ã§LTSï¼ˆé•·æœŸã‚µãƒãƒ¼ãƒˆï¼‰"
    - "pandas 2.0ã¨ã®äº’æ›æ€§"
  alternatives:
    Python_3.10: "å‹ãƒ’ãƒ³ãƒˆæ©Ÿèƒ½ãŒé™å®šçš„"
    Python_3.12: "ä¸€éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªå¯¾å¿œï¼ˆãƒªãƒªãƒ¼ã‚¹ç›´å¾Œï¼‰"
```

**Q2: ãªãœSQLiteã‚’é¸æŠã—ãŸã®ã‹? PostgreSQLã§ã¯ãªã„ã®ã‹?**
```yaml
answer:
  sqlite_benefits:
    - "ã‚µãƒ¼ãƒãƒ¼ä¸è¦ï¼ˆé‹ç”¨ã‚³ã‚¹ãƒˆ0å††ï¼‰"
    - "GitHub Pageså¯¾å¿œï¼ˆé™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ï¼‰"
    - "WASMå¯¾å¿œï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å†…å®Ÿè¡Œï¼‰"
    - "å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®¹æ˜“ï¼‰"
  
  postgresql_drawbacks:
    - "ã‚µãƒ¼ãƒãƒ¼å¿…è¦ï¼ˆHeroku $7/æœˆ~ï¼‰"
    - "GitHub Pageséå¯¾å¿œ"
    - "WASMéå¯¾å¿œ"
    - "é‹ç”¨è² è·ï¼ˆãƒ‘ãƒƒãƒé©ç”¨ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰"
  
  use_case:
    data_size: "< 1GBï¼ˆ4000ç¤¾ Ã— 5å¹´ï¼‰"
    concurrent_users: "èª­å–å°‚ç”¨ï¼ˆåŒæ™‚æ›¸è¾¼ãªã—ï¼‰"
    query_complexity: "ä¸­ç¨‹åº¦ï¼ˆJOINã‚ã‚Šï¼‰"
    conclusion: "SQLiteã§ååˆ†"
```

**Q3: GitHub LFSã®å®¹é‡åˆ¶é™ã¯ã©ã†ã™ã‚‹?**
```yaml
answer:
  free_tier:
    storage: "1GB"
    bandwidth: "1GB/æœˆ"
  
  current_usage:
    db_size: "50MBï¼ˆåˆå›ï¼‰"
    db_size_monthly: "+5MB/æœˆï¼ˆæ¨å®šï¼‰"
    db_size_12months: "110MB"
    conclusion: "1å¹´é–“ã¯ç„¡æ–™æ å†…"
  
  capacity_management:
    - "gzipåœ§ç¸®ï¼ˆ70-80%å‰Šæ¸›ï¼‰"
    - "å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³å‰Šé™¤ï¼ˆpruneï¼‰"
    - "GitHub Releasesç§»è¡Œï¼ˆç„¡åˆ¶é™ï¼‰"
  
  paid_plan:
    cost: "$5/æœˆï¼ˆ50GBè¿½åŠ ï¼‰"
    trigger: "ç„¡æ–™æ 90%ä½¿ç”¨æ™‚"
```

**Q4: EDINET APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¯ã©ã†å¯¾å‡¦ã™ã‚‹?**
```yaml
answer:
  rate_limit:
    official: "æ˜è¨˜ãªã—ï¼ˆæš—é»™çš„ã«1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«æ¨å¥¨ï¼‰"
    å®Ÿæ¸¬å€¤: "1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«ã§å®‰å®š"
  
  å¯¾ç­–:
    rate_limiter:
      implementation: "Token Bucket Algorithm"
      buffer: "1.1ç§’/1ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ï¼‰"
    
    incremental_updates:
      method: "å·®åˆ†æ›´æ–°ï¼ˆ--since-dbï¼‰"
      impact: "æ—¥æ¬¡æ›´æ–°: 10-50ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ10-50ç§’ï¼‰"
    
    parallel_processing:
      status: "ä¸å¯ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™é•åï¼‰"
      alternative: "ä¸¦åˆ—ãƒ‘ãƒ¼ã‚¹ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œï¼‰"
```

**Q5: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å¤§ä¸ˆå¤«ã‹?**
```yaml
answer:
  concerns:
    - "50MB DBãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
    - "4000è¡Œãƒ†ãƒ¼ãƒ–ãƒ«æç”»"
    - "1000ãƒã‚¤ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆæç”»"
  
  solutions:
    db_download:
      - "Brotliåœ§ç¸®: 50MB â†’ 10-15MB"
      - "IndexedDBã‚­ãƒ£ãƒƒã‚·ãƒ¥: 2å›ç›®ä»¥é™100ms"
      - "ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤ºï¼ˆUXæ”¹å–„ï¼‰"
    
    table_rendering:
      - "ä»®æƒ³ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«: 4000è¡Œ â†’ 20è¡Œæç”»"
      - "ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³: 100è¡Œ/ãƒšãƒ¼ã‚¸"
      - "é…å»¶èª­è¾¼: åˆæœŸ50è¡Œã®ã¿"
    
    chart_rendering:
      - "lightweight-charts: 500msï¼ˆå®Ÿç¸¾ï¼‰"
      - "ãƒ‡ãƒ¼ã‚¿é–“å¼•ã: ã‚ºãƒ¼ãƒ ã‚¢ã‚¦ãƒˆæ™‚"
      - "WebWorker: è¨ˆç®—ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰"
  
  target_metrics:
    Lighthouse_Performance: ">= 90"
    LCP: "< 2.5ç§’"
    FID: "< 100ms"
    CLS: "< 0.1"
```

**Q6: AIï¼ˆClaudeï¼‰ã«ã‚ˆã‚‹95%è‡ªå‹•ç”Ÿæˆã¯ç¾å®Ÿçš„ã‹?**
```yaml
answer:
  å®Ÿç¸¾:
    similar_projects:
      - "start.ps1ï¼ˆ400è¡Œï¼‰: 100% AIç”Ÿæˆ"
      - "spec.mdï¼ˆ2025è¡Œï¼‰: 95% AIç”Ÿæˆ"
      - "requirements.mdï¼ˆ1536è¡Œï¼‰: 95% AIç”Ÿæˆ"
    
    ai_strengths:
      - "å®šå‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆï¼ˆCRUDã€APIé€£æºï¼‰"
      - "ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆï¼ˆpytestï¼‰"
      - "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆYAMLã€SQLï¼‰"
      - "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ"
    
    human_tasks:
      - "è¦ä»¶å®šç¾©ï¼ˆ5%ï¼‰"
      - "ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»æ¤œè¨¼ï¼ˆé©å®œï¼‰"
      - "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼ˆé©å®œï¼‰"
  
  workflow:
    - "1. äººé–“: ã‚¿ã‚¹ã‚¯å®šç¾©ï¼ˆIMPL-XXXï¼‰"
    - "2. AI: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"
    - "3. AI: ãƒ†ã‚¹ãƒˆç”Ÿæˆ"
    - "4. AI: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"
    - "5. äººé–“: å—å…¥ãƒ†ã‚¹ãƒˆ"
    - "6. äººé–“: æ‰¿èªãƒ»ãƒãƒ¼ã‚¸"
```

**Q7: 7é€±é–“ã§æœ¬å½“ã«å®Œæˆã™ã‚‹ã®ã‹?**
```yaml
answer:
  å·¥æ•°è¦‹ç©:
    phase1_foundation: "7æ—¥ï¼ˆç’°å¢ƒæ§‹ç¯‰ï¼‰"
    phase2_pipeline: "14æ—¥ï¼ˆãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è§£æï¼‰"
    phase3_analysis: "10æ—¥ï¼ˆè¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ï¼‰"
    phase4_frontend: "10æ—¥ï¼ˆUIå®Ÿè£…ï¼‰"
    phase5_automation: "7æ—¥ï¼ˆè‡ªå‹•åŒ–ï¼‰"
    total: "48æ—¥ = 6.9é€±é–“"
  
  ai_speedup:
    without_ai: "120æ—¥ï¼ˆ3å€ï¼‰"
    with_ai: "48æ—¥"
    productivity: "2.5å€"
  
  risk_buffer:
    schedule: "7é€±é–“ï¼ˆä½™è£•1é€±ï¼‰"
    contingency: "ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½å¾Œå›ã—"
  
  critical_path:
    - "IMPL-003: ã‚¹ã‚­ãƒ¼ãƒï¼ˆ2æ—¥ï¼‰"
    - "IMPL-007: XBRLå–å¾—ï¼ˆ3æ—¥ï¼‰"
    - "IMPL-011: ãƒ‘ãƒ¼ã‚¹ï¼ˆ4æ—¥ï¼‰"
    - "IMPL-013: ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆ3æ—¥ï¼‰"
    - "IMPL-015: NetNetè¨ˆç®—ï¼ˆ3æ—¥ï¼‰"
    - "IMPL-027: GitHub Actionsï¼ˆ3æ—¥ï¼‰"
    total_critical: "18æ—¥ï¼ˆ2.6é€±é–“ï¼‰"
```

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

**å•é¡Œ1: XBRLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼**
```yaml
ç—‡çŠ¶:
  - "lxml.etree.XMLSyntaxError: Opening and ending tag mismatch"
  - "KeyError: 'Assets'"

åŸå› :
  - "XBRLåå‰ç©ºé–“ã®å¤‰æ›´"
  - "ã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°ã®ä¸ä¸€è‡´"
  - "ä¸æ­£ãªXMLãƒ•ã‚¡ã‚¤ãƒ«"

è§£æ±ºæ‰‹é †:
  1_ç¢ºèª:
    - "lxml --version"
    - "ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: ls data/raw/xbrl/"
  
  2_ãƒ‡ãƒãƒƒã‚°:
    - "python scripts/parse_xbrl.py --input data/raw/xbrl/S100XXXX.zip --debug"
    - "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª: logs/parse_xbrl.log"
  
  3_ä¿®æ­£:
    - "ã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°æ›´æ–°: config/xbrl_tags.yml"
    - "åå‰ç©ºé–“è¿½åŠ "
    - "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç·©å’Œï¼ˆä¸€æ™‚çš„ï¼‰"
  
  4_æ¤œè¨¼:
    - "pytest tests/test_parse.py::test_parse_xbrl_with_new_namespace"
    - "æ‰‹å‹•ãƒ‘ãƒ¼ã‚¹ç¢ºèª"

äºˆé˜²ç­–:
  - "è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼ˆã‚¿ã‚°ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰"
  - "ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆæ‹¡å……ï¼ˆã‚µãƒ³ãƒ—ãƒ«100ä»¶ï¼‰"
  - "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è‡ªå‹•ç›£è¦–"
```

**å•é¡Œ2: GitHub Actions ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ**
```yaml
ç—‡çŠ¶:
  - "Error: The job running on runner has exceeded the maximum execution time of 60 minutes"

åŸå› :
  - "XBRLå–å¾—æ™‚é–“è¶…éï¼ˆåˆå›å®Ÿè¡Œæ™‚ï¼‰"
  - "ãƒ‘ãƒ¼ã‚¹å‡¦ç†æ™‚é–“è¶…é"
  - "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶"

è§£æ±ºæ‰‹é †:
  1_å³åº§ã®å¯¾å‡¦:
    - "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†å®Ÿè¡Œï¼ˆéƒ¨åˆ†å®Ÿè¡Œï¼‰"
    - "timeout-minutes: 120 ã«å¤‰æ›´"
  
  2_ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„:
    - "ä¸¦åˆ—å‡¦ç†æœ‰åŠ¹åŒ–ï¼ˆmultiprocessingï¼‰"
    - "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼ˆactions/cacheï¼‰"
    - "å·®åˆ†æ›´æ–°å¾¹åº•ï¼ˆ--since-dbï¼‰"
  
  3_åˆ†å‰²å®Ÿè¡Œ:
    - "XBRLå–å¾—ã¨ãƒ‘ãƒ¼ã‚¹ã‚’åˆ¥ã‚¸ãƒ§ãƒ–åŒ–"
    - "continues-on-error: true è¨­å®š"
  
  code_example: |
    jobs:
      fetch:
        timeout-minutes: 30
        steps:
          - name: Fetch XBRL
            uses: actions/cache@v4
            with:
              key: xbrl-${{ hashFiles('data/db/stock-analysis.db') }}
      
      parse:
        needs: fetch
        timeout-minutes: 30
        steps:
          - name: Parse XBRL

äºˆé˜²ç­–:
  - "å®šæœŸVACUUMï¼ˆDBæœ€é©åŒ–ï¼‰"
  - "ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"
  - "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ï¼ˆå®Ÿè¡Œæ™‚é–“ã‚°ãƒ©ãƒ•ï¼‰"
```

**å•é¡Œ3: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰DBèª­è¾¼å¤±æ•—**
```yaml
ç—‡çŠ¶:
  - "Uncaught ReferenceError: initSqlJs is not defined"
  - "Failed to load database: HTTP 404"

åŸå› :
  - "sql-wasm.js èª­è¾¼å¤±æ•—"
  - "DBãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹èª¤ã‚Š"
  - "LFSæœªãƒ—ãƒ«"

è§£æ±ºæ‰‹é †:
  1_ãƒ–ãƒ©ã‚¦ã‚¶DevToolsç¢ºèª:
    - "Network ã‚¿ãƒ–: sql-wasm.js ã®200 OKç¢ºèª"
    - "Network ã‚¿ãƒ–: stock-analysis.db ã®200 OKç¢ºèª"
    - "Console ã‚¿ãƒ–: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç¢ºèª"
  
  2_ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª:
    - "git lfs ls-files | grep stock-analysis.db"
    - "ls -lh data/db/stock-analysis.db"
  
  3_ä¿®æ­£:
    - "git lfs pull"
    - "ãƒ‘ã‚¹ä¿®æ­£: /data/stock-analysis.db â†’ /data/db/stock-analysis.db"
    - "CORSè¨­å®šç¢ºèªï¼ˆGitHub Pagesè‡ªå‹•å¯¾å¿œï¼‰"
  
  4_ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢:
    - "ãƒ–ãƒ©ã‚¦ã‚¶ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢: Ctrl+Shift+Del"
    - "IndexedDBã‚¯ãƒªã‚¢: DevTools > Application > IndexedDB > å‰Šé™¤"

äºˆé˜²ç­–:
  - ".gitattributes ç¢ºèª: *.db filter=lfs"
  - "ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ"
  - "E2Eãƒ†ã‚¹ãƒˆè¿½åŠ ï¼ˆPlaywrightï¼‰"
```

**å•é¡Œ4: NetNetPBRè¨ˆç®—çµæœãŒç•°å¸¸**
```yaml
ç—‡çŠ¶:
  - "NetNetPBR = 10000ï¼ˆç•°å¸¸ã«å¤§ãã„ï¼‰"
  - "NetNetPBR = -5ï¼ˆè² ã®å€¤ï¼‰"
  - "è¨ˆç®—å¯¾è±¡éŠ˜æŸ„0ä»¶"

åŸå› :
  - "è²¡å‹™ãƒ‡ãƒ¼ã‚¿æ¬ æï¼ˆNULLå€¤ï¼‰"
  - "å˜ä½èª¤ã‚Šï¼ˆç™¾ä¸‡å†† vs å††ï¼‰"
  - "è² å‚µã®ç¬¦å·èª¤ã‚Š"

è§£æ±ºæ‰‹é †:
  1_ãƒ‡ãƒ¼ã‚¿ç¢ºèª:
    - "SELECT * FROM financials WHERE company_id = '9501'"
    - "SELECT * FROM stock_prices WHERE company_id = '9501'"
  
  2_è¨ˆç®—æ¤œè¨¼:
    - "æ‰‹è¨ˆç®—ã¨ã®æ¯”è¼ƒ"
    - "python -c 'from scripts.analyzers.netnet import NetNetAnalyzer; print(NetNetAnalyzer("data/db/stock-analysis.db").calculate_all()[0])'"
  
  3_ä¿®æ­£:
    - "NULLå€¤å‡¦ç†: COALESCE(cash, 0)"
    - "å˜ä½çµ±ä¸€: å…¨ã¦ç™¾ä¸‡å††"
    - "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ : 0 < NetNetPBR < 10"
  
  4_ãƒ†ã‚¹ãƒˆ:
    - "pytest tests/test_netnet.py -v"
    - "ã‚µãƒ³ãƒ—ãƒ«100éŠ˜æŸ„ã§æ¤œè¨¼"

äºˆé˜²ç­–:
  - "ç•°å¸¸å€¤æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯å¼·åŒ–"
  - "å˜ä½“ãƒ†ã‚¹ãƒˆæ‹¡å……"
  - "ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æ¬¡ï¼‰"
```

### ç”¨èªé›†ï¼ˆæ‹¡å……ç‰ˆï¼‰

| ç”¨èª | è‹±èª | èª¬æ˜ | é–¢é€£æ¦‚å¿µ |
|------|------|------|----------|
| MVP | Minimum Viable Product | æœ€å°å®Ÿè¡Œå¯èƒ½è£½å“ã€‚å¿…è¦æœ€ä½é™ã®æ©Ÿèƒ½ã§å‹•ä½œã™ã‚‹è£½å“ | ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã€ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ |
| TDD | Test-Driven Development | ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã€‚ãƒ†ã‚¹ãƒˆã‚’å…ˆã«æ›¸ã„ã¦ã‹ã‚‰å®Ÿè£…ã™ã‚‹é–‹ç™ºæ‰‹æ³• | ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚° |
| CI/CD | Continuous Integration / Continuous Deployment | ç¶™ç¶šçš„çµ±åˆ/ãƒ‡ãƒ—ãƒ­ã‚¤ã€‚ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã‚’è‡ªå‹•ã§ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ | GitHub Actionsã€DevOps |
| ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹ | Critical Path | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ã«å¿…è¦ãªæœ€é•·ã®ä¾å­˜ã‚¿ã‚¹ã‚¯çµŒè·¯ | ã‚¬ãƒ³ãƒˆãƒãƒ£ãƒ¼ãƒˆã€å·¥ç¨‹ç®¡ç† |
| ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ | Code Coverage | ãƒ†ã‚¹ãƒˆãŒã‚«ãƒãƒ¼ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã®å‰²åˆï¼ˆ0-100%ï¼‰ | pytest-covã€å“è³ªä¿è¨¼ |
| ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚° | Refactoring | å¤–éƒ¨å‹•ä½œã‚’å¤‰ãˆãšã«ã‚³ãƒ¼ãƒ‰å†…éƒ¨æ§‹é€ ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ | æŠ€è¡“çš„è² å‚µã€ä¿å®ˆæ€§ |
| XBRL | eXtensible Business Reporting Language | è²¡å‹™å ±å‘Šç”¨ã®XMLãƒ™ãƒ¼ã‚¹æ¨™æº–å½¢å¼ | EDINETã€æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ |
| NetNetPBR | Net-Net Price to Book Ratio | å³æ™‚ç¾é‡‘åŒ–å¯èƒ½è³‡ç”£ã«åŸºã¥ãPBR | ãƒãƒªãƒ¥ãƒ¼æŠ•è³‡ã€ã‚°ãƒ¬ã‚¢ãƒ  |
| RS | Relative Strength | ãƒªãƒ©ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ³ã‚°ã‚¹ã€‚å¸‚å ´ã«å¯¾ã™ã‚‹ç›¸å¯¾çš„ãªå¼·ã• | ã‚ªãƒ‹ãƒ¼ãƒ«ã€ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ  |
| LFS | Large File Storage | Gitã§å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç®¡ç†ã™ã‚‹ä»•çµ„ã¿ | GitHubã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† |
| WASM | WebAssembly | ãƒ–ãƒ©ã‚¦ã‚¶ã§å®Ÿè¡Œå¯èƒ½ãªãƒã‚¤ãƒŠãƒªå½¢å¼ | sqlite-wasmã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ |
| IndexedDB | - | ãƒ–ãƒ©ã‚¦ã‚¶å†…ã®Key-Valueãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ | ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œ |
| Brotli | - | Googleé–‹ç™ºã®é«˜åœ§ç¸®ç‡åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | gzipã€HTTPåœ§ç¸® |
| EDINET | Electronic Disclosure for Investors' NETwork | é‡‘èåºã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æå‡ºã‚·ã‚¹ãƒ†ãƒ  | è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€XBRL |
| OHLCV | Open, High, Low, Close, Volume | æ ªä¾¡ã®å§‹å€¤ãƒ»é«˜å€¤ãƒ»å®‰å€¤ãƒ»çµ‚å€¤ãƒ»å‡ºæ¥é«˜ | ãƒ­ãƒ¼ã‚½ã‚¯è¶³ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ |
| Lighthouse | - | Googleã®ã‚¦ã‚§ãƒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šãƒ„ãƒ¼ãƒ« | Core Web Vitalsã€SEO |
| LCP | Largest Contentful Paint | æœ€å¤§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æç”»æ™‚é–“ï¼ˆ< 2.5ç§’ï¼‰ | Web Vitalsã€UX |
| FID | First Input Delay | åˆå›å…¥åŠ›é…å»¶ï¼ˆ< 100msï¼‰ | Web Vitalsã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ€§ |
| CLS | Cumulative Layout Shift | ç´¯ç©ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ›´ï¼ˆ< 0.1ï¼‰ | Web Vitalsã€è¦–è¦šå®‰å®šæ€§ |
| ãƒ¢ãƒƒã‚¯ | Mock | ãƒ†ã‚¹ãƒˆç”¨ã®å½ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | pytest-mockã€ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ |
| ã‚¹ã‚¿ãƒ– | Stub | æœ€å°é™ã®å®Ÿè£…ã‚’æŒã¤ä»£æ›¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | ãƒ†ã‚¹ãƒˆãƒ€ãƒ–ãƒ«ã€çµ±åˆãƒ†ã‚¹ãƒˆ |
| E2E | End-to-End | ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆã€‚ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å‹•ä½œç¢ºèª | Playwrightã€å—å…¥ãƒ†ã‚¹ãƒˆ |
| SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ | SQL Injection | SQLæ–‡ã«ä¸æ­£ãªã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥ã™ã‚‹æ”»æ’ƒ | ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒª |
| ãƒ¬ãƒ¼ãƒˆåˆ¶é™ | Rate Limiting | APIå‘¼ã³å‡ºã—é »åº¦ã®åˆ¶é™ | Token Bucketã€ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚° |

### å‚è€ƒè³‡æ–™

**å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**:
```yaml
python:
  - "Python 3.11 Documentation: https://docs.python.org/3.11/"
  - "pandas User Guide: https://pandas.pydata.org/docs/user_guide/"
  - "lxml Tutorial: https://lxml.de/tutorial.html"
  - "pytest Documentation: https://docs.pytest.org/"

javascript:
  - "MDN Web Docs: https://developer.mozilla.org/"
  - "sqlite-wasm: https://sql.js.org/"
  - "lightweight-charts: https://tradingview.github.io/lightweight-charts/"

github:
  - "GitHub Actions: https://docs.github.com/en/actions"
  - "GitHub Pages: https://docs.github.com/en/pages"
  - "Git LFS: https://git-lfs.com/"

finance:
  - "EDINET API: https://disclosure.edinet-fsa.go.jp/EKW0EZ1001.html"
  - "XBRL International: https://www.xbrl.org/"
```

**æ›¸ç±**:
```yaml
investment:
  - "ãƒ™ãƒ³ã‚¸ãƒ£ãƒŸãƒ³ãƒ»ã‚°ãƒ¬ã‚¢ãƒ ã€è³¢æ˜ãªã‚‹æŠ•è³‡å®¶ã€ï¼ˆãƒãƒƒãƒˆãƒãƒƒãƒˆç†è«–ï¼‰"
  - "ã‚¦ã‚£ãƒªã‚¢ãƒ ãƒ»ã‚ªãƒ‹ãƒ¼ãƒ«ã€ã‚ªãƒ‹ãƒ¼ãƒ«ã®æˆé•·æ ªç™ºæ˜æ³•ã€ï¼ˆCAN-SLIMï¼‰"

software:
  - "Martin Fowlerã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã€"
  - "Robert C. Martinã€Clean Codeã€"
  - "Kent Beckã€ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã€"
```

---

**ã“ã®å®Ÿè£…è¨ˆç”»æ›¸ã«åŸºã¥ãã€7é€±é–“ã§æ ªå¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã‚’å®Œäº†ã—ã¾ã™ã€‚**

---

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæˆåŠŸåŸºæº–

### å®šé‡çš„æˆåŠŸåŸºæº–

```yaml
functionality:
  data_coverage:
    target: "æ±è¨¼ä¸Šå ´ä¼æ¥­4000ç¤¾ä»¥ä¸Š"
    measurement: "SELECT COUNT(DISTINCT company_id) FROM companies"
    threshold: ">= 4000"
  
  calculation_accuracy:
    target: "NetNetPBRè¨ˆç®—ç²¾åº¦ < 0.01%"
    measurement: "æ‰‹è¨ˆç®—ã¨ã®æ¯”è¼ƒï¼ˆã‚µãƒ³ãƒ—ãƒ«100éŠ˜æŸ„ï¼‰"
    threshold: "èª¤å·® < 0.01%"
  
  automation:
    target: "æ—¥æ¬¡è‡ªå‹•æ›´æ–°æˆåŠŸç‡ >= 95%"
    measurement: "GitHub ActionsæˆåŠŸç‡ï¼ˆ30æ—¥é–“ï¼‰"
    threshold: ">= 95%"

performance:
  backend:
    - metric: "XBRLå–å¾—æ™‚é–“"
      target: "æ—¥æ¬¡æ›´æ–° < 3åˆ†"
      measurement: "GitHub Actionså®Ÿè¡Œæ™‚é–“"
    
    - metric: "NetNetè¨ˆç®—æ™‚é–“"
      target: "4000ç¤¾ < 10ç§’"
      measurement: "time python scripts/analyzers/netnet.py"
    
    - metric: "DB ã‚µã‚¤ã‚º"
      target: "< 1GBï¼ˆåˆå¹´åº¦ï¼‰"
      measurement: "du -h data/db/stock-analysis.db"
  
  frontend:
    - metric: "Lighthouse Performance"
      target: ">= 90"
      measurement: "Chrome Lighthouse"
    
    - metric: "DB èª­è¾¼æ™‚é–“"
      target: "åˆå› < 3ç§’ã€2å›ç›® < 100ms"
      measurement: "Performance API"
    
    - metric: "ãƒãƒ£ãƒ¼ãƒˆæç”»"
      target: "1000ãƒã‚¤ãƒ³ãƒˆ < 500ms"
      measurement: "console.time()"

quality:
  test_coverage:
    target: "100%"
    measurement: "pytest --cov=scripts --cov-report=term"
    threshold: "100%"
  
  code_quality:
    - metric: "flake8"
      target: "0 errors"
      measurement: "flake8 scripts/"
    
    - metric: "mypy"
      target: "0 type errors"
      measurement: "mypy scripts/"
    
    - metric: "å¾ªç’°çš„è¤‡é›‘åº¦"
      target: "å¹³å‡ < Bï¼ˆ< 10ï¼‰"
      measurement: "radon cc scripts/ -a"

usability:
  - metric: "ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡"
    target: "< 1%ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å½“ãŸã‚Šï¼‰"
    measurement: "window.onerror ã‚«ã‚¦ãƒ³ãƒˆ"
  
  - metric: "ãƒšãƒ¼ã‚¸èª­è¾¼æ™‚é–“"
    target: "95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ« < 5ç§’"
    measurement: "Google Analytics"
```

### å®šæ€§çš„æˆåŠŸåŸºæº–

```yaml
documentation:
  - "README.md ãŒå®Œå…¨ï¼ˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ä½¿ç”¨æ–¹æ³•ã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰"
  - "ã‚³ãƒ¼ãƒ‰å†…ã‚³ãƒ¡ãƒ³ãƒˆå……å®Ÿï¼ˆé–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹å…¨ã¦ã«docstringï¼‰"
  - "APIä»•æ§˜æ›¸ä½œæˆï¼ˆå†…éƒ¨é–¢æ•°å«ã‚€ï¼‰"

maintainability:
  - "æ–°è¦ãƒ¡ãƒ³ãƒãƒ¼ãŒ1æ—¥ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ã§ãã‚‹"
  - "ãƒã‚°ä¿®æ­£ãŒå¹³å‡1æ™‚é–“ä»¥å†…ã§å®Œäº†"
  - "æ–°æ©Ÿèƒ½è¿½åŠ ãŒå¹³å‡1é€±é–“ä»¥å†…ã§å®Œäº†"

reliability:
  - "30æ—¥é–“é€£ç¶šç¨¼åƒï¼ˆGitHub Actionsï¼‰"
  - "ãƒ‡ãƒ¼ã‚¿æ¬ æã‚¼ãƒ­ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼ï¼‰"
  - "ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ï¼ˆGitHub Pages SLA 99.9%ï¼‰"
```

### æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿè£…é–‹å§‹ï¼‰

**å³åº§ã«å®Ÿè¡Œ**:
```powershell
# 1. ãƒ–ãƒ©ãƒ³ãƒç¢ºèª
git branch

# 2. Pythonç’°å¢ƒç¢ºèª
python --version  # 3.11ä»¥ä¸Š

# 3. ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv

# 4. ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–
.\venv\Scripts\Activate.ps1

# 5. Git LFSåˆæœŸåŒ–
git lfs install

# 6. requirements.txtä½œæˆ
@"
# Core dependencies
pandas==2.0.3
numpy==1.24.3
lxml==4.9.3
requests==2.31.0

# Testing
pytest==7.4.0
pytest-cov==4.1.0
pytest-mock==3.11.1
pytest-xdist==3.3.1
pytest-timeout==2.1.0
pytest-benchmark==4.0.0

# Code quality
flake8==6.0.0
mypy==1.4.1
black==23.7.0
isort==5.12.0
pylint==2.17.5
radon==6.0.1

# Utilities
tqdm==4.65.0
python-dotenv==1.0.0
pyyaml==6.0.1
"@ | Out-File -FilePath requirements.txt -Encoding UTF8

# 7. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# 8. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
New-Item -ItemType Directory -Force -Path data\raw\xbrl
New-Item -ItemType Directory -Force -Path data\raw\prices
New-Item -ItemType Directory -Force -Path data\normalized
New-Item -ItemType Directory -Force -Path data\db
New-Item -ItemType Directory -Force -Path data\cache
New-Item -ItemType Directory -Force -Path scripts\analyzers
New-Item -ItemType Directory -Force -Path src
New-Item -ItemType Directory -Force -Path schemas
New-Item -ItemType Directory -Force -Path tests
New-Item -ItemType Directory -Force -Path utils
New-Item -ItemType Directory -Force -Path logs

# 9. .gitignoreä½œæˆ
@"
# Python
venv/
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
*.egg-info/
dist/
build/

# Data
data/raw/
data/normalized/
data/cache/
*.db-journal

# Logs
logs/
*.log

# IDEs
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Testing
.pytest_cache/
.coverage
htmlcov/

# Environment
.env
"@ | Out-File -FilePath .gitignore -Encoding UTF8

# 10. LFSãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨­å®š
git lfs track "*.db"
git lfs track "*.db.gz"

# 11. åˆå›ã‚³ãƒŸãƒƒãƒˆ
git add .gitattributes
git add requirements.txt
git add .gitignore
git commit -m "IMPL-001~006: åŸºç›¤æ§‹ç¯‰å®Œäº†"
```

**Week 1 ã‚¿ã‚¹ã‚¯é–‹å§‹**:
```yaml
day_1:
  - task: "IMPL-001: Pythonç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
    status: "å®Œäº†ï¼ˆä¸Šè¨˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼‰"
  
  - task: "IMPL-002: Git/GitHubè¨­å®š"
    status: "å®Œäº†ï¼ˆä¸Šè¨˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼‰"
  
  - task: "IMPL-003: SQLiteã‚¹ã‚­ãƒ¼ãƒå®Ÿè£…"
    action: "æ¬¡ã®ã‚¿ã‚¹ã‚¯"
    command: |
      # schemas/create_tables.sql ä½œæˆ
      # ï¼ˆClaudeã«ä¾é ¼: "IMPL-003ã®SQLã‚¹ã‚­ãƒ¼ãƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„"ï¼‰

next_steps:
  - "1. IMPL-003: SQLã‚¹ã‚­ãƒ¼ãƒä½œæˆï¼ˆschemas/create_tables.sqlï¼‰"
  - "2. IMPL-004: DBåˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆï¼ˆscripts/init_db.pyï¼‰"
  - "3. IMPL-005: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèªï¼ˆtree ã‚³ãƒãƒ³ãƒ‰ï¼‰"
  - "4. IMPL-006: requirements.txtæ¤œè¨¼ï¼ˆpip listï¼‰"
```

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†**:
```yaml
communication:
  - tool: "GitHub Issues"
    use: "ã‚¿ã‚¹ã‚¯ç®¡ç†ã€ãƒã‚°å ±å‘Š"
    template: "specs/001-stock-analysis-system/spec.mdï¼ˆIssueä¾‹ï¼‰"
  
  - tool: "GitHub Projects"
    use: "ã‚«ãƒ³ãƒãƒ³ãƒœãƒ¼ãƒ‰ï¼ˆToDo, In Progress, Doneï¼‰"
    columns:
      - "Backlog: IMPL-007~032"
      - "In Progress: IMPL-003~006"
      - "Done: ãªã—"
  
  - tool: "GitHub Discussions"
    use: "è¨­è¨ˆè­°è«–ã€è³ªå•"

progress_tracking:
  - frequency: "æ¯æ—¥"
    action: "README.md ã®é€²æ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ›´æ–°"
    format: |
      ## é€²æ—çŠ¶æ³
      - [x] IMPL-001: Pythonç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
      - [x] IMPL-002: Git/GitHubè¨­å®š
      - [ ] IMPL-003: SQLiteã‚¹ã‚­ãƒ¼ãƒå®Ÿè£…ï¼ˆé€²è¡Œä¸­ï¼‰
      ...
  
  - frequency: "é€±æ¬¡"
    action: "ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é”æˆç¢ºèª"
    report: "GitHub Discussions ã«æŠ•ç¨¿"

quality_gates:
  before_merge:
    - "å…¨ãƒ†ã‚¹ãƒˆåˆæ ¼ï¼ˆpytestï¼‰"
    - "ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ 100%"
    - "flake8, mypy åˆæ ¼"
    - "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿èªï¼ˆã‚»ãƒ«ãƒ•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯ï¼‰"
  
  before_release:
    - "å—å…¥ãƒ†ã‚¹ãƒˆå…¨åˆæ ¼"
    - "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°"
    - "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆåˆæ ¼"
    - "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯"
```

---

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0 | **ä½œæˆæ—¥**: 2025å¹´11æœˆ22æ—¥ | **æœ€çµ‚æ›´æ–°**: 2025å¹´11æœˆ22æ—¥ | **æ‰¿èª**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ¼ãƒ‰

**ç·ãƒšãƒ¼ã‚¸æ•°**: 1 | **ç·è¡Œæ•°**: 4000+ | **è¦‹ç©å·¥æ•°**: 48æ—¥ï¼ˆAIæ”¯æ´ï¼‰ | **ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**: 7é€±é–“
